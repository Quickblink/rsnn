{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from Code.ANN import lstmPolicyPredictor, FullyConnected\n",
    "from Code.envs.GPEnv import PassiveEnv\n",
    "from wip.Code.train import make_dataset_simple\n",
    "from Code.SNN import DynNetwork, SequenceWrapper\n",
    "from Code.ANN import LSTMWrapper, ReLuWrapper\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from Code import Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#TODO: output reset mechanism\n",
    "\n",
    "config = {\n",
    "    'ALPHA': 0.5, #0.7\n",
    "    'BETA': 0.9, #0.95\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "secondconfig = {\n",
    "    'ALPHA': 0.7,\n",
    "    'BETA': 0.5, #0.95\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "heavyside = {\n",
    "    'ALPHA': 0,\n",
    "    'BETA': 1, #0.95\n",
    "    'RESET_ZERO': False,\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "outconfig = {\n",
    "    'ALPHA': 0,\n",
    "    'BETA': 0,\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "class Selector(nn.Module):\n",
    "    def __init__(self, params, size):\n",
    "        super().__init__()\n",
    "        self.start = params\n",
    "        self.end = params + size\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        return x[:, self.start:self.end], ()\n",
    "\n",
    "    def get_initial_state(self, batch_size):\n",
    "        return ()\n",
    "\n",
    "architecture1 = OrderedDict([\n",
    "    ('input', [3]),\n",
    "    ('obs', [2, ['input'], Selector, 0, None]),\n",
    "    ('probe', [1, ['input'], Selector, 2, None]),\n",
    "    ('pre_mem', [128, ['obs', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('mem', [64, ['pre_mem'], Neurons.CooldownNeuron, config, nn.Linear]), #CooldownNeuron 32\n",
    "    ('short_mem', [64, ['pre_mem'], Neurons.CooldownNeuron, secondconfig, nn.Linear]), #32\n",
    "    ('post_mem', [128, ['probe', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('output', [2, ['post_mem'], Neurons.OutputNeuron, outconfig, nn.Linear]), #OutputNeuron\n",
    "])\n",
    "\n",
    "architecture0 = OrderedDict([\n",
    "    ('input', [3]),\n",
    "    ('obs', [2, ['input'], Selector, 0, None]),\n",
    "    ('probe', [1, ['input'], Selector, 2, None]),\n",
    "    ('pre_mem', [128, ['obs', 'mem'], Neurons.LIFNeuron, outconfig, nn.Linear]),\n",
    "    ('mem', [128, ['pre_mem'], Neurons.CooldownNeuron, heavyside, nn.Linear]), #CooldownNeuron 32\n",
    "    ('post_mem', [128, ['probe', 'mem'], Neurons.LIFNeuron, outconfig, nn.Linear]),\n",
    "    ('output', [2, ['post_mem'], Neurons.OutputNeuron, outconfig, nn.Linear]), #OutputNeuron\n",
    "])\n",
    "\n",
    "architecture2 = OrderedDict([\n",
    "    ('input', [3]),\n",
    "    ('obs', [2, ['input'], Selector, 0, None]),\n",
    "    ('probe', [1, ['input'], Selector, 2, None]),\n",
    "    ('pre_mem', [64, ['obs', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('mem', [128, ['pre_mem'], Neurons.CooldownNeuron, config, nn.Linear]), #CooldownNeuron 32\n",
    "    ('short_mem', [128, ['pre_mem'], Neurons.CooldownNeuron, secondconfig, nn.Linear]), #32\n",
    "    ('post_mem', [64, ['probe', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('secondproc', [64, ['post_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('output', [2, ['secondproc'], Neurons.OutputNeuron, outconfig, nn.Linear]), #OutputNeuron\n",
    "])\n",
    "\n",
    "architecturelstm0 = OrderedDict([\n",
    "    ('input', [3]),\n",
    "    ('obs', [2, ['input'], Selector, 0, None]),\n",
    "    ('probe', [1, ['input'], Selector, 2, None]),\n",
    "    ('lstm', [128, ['obs'], LSTMWrapper, None, nn.Linear]),\n",
    "    ('post_mem', [128, ['probe', 'lstm'], ReLuWrapper, None, nn.Linear]),\n",
    "    ('output', [2, ['post_mem'], Neurons.OutputNeuron, outconfig, nn.Linear]), #OutputNeuron\n",
    "])\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "SIM_TIME = 1\n",
    "MAX_ITER = 50\n",
    "\n",
    "device = torch.device('cuda')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from Code.Networks import Selector, DynNetwork, SequenceWrapper, OuterWrapper, LSTMWrapper, ReLuWrapper\n",
    "from Code.NewNeurons import SeqOnlySpike, CooldownNeuron, OutputNeuron\n",
    "\n",
    "base_config = {\n",
    "    'ALPHA': 0,\n",
    "    'BETA': 0,\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "heavyside = {\n",
    "    'ALPHA': 0,\n",
    "    'BETA': 1, #0.95\n",
    "    'RESET_ZERO': False,\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "mem_loop = OrderedDict([\n",
    "    ('input', 2),\n",
    "    ('pre_mem', [['input', 'output'], SeqOnlySpike(128, base_config), nn.Linear]),\n",
    "    ('output', [['pre_mem'], CooldownNeuron(128, heavyside), nn.Linear]),\n",
    "])\n",
    "\n",
    "architecture = OrderedDict([\n",
    "    ('input', 3),\n",
    "    ('obs', [['input'], Selector(0, 2), None]),\n",
    "    ('probe', [['input'], Selector(2, 1), None]),\n",
    "    ('mem_loop', [['obs'], SequenceWrapper(DynNetwork(mem_loop)), None]),\n",
    "    ('post_mem', [['probe', 'mem_loop'], SeqOnlySpike(128, base_config), nn.Linear]),\n",
    "    ('output', [['post_mem'], OutputNeuron(2, base_config), nn.Linear]),\n",
    "])\n",
    "\n",
    "architecturelstm = OrderedDict([\n",
    "    ('input', 3),\n",
    "    ('obs', [['input'], Selector(0, 2), None]),\n",
    "    ('probe', [['input'], Selector(2, 1), None]),\n",
    "    ('lstm', [['obs'], LSTMWrapper(2, 128), None]),\n",
    "    ('post_mem', [['probe', 'lstm'], ReLuWrapper(128), nn.Linear]),\n",
    "    ('output', [['post_mem'], OutputNeuron(2, base_config), nn.Linear]),\n",
    "])\n",
    "\n",
    "#TODO: fix output\n",
    "\n",
    "model = OuterWrapper(DynNetwork(architecture), BATCH_SIZE, device, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "env = PassiveEnv(BATCH_SIZE, MAX_ITER, device)\n",
    "#model = lstmPolicyPredictor(1,32,64)\n",
    "\n",
    "#model = FullyConnected([1, 128, 128, 1])\n",
    "\n",
    "model_raw = DynNetwork(architecture, SIM_TIME)\n",
    "model = SequenceWrapper(model_raw, BATCH_SIZE, device, False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "mse = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)#0.000011e-6\n",
    "#optimizer = optim.Adam(model.model.layers['output_linear'].parameters(), lr=1e-4)#0.000011e-6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043683312833309174 0.07636509090662003 0\n",
      "0.042748503386974335 0.07718075066804886 100\n",
      "0.042002614587545395 0.07323010265827179 200\n",
      "0.04200999066233635 0.07358777523040771 300\n",
      "0.041039008647203445 0.07261829078197479 400\n",
      "0.043303847312927246 0.07408227771520615 500\n",
      "0.0407387837767601 0.07289744913578033 600\n",
      "0.04048919677734375 0.072781041264534 700\n",
      "0.041787758469581604 0.07650204747915268 800\n",
      "0.03737260401248932 0.06898397952318192 900\n",
      "0.04042200371623039 0.0725611224770546 1000\n",
      "0.04019938409328461 0.07072747498750687 1100\n",
      "0.03956860676407814 0.07087235897779465 1200\n",
      "0.04184488207101822 0.07328825443983078 1300\n",
      "0.0388055182993412 0.06901288032531738 1400\n",
      "0.04098735749721527 0.07384707778692245 1500\n",
      "0.04019228741526604 0.07399100065231323 1600\n",
      "0.041445836424827576 0.07105650007724762 1700\n",
      "0.0401562824845314 0.07046672701835632 1800\n",
      "0.040979545563459396 0.07318063825368881 1900\n",
      "0.03995523229241371 0.073030985891819 2000\n",
      "0.04128078371286392 0.07259466499090195 2100\n",
      "0.04097726196050644 0.07311677932739258 2200\n",
      "0.04002423211932182 0.07206999510526657 2300\n",
      "0.040305737406015396 0.07085369527339935 2400\n",
      "0.04113782197237015 0.07082449644804001 2500\n",
      "0.04052721709012985 0.07271096855401993 2600\n",
      "0.03967851772904396 0.0702916756272316 2700\n",
      "0.040384531021118164 0.07078363001346588 2800\n",
      "0.04094846546649933 0.07183580100536346 2900\n",
      "0.03821982443332672 0.06690465658903122 3000\n",
      "0.038411691784858704 0.07030375301837921 3100\n",
      "0.03830481320619583 0.0693412721157074 3200\n",
      "0.040315598249435425 0.07055865228176117 3300\n",
      "0.03945572301745415 0.07171191275119781 3400\n",
      "0.0398167259991169 0.06859145313501358 3500\n",
      "0.03830387443304062 0.06819634139537811 3600\n",
      "0.038595933467149734 0.06994016468524933 3700\n",
      "0.03874783590435982 0.06796179711818695 3800\n",
      "0.040588658303022385 0.07070207595825195 3900\n",
      "0.03947049379348755 0.07158982753753662 4000\n",
      "0.03773251920938492 0.06774377822875977 4100\n",
      "0.03964446857571602 0.06688730418682098 4200\n",
      "0.038615502417087555 0.06868541985750198 4300\n",
      "0.038832664489746094 0.06960225850343704 4400\n",
      "0.03913550823926926 0.07080671191215515 4500\n",
      "0.03900637850165367 0.06888584047555923 4600\n",
      "0.039569191634655 0.0714607983827591 4700\n",
      "0.0377957858145237 0.06904219835996628 4800\n",
      "0.04027218371629715 0.07233402878046036 4900\n",
      "0.03878732770681381 0.06836036592721939 5000\n",
      "0.03935727849602699 0.06932400912046432 5100\n",
      "0.0381879098713398 0.06751421093940735 5200\n",
      "0.037231821566820145 0.06600076705217361 5300\n",
      "0.039049044251441956 0.06835152208805084 5400\n",
      "0.03752181679010391 0.06591920554637909 5500\n",
      "0.03795527666807175 0.0693637803196907 5600\n",
      "0.038454242050647736 0.0667247325181961 5700\n",
      "0.03951330855488777 0.06729363650083542 5800\n",
      "0.03894171491265297 0.06672443449497223 5900\n",
      "0.03632335364818573 0.06556890904903412 6000\n",
      "0.037317704409360886 0.06632816046476364 6100\n",
      "0.04019731283187866 0.0712057426571846 6200\n",
      "0.038981594145298004 0.06768641620874405 6300\n",
      "0.039324190467596054 0.07048222422599792 6400\n",
      "0.03976251929998398 0.07060413807630539 6500\n",
      "0.03925314173102379 0.06916951388120651 6600\n",
      "0.037406980991363525 0.0676020011305809 6700\n",
      "0.03872443735599518 0.06915757060050964 6800\n",
      "0.038797881454229355 0.07057058811187744 6900\n",
      "0.03806707635521889 0.06722618639469147 7000\n",
      "0.03776620700955391 0.06802787631750107 7100\n",
      "0.0373055674135685 0.06642702221870422 7200\n",
      "0.03807969018816948 0.06633996963500977 7300\n",
      "0.038327187299728394 0.06782618910074234 7400\n",
      "0.0370929129421711 0.06633314490318298 7500\n",
      "0.03850262239575386 0.06718242168426514 7600\n",
      "0.037210870534181595 0.06867151707410812 7700\n",
      "0.03726590424776077 0.06670744717121124 7800\n",
      "0.036939773708581924 0.06525678932666779 7900\n",
      "0.038085635751485825 0.06701838970184326 8000\n",
      "0.037584125995635986 0.0692245289683342 8100\n",
      "0.037189047783613205 0.06494726240634918 8200\n",
      "0.03849641978740692 0.06775132566690445 8300\n",
      "0.038493335247039795 0.06821654736995697 8400\n",
      "0.037623342126607895 0.06649331748485565 8500\n",
      "0.03903230279684067 0.06776072829961777 8600\n",
      "0.03753913566470146 0.06751620024442673 8700\n",
      "0.03748476505279541 0.06638744473457336 8800\n",
      "0.037129998207092285 0.06670055538415909 8900\n",
      "0.03703649714589119 0.0650886595249176 9000\n",
      "0.03584661707282066 0.0651039183139801 9100\n",
      "0.038027338683605194 0.06654978543519974 9200\n",
      "0.038448870182037354 0.06766558438539505 9300\n",
      "0.03654899820685387 0.0643526166677475 9400\n",
      "0.03679044172167778 0.06789639592170715 9500\n",
      "0.038864314556121826 0.06757469475269318 9600\n",
      "0.03579704090952873 0.06663306057453156 9700\n",
      "0.038715146481990814 0.06809285283088684 9800\n",
      "0.035736240446567535 0.06427425146102905 9900\n",
      "Total time:  2996.342612504959\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(10000):\n",
    "    model.zero_grad()\n",
    "    inputs, targets = env.getBatch()\n",
    "    if i%100 == 0:\n",
    "        for p in model.parameters():\n",
    "            if torch.isnan(p).any():\n",
    "                raise Exception('Corrupted Model')\n",
    "    outputs, _ = model(inputs)\n",
    "    processed = torch.empty_like(outputs)\n",
    "    processed[:, :, 1] = outputs[:, :, 1]\n",
    "    processed[:, :, 0] = torch.sigmoid(outputs[:, :, 0])\n",
    "    loss = mse(processed, targets)\n",
    "    #loss = mse(outputs[..., 1], targets[..., 1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        print(loss.item(), (loss/targets.view(-1).var()).item(), i)\n",
    "\n",
    "print('Total time: ', time.time()-start)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x7fbeccdc5e10>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#model = torch.load('../models/snn_passive3')\n",
    "%matplotlib\n",
    "\n",
    "\n",
    "inputs, targets = env.getBatch()\n",
    "outputs, _ = model(inputs)\n",
    "plt.scatter(inputs[:, 0, 2].cpu(), targets[:, 0, 1].cpu(), label='Mean_Target')\n",
    "plt.scatter(inputs[:, 0, 2].cpu(), outputs[:, 0, 1].detach().cpu(), label='Mean')\n",
    "plt.scatter(inputs[:, 0, 2].cpu(), targets[:, 0, 0].cpu(), label='Var_Target')\n",
    "plt.scatter(inputs[:, 0, 2].cpu(), torch.sigmoid(outputs[:, 0, 0].cpu()).detach(), label='Var')\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:354: UserWarning: Couldn't retrieve source code for container of type Selector. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, '../../models/rsnn_gppred2')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "obs, targets = env.getBatch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0725,  1.3078,  0.7469],\n        [ 0.7469,  0.1004,  0.1551],\n        [ 0.1551,  0.7648,  0.5999],\n        [ 0.5999, -0.3369,  0.3660],\n        [ 0.3660,  0.6587,  0.2637],\n        [ 0.2637,  0.3779,  0.2201],\n        [ 0.2201,  0.3814,  0.1194],\n        [ 0.1194,  1.0581,  0.8709],\n        [ 0.8709,  0.5644,  0.1411],\n        [ 0.1411,  0.8821,  0.6016],\n        [ 0.6016, -0.3385,  0.0749],\n        [ 0.0749,  1.3016,  0.7182],\n        [ 0.7182, -0.0277,  0.5491],\n        [ 0.5491, -0.1718,  0.2822],\n        [ 0.2822,  0.4266,  0.7817],\n        [ 0.7817,  0.2554,  0.1489],\n        [ 0.1489,  0.8160,  0.9466],\n        [ 0.9466,  0.6245,  0.5037],\n        [ 0.5037,  0.1100,  0.6078],\n        [ 0.6078, -0.3423,  0.3834],\n        [ 0.3834,  0.6589,  0.1964],\n        [ 0.1964,  0.4742,  0.7783],\n        [ 0.7783,  0.2406,  0.3649],\n        [ 0.3649,  0.6579,  0.9045],\n        [ 0.9045,  0.6172,  0.5368],\n        [ 0.5368, -0.1034,  0.7161],\n        [ 0.7161, -0.0366,  0.4711],\n        [ 0.4711,  0.3251,  0.9820],\n        [ 0.9820,  0.5764,  0.4191],\n        [ 0.4191,  0.5849,  0.8393],\n        [ 0.8393,  0.4793,  0.6317],\n        [ 0.6317, -0.3269,  0.2778],\n        [ 0.2778,  0.4132,  0.2948],\n        [ 0.2948,  0.4687,  0.4170],\n        [ 0.4170,  0.5919,  0.8782],\n        [ 0.8782,  0.5793,  0.2520],\n        [ 0.2520,  0.3598,  0.0140],\n        [ 0.0140,  1.1842,  0.8415],\n        [ 0.8415,  0.4862,  0.4262],\n        [ 0.4262,  0.5586,  0.5436],\n        [ 0.5436, -0.1420,  0.9644],\n        [ 0.9644,  0.6065,  0.9086],\n        [ 0.9086,  0.6209,  0.5564],\n        [ 0.5564, -0.2085,  0.4671],\n        [ 0.4671,  0.3501,  0.0190],\n        [ 0.0190,  1.2139,  0.3513],\n        [ 0.3513,  0.6404,  0.3101],\n        [ 0.3101,  0.5235,  0.6660],\n        [ 0.6660, -0.2381,  0.3934],\n        [ 0.3934,  0.6482,  0.2089]], device='cuda:0')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[:, 0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.7684e-20,  1.7391e-10],\n        [ 5.0578e-01,  9.3009e-01],\n        [ 1.1508e-01,  3.4039e-02],\n        [ 2.4592e-02, -4.2329e-02],\n        [ 6.7668e-01,  4.2292e-01],\n        [ 9.8833e-01,  3.8013e-01],\n        [ 9.9864e-01,  1.0591e+00],\n        [ 2.3511e-01,  1.0906e-01],\n        [ 9.9999e-01,  8.8214e-01],\n        [ 9.9982e-01, -3.3843e-01],\n        [ 9.9999e-01,  1.3017e+00],\n        [ 9.8745e-01, -4.8751e-02],\n        [ 9.7186e-01, -1.9440e-01],\n        [ 9.9988e-01,  4.2651e-01],\n        [ 9.9765e-01,  2.5635e-01],\n        [ 9.9999e-01,  8.1605e-01],\n        [ 8.5181e-01,  5.0005e-01],\n        [ 9.9471e-01,  1.1237e-01],\n        [ 9.9999e-01, -3.4233e-01],\n        [ 9.9987e-01,  6.5898e-01],\n        [ 9.9999e-01,  4.7421e-01],\n        [ 9.9999e-01,  2.4056e-01],\n        [ 9.9999e-01,  6.5790e-01],\n        [ 9.9935e-01,  6.1698e-01],\n        [ 9.9999e-01, -1.0340e-01],\n        [ 9.9999e-01, -3.6590e-02],\n        [ 9.9994e-01,  3.2506e-01],\n        [ 9.9712e-01,  5.7741e-01],\n        [ 9.9997e-01,  5.8489e-01],\n        [ 9.9997e-01,  4.7928e-01],\n        [ 9.9997e-01, -3.2689e-01],\n        [ 9.9999e-01,  4.1316e-01],\n        [ 9.9999e-01,  4.6872e-01],\n        [ 9.9999e-01,  5.9194e-01],\n        [ 9.9999e-01,  5.7926e-01],\n        [ 9.9999e-01,  3.5976e-01],\n        [ 9.8402e-01,  1.2049e+00],\n        [ 9.9999e-01,  4.8617e-01],\n        [ 1.0000e+00,  5.5862e-01],\n        [ 1.0000e+00, -1.4203e-01],\n        [ 9.9999e-01,  6.0651e-01],\n        [ 9.9999e-01,  6.2090e-01],\n        [ 1.0000e+00, -2.0851e-01],\n        [ 9.9999e-01,  3.5007e-01],\n        [ 9.9998e-01,  1.2140e+00],\n        [ 9.9999e-01,  6.4043e-01],\n        [ 9.9999e-01,  5.2345e-01],\n        [ 9.9998e-01, -2.3806e-01],\n        [ 1.0000e+00,  6.4820e-01],\n        [ 1.0000e+00,  4.1728e-01]], device='cuda:0')"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[:, 0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#model2 = torch.load('../../models/rsnn_gppred1')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "SequenceWrapper(\n  (pretrace): DynNetwork(\n    (layers): ModuleDict(\n      (obs): Selector()\n      (probe): Selector()\n      (pre_mem_linear): Linear(in_features=130, out_features=128, bias=True)\n      (pre_mem): LIFNeuron()\n      (mem_linear): Linear(in_features=128, out_features=128, bias=True)\n      (mem): CooldownNeuron(\n        (elu): ELU(alpha=1.0)\n      )\n      (post_mem_linear): Linear(in_features=129, out_features=128, bias=True)\n      (post_mem): LIFNeuron()\n      (output_linear): Linear(in_features=128, out_features=2, bias=True)\n      (output): OutputNeuron()\n    )\n  )\n  (model): DynNetwork(\n    (layers): ModuleDict(\n      (obs): Selector()\n      (probe): Selector()\n      (pre_mem_linear): Linear(in_features=130, out_features=128, bias=True)\n      (pre_mem): LIFNeuron()\n      (mem_linear): Linear(in_features=128, out_features=128, bias=True)\n      (mem): CooldownNeuron(\n        (elu): ELU(alpha=1.0)\n      )\n      (post_mem_linear): Linear(in_features=129, out_features=128, bias=True)\n      (post_mem): LIFNeuron()\n      (output_linear): Linear(in_features=128, out_features=2, bias=True)\n      (output): OutputNeuron()\n    )\n  )\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model2.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for p in model.model.layers['output_linear'].parameters():\n",
    "    print(p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.parameters at 0x7fbeccb995c8>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers['output_linear'].parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}