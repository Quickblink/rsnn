{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from Code.ANN import lstmPolicyPredictor, FullyConnected\n",
    "from Code.envs.MountainCar import MultiMountainCar, LookupPolicy, PassiveEnv\n",
    "from wip.Code.train import make_dataset_simple\n",
    "from Code.SNN import DynNetwork, SequenceWrapper\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from Code import Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#TODO: output reset mechanism\n",
    "\n",
    "config = {\n",
    "    'ALPHA': 0.7,\n",
    "    'BETA': 0.9, #0.95\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "secondconfig = {\n",
    "    'ALPHA': 0.7,\n",
    "    'BETA': 0.5, #0.95\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "outconfig = {\n",
    "    'ALPHA': 0,\n",
    "    'BETA': 0,\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "\n",
    "architecture1 = OrderedDict([\n",
    "    ('input', [1]),\n",
    "    ('pre_mem', [64, ['input', 'mem'], Neurons.LIFNeuron, config]),\n",
    "    ('mem', [32, ['pre_mem'], Neurons.CooldownNeuron, config]), #CooldownNeuron\n",
    "    ('post_mem', [64, ['input', 'mem'], Neurons.LIFNeuron, config]),\n",
    "    ('output', [1, ['post_mem'], Neurons.OutputNeuron, outconfig]), #OutputNeuron\n",
    "])\n",
    "\n",
    "architecture = OrderedDict([\n",
    "    ('input', [1]),\n",
    "    ('pre_mem', [64, ['input', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('mem', [32, ['pre_mem'], Neurons.CooldownNeuron, config, nn.Linear]), #CooldownNeuron\n",
    "    ('short_mem', [32, ['pre_mem'], Neurons.CooldownNeuron, secondconfig, nn.Linear]),\n",
    "    ('post_mem', [64, ['input', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('output', [1, ['post_mem'], Neurons.OutputNeuron, outconfig, nn.Linear]), #OutputNeuron\n",
    "])\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SIM_TIME = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "env = MultiMountainCar(device)\n",
    "MAX_ITER = 200\n",
    "#model = lstmPolicyPredictor(1,32,64)\n",
    "\n",
    "#model = FullyConnected([1, 128, 128, 1])\n",
    "\n",
    "model_raw = DynNetwork(architecture, SIM_TIME)\n",
    "model = SequenceWrapper(model_raw, BATCH_SIZE, device, False)\n",
    "\n",
    "teacher = LookupPolicy(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "testenv = gym.make('MountainCar-v0')\n",
    "\n",
    "def validate(num_runs, render=False):\n",
    "    sum = 0\n",
    "    for i in range(num_runs):\n",
    "        obs = testenv.reset()\n",
    "        state = None\n",
    "        for t in range(300):\n",
    "            if render:\n",
    "                testenv.render()\n",
    "            output, state = model(torch.tensor([[[obs[0]]]], dtype=torch.float), state)\n",
    "            action = 2 if output > 0 else 0\n",
    "            obs, _, done, _ = testenv.step(action)\n",
    "            if done:\n",
    "                #print(t+1)\n",
    "                sum += t + 1\n",
    "                break\n",
    "    print('Validation: ', sum/num_runs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "bce = nn.BCELoss(reduction='none') #reduction='sum'\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)#0.00001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6772387027740479 200 0\n",
      "Validation:  200.0\n",
      "0.6757628917694092 200 10\n",
      "0.6727081537246704 200 20\n",
      "0.6703775525093079 200 30\n",
      "0.6707730889320374 200 40\n",
      "0.6648341417312622 200 50\n",
      "0.6750781536102295 200 60\n",
      "0.6877434253692627 200 70\n",
      "0.679787814617157 200 80\n",
      "0.6696767210960388 200 90\n",
      "0.6473906636238098 200 100\n",
      "Validation:  200.0\n",
      "0.650684118270874 200 110\n",
      "0.6186470985412598 200 120\n",
      "0.6612014770507812 200 130\n",
      "0.6292560696601868 200 140\n",
      "0.6390781998634338 200 150\n",
      "0.6116876006126404 200 160\n",
      "0.661375105381012 200 170\n",
      "0.6208813190460205 200 180\n",
      "0.6210055351257324 200 190\n",
      "0.621647298336029 200 200\n",
      "Validation:  200.0\n",
      "0.6275950074195862 200 210\n",
      "0.6094839572906494 200 220\n",
      "0.6008831262588501 200 230\n",
      "0.5922849774360657 200 240\n",
      "0.5756155252456665 200 250\n",
      "0.5645986199378967 200 260\n",
      "0.5616487264633179 200 270\n",
      "0.5956995487213135 200 280\n",
      "0.5689993500709534 200 290\n",
      "0.5781638622283936 200 300\n",
      "Validation:  200.0\n",
      "0.5647542476654053 200 310\n",
      "0.5438669323921204 200 320\n",
      "0.5398746728897095 200 330\n",
      "0.5409409403800964 200 340\n",
      "0.5420448184013367 200 350\n",
      "0.5320726633071899 200 360\n",
      "0.5361395478248596 200 370\n",
      "0.5265375375747681 200 380\n",
      "0.5142492055892944 200 390\n",
      "0.52896648645401 200 400\n",
      "Validation:  200.0\n",
      "0.5950196385383606 200 410\n",
      "0.5673623085021973 200 420\n",
      "0.5008054971694946 200 430\n",
      "0.49559155106544495 200 440\n",
      "0.5052493214607239 200 450\n",
      "0.4592682719230652 150 460\n",
      "0.4526694715023041 200 470\n",
      "0.42227479815483093 151 480\n",
      "0.39777183532714844 149 490\n",
      "0.3703592121601105 151 500\n",
      "Validation:  146.6\n",
      "0.34584707021713257 181 510\n",
      "0.3498830199241638 173 520\n",
      "0.38068729639053345 157 530\n",
      "0.3393558859825134 172 540\n",
      "0.4273681342601776 153 550\n",
      "0.38526269793510437 153 560\n",
      "0.3555508255958557 151 570\n",
      "0.35296350717544556 153 580\n",
      "0.337387353181839 153 590\n",
      "0.3497493863105774 155 600\n",
      "Validation:  149.8\n",
      "0.33693814277648926 152 610\n",
      "0.30783796310424805 152 620\n",
      "0.3476470410823822 152 630\n",
      "0.3003273904323578 155 640\n",
      "0.2899138927459717 153 650\n",
      "0.3012215793132782 200 660\n",
      "0.28712260723114014 159 670\n",
      "0.2704887092113495 155 680\n",
      "0.279037207365036 161 690\n",
      "0.27119871973991394 156 700\n",
      "Validation:  154.0\n",
      "0.25449320673942566 159 710\n",
      "0.2677057683467865 157 720\n",
      "0.3091632127761841 165 730\n",
      "0.3115816116333008 188 740\n",
      "0.47057050466537476 191 750\n",
      "0.5884425044059753 200 760\n",
      "0.29758593440055847 156 770\n",
      "0.3021780550479889 160 780\n",
      "0.28520968556404114 159 790\n",
      "0.29549136757850647 159 800\n",
      "Validation:  156.3\n",
      "0.35969826579093933 189 810\n",
      "0.21843968331813812 108 820\n",
      "0.2173401415348053 108 830\n",
      "0.20634840428829193 116 840\n",
      "0.20059405267238617 113 850\n",
      "0.20058190822601318 111 860\n",
      "0.2095559537410736 110 870\n",
      "0.19596436619758606 112 880\n",
      "0.19771863520145416 112 890\n",
      "0.19238854944705963 112 900\n",
      "Validation:  103.0\n",
      "0.18938343226909637 108 910\n",
      "0.18735317885875702 109 920\n",
      "0.2071678340435028 108 930\n",
      "0.17832021415233612 108 940\n",
      "0.17545048892498016 108 950\n",
      "0.19336014986038208 106 960\n",
      "0.19000457227230072 106 970\n",
      "0.180813729763031 108 980\n",
      "0.18555797636508942 107 990\n",
      "0.17633531987667084 107 1000\n",
      "Validation:  101.7\n",
      "0.18622979521751404 107 1010\n",
      "0.19166259467601776 106 1020\n",
      "0.1848457157611847 107 1030\n",
      "0.16736499965190887 106 1040\n",
      "0.1769922524690628 107 1050\n",
      "0.18034721910953522 106 1060\n",
      "0.17308025062084198 106 1070\n",
      "0.17868572473526 106 1080\n",
      "0.16088955104351044 105 1090\n",
      "0.1663290411233902 105 1100\n",
      "Validation:  101.7\n",
      "0.1667323261499405 105 1110\n",
      "0.18440376222133636 105 1120\n",
      "0.1777098923921585 106 1130\n",
      "0.17292974889278412 107 1140\n",
      "0.17367355525493622 105 1150\n",
      "0.1715444028377533 106 1160\n",
      "0.16841888427734375 106 1170\n",
      "0.172969788312912 106 1180\n",
      "0.16838118433952332 106 1190\n",
      "0.16669784486293793 106 1200\n",
      "Validation:  101.4\n",
      "0.17209923267364502 107 1210\n",
      "0.17561092972755432 105 1220\n",
      "0.176908940076828 106 1230\n",
      "0.15914486348628998 105 1240\n",
      "0.16188164055347443 106 1250\n",
      "0.16426995396614075 105 1260\n",
      "0.1548338681459427 105 1270\n",
      "0.15679965913295746 105 1280\n",
      "0.16558900475502014 106 1290\n",
      "0.17474576830863953 106 1300\n",
      "Validation:  102.0\n",
      "0.17255501449108124 106 1310\n",
      "0.16451740264892578 107 1320\n",
      "0.18649762868881226 107 1330\n",
      "0.16074946522712708 106 1340\n",
      "0.16748104989528656 105 1350\n",
      "0.1557120978832245 105 1360\n",
      "0.17062333226203918 106 1370\n",
      "0.1597675383090973 106 1380\n",
      "0.15867118537425995 105 1390\n",
      "0.1751672625541687 106 1400\n",
      "Validation:  100.1\n",
      "0.1590375304222107 105 1410\n",
      "0.1621701419353485 105 1420\n",
      "0.1565086543560028 105 1430\n",
      "0.15347182750701904 106 1440\n",
      "0.15463487803936005 105 1450\n",
      "0.17109915614128113 105 1460\n",
      "0.1656636893749237 105 1470\n",
      "0.1566077321767807 104 1480\n",
      "0.16296504437923431 106 1490\n",
      "0.15150092542171478 105 1500\n",
      "Validation:  101.8\n",
      "0.16303226351737976 105 1510\n",
      "0.16545246541500092 105 1520\n",
      "0.15688948333263397 105 1530\n",
      "0.1711835265159607 105 1540\n",
      "0.15833909809589386 105 1550\n",
      "0.15120495855808258 106 1560\n",
      "0.16397641599178314 105 1570\n",
      "0.1550450325012207 105 1580\n",
      "0.14719870686531067 104 1590\n",
      "0.15399277210235596 104 1600\n",
      "Validation:  101.3\n",
      "0.15532046556472778 104 1610\n",
      "0.1615811288356781 104 1620\n",
      "0.14853793382644653 105 1630\n",
      "0.15866832435131073 104 1640\n",
      "0.14352048933506012 105 1650\n",
      "0.16097447276115417 105 1660\n",
      "0.15310169756412506 105 1670\n",
      "0.15084870159626007 105 1680\n",
      "0.15617038309574127 105 1690\n",
      "0.1462680846452713 105 1700\n",
      "Validation:  101.5\n",
      "0.13950414955615997 107 1710\n",
      "0.15620316565036774 105 1720\n",
      "0.16210144758224487 105 1730\n",
      "0.17281794548034668 105 1740\n",
      "0.15445701777935028 105 1750\n",
      "0.15259701013565063 105 1760\n",
      "0.15793640911579132 106 1770\n",
      "0.1536683440208435 105 1780\n",
      "0.16002757847309113 107 1790\n",
      "0.1440809965133667 105 1800\n",
      "Validation:  101.0\n",
      "0.15906105935573578 105 1810\n",
      "0.1537463515996933 106 1820\n",
      "0.14947648346424103 105 1830\n",
      "0.15103267133235931 106 1840\n",
      "0.1578294336795807 106 1850\n",
      "0.14704494178295135 106 1860\n",
      "0.16390234231948853 107 1870\n",
      "0.15019021928310394 106 1880\n",
      "0.16774481534957886 105 1890\n",
      "0.15121357142925262 106 1900\n",
      "Validation:  102.4\n",
      "0.15050634741783142 106 1910\n",
      "0.1690353900194168 106 1920\n",
      "0.15801090002059937 105 1930\n",
      "0.15235482156276703 105 1940\n",
      "0.14690349996089935 105 1950\n",
      "0.14140759408473969 105 1960\n",
      "0.14377741515636444 105 1970\n",
      "0.16157856583595276 105 1980\n",
      "0.1453482061624527 105 1990\n",
      "0.1467081606388092 106 2000\n",
      "Validation:  102.1\n",
      "0.15337321162223816 106 2010\n",
      "0.14881978929042816 105 2020\n",
      "0.1383262574672699 105 2030\n",
      "0.16066917777061462 104 2040\n",
      "0.13264770805835724 105 2050\n",
      "0.14708146452903748 104 2060\n",
      "0.1554102599620819 105 2070\n",
      "0.14651624858379364 105 2080\n",
      "0.15126650035381317 105 2090\n",
      "0.14668214321136475 105 2100\n",
      "Validation:  101.8\n",
      "0.13735507428646088 104 2110\n",
      "0.14597204327583313 105 2120\n",
      "0.1490105241537094 105 2130\n",
      "0.13975773751735687 105 2140\n",
      "0.13749411702156067 104 2150\n",
      "0.13529759645462036 104 2160\n",
      "0.14175066351890564 105 2170\n",
      "0.14158792793750763 105 2180\n",
      "0.14146623015403748 104 2190\n",
      "0.12242472171783447 105 2200\n",
      "Validation:  101.0\n",
      "0.1394151896238327 105 2210\n",
      "0.14077123999595642 104 2220\n",
      "0.12868794798851013 104 2230\n",
      "0.13549795746803284 105 2240\n",
      "0.1420140415430069 105 2250\n",
      "0.13730241358280182 104 2260\n",
      "0.13932639360427856 104 2270\n",
      "0.1406446248292923 105 2280\n",
      "0.1342964470386505 105 2290\n",
      "0.1404239982366562 105 2300\n",
      "Validation:  101.9\n",
      "0.14045953750610352 105 2310\n",
      "0.13926993310451508 104 2320\n",
      "0.13689902424812317 105 2330\n",
      "0.13840751349925995 104 2340\n",
      "0.1343003660440445 105 2350\n",
      "0.12574975192546844 104 2360\n",
      "0.13822393119335175 104 2370\n",
      "0.1320430338382721 105 2380\n",
      "0.1387828141450882 104 2390\n",
      "0.13276265561580658 105 2400\n",
      "Validation:  101.6\n",
      "0.1300683468580246 105 2410\n",
      "0.144090473651886 104 2420\n",
      "0.14501938223838806 105 2430\n",
      "0.1358117312192917 105 2440\n",
      "0.14013773202896118 105 2450\n",
      "0.12880168855190277 104 2460\n",
      "0.13546881079673767 104 2470\n",
      "0.14557810127735138 104 2480\n",
      "0.14373555779457092 106 2490\n",
      "0.14481881260871887 106 2500\n",
      "Validation:  101.3\n",
      "0.134114071726799 104 2510\n",
      "0.137815922498703 104 2520\n",
      "0.12635663151741028 104 2530\n",
      "0.13167130947113037 105 2540\n",
      "0.12956255674362183 105 2550\n",
      "0.13865289092063904 105 2560\n",
      "0.13881680369377136 104 2570\n",
      "0.13182000815868378 104 2580\n",
      "0.12891770899295807 107 2590\n",
      "0.1272868812084198 104 2600\n",
      "Validation:  101.0\n",
      "0.13844497501850128 104 2610\n",
      "0.1228640228509903 104 2620\n",
      "0.13503019511699677 104 2630\n",
      "0.13721995055675507 105 2640\n",
      "0.1422184556722641 105 2650\n",
      "0.1276201456785202 105 2660\n",
      "0.13101239502429962 105 2670\n",
      "0.131275936961174 105 2680\n",
      "0.13416887819766998 104 2690\n",
      "0.13703632354736328 105 2700\n",
      "Validation:  101.9\n",
      "0.12806008756160736 104 2710\n",
      "0.11944359540939331 104 2720\n",
      "0.13539448380470276 104 2730\n",
      "0.12604112923145294 104 2740\n",
      "0.12179867923259735 104 2750\n",
      "0.1284133344888687 104 2760\n",
      "0.11815819889307022 104 2770\n",
      "0.13110549747943878 104 2780\n",
      "0.12663370370864868 104 2790\n",
      "0.13021525740623474 104 2800\n",
      "Validation:  101.8\n",
      "0.1267215758562088 104 2810\n",
      "0.12665680050849915 104 2820\n",
      "0.12393920123577118 104 2830\n",
      "0.12867531180381775 104 2840\n",
      "0.1400768756866455 106 2850\n",
      "0.12567022442817688 104 2860\n",
      "0.13264606893062592 104 2870\n",
      "0.12997432053089142 104 2880\n",
      "0.12596237659454346 104 2890\n",
      "0.1355486959218979 105 2900\n",
      "Validation:  102.0\n",
      "0.12346655875444412 104 2910\n",
      "0.12455744296312332 104 2920\n",
      "0.12608355283737183 104 2930\n",
      "0.11992643028497696 104 2940\n",
      "0.12399384379386902 104 2950\n",
      "0.12381395697593689 104 2960\n",
      "0.123687744140625 104 2970\n",
      "0.12149565666913986 104 2980\n",
      "0.12172136455774307 104 2990\n",
      "0.12964802980422974 104 3000\n",
      "Validation:  101.7\n",
      "0.1240178719162941 104 3010\n",
      "0.12186510860919952 105 3020\n",
      "0.12466134130954742 104 3030\n",
      "0.13259854912757874 104 3040\n",
      "0.1188877522945404 104 3050\n",
      "0.13324910402297974 104 3060\n",
      "0.11992192268371582 104 3070\n",
      "0.11688019335269928 104 3080\n",
      "0.12872672080993652 104 3090\n",
      "0.12269976735115051 104 3100\n",
      "Validation:  101.8\n",
      "0.12151999771595001 104 3110\n",
      "0.11436422914266586 104 3120\n",
      "0.11693817377090454 104 3130\n",
      "0.12569817900657654 104 3140\n",
      "0.12047931551933289 107 3150\n",
      "0.11495373398065567 106 3160\n",
      "0.12830005586147308 104 3170\n",
      "0.1254432499408722 104 3180\n",
      "0.11900197714567184 104 3190\n",
      "0.12394697964191437 104 3200\n",
      "Validation:  102.6\n",
      "0.1273207664489746 105 3210\n",
      "0.12403801083564758 104 3220\n",
      "0.12432009726762772 104 3230\n",
      "0.12376756966114044 104 3240\n",
      "0.1298091858625412 104 3250\n",
      "0.11996888369321823 104 3260\n",
      "0.12173891812562943 104 3270\n",
      "0.11866138130426407 104 3280\n",
      "0.11869208514690399 108 3290\n",
      "0.11624691635370255 107 3300\n",
      "Validation:  103.7\n",
      "0.11457297950983047 104 3310\n",
      "0.12047789245843887 104 3320\n",
      "0.11704208701848984 104 3330\n",
      "0.12533260881900787 105 3340\n",
      "0.1147599145770073 105 3350\n",
      "0.12200024724006653 104 3360\n",
      "0.12243957072496414 104 3370\n",
      "0.11469889432191849 104 3380\n",
      "0.11558321863412857 105 3390\n",
      "0.11950981616973877 105 3400\n",
      "Validation:  101.9\n",
      "0.1255471110343933 113 3410\n",
      "0.11084325611591339 109 3420\n",
      "0.12571798264980316 106 3430\n",
      "0.12300604581832886 104 3440\n",
      "0.1287752091884613 106 3450\n",
      "0.10959997773170471 111 3460\n",
      "0.11493998020887375 104 3470\n",
      "0.11773514747619629 104 3480\n",
      "0.12006281316280365 105 3490\n",
      "0.11700250208377838 110 3500\n",
      "Validation:  102.2\n",
      "0.11941300332546234 105 3510\n",
      "0.11246363818645477 107 3520\n",
      "0.11597730219364166 106 3530\n",
      "0.12244658172130585 108 3540\n",
      "0.12859505414962769 105 3550\n",
      "0.11433769762516022 104 3560\n",
      "0.11531225591897964 104 3570\n",
      "0.11688317358493805 104 3580\n",
      "0.11907807737588882 104 3590\n",
      "0.11627446860074997 105 3600\n",
      "Validation:  101.7\n",
      "0.11233799159526825 104 3610\n",
      "0.11358558386564255 105 3620\n",
      "0.11383655667304993 105 3630\n",
      "0.10470110177993774 105 3640\n",
      "0.11999019980430603 106 3650\n",
      "0.12677250802516937 105 3660\n",
      "0.12452150881290436 104 3670\n",
      "0.11726165562868118 104 3680\n",
      "0.11592701077461243 104 3690\n",
      "0.12841637432575226 104 3700\n",
      "Validation:  102.4\n",
      "0.11973057687282562 107 3710\n",
      "0.11372077465057373 109 3720\n",
      "0.12135529518127441 107 3730\n",
      "0.12783268094062805 107 3740\n",
      "0.12887290120124817 105 3750\n",
      "0.12398001551628113 104 3760\n",
      "0.14397019147872925 105 3770\n",
      "0.11894361674785614 105 3780\n",
      "0.12003998458385468 110 3790\n",
      "0.15097694098949432 107 3800\n",
      "Validation:  102.5\n",
      "0.1339077353477478 106 3810\n",
      "0.12882985174655914 115 3820\n",
      "0.12930962443351746 105 3830\n",
      "0.14205323159694672 108 3840\n",
      "0.1244797557592392 106 3850\n",
      "0.1231103464961052 106 3860\n",
      "0.12985147535800934 107 3870\n",
      "0.17919760942459106 189 3880\n",
      "0.1252528578042984 113 3890\n",
      "0.12072200328111649 106 3900\n",
      "Validation:  103.0\n",
      "0.1213279440999031 105 3910\n",
      "0.11991813778877258 105 3920\n",
      "0.1074519008398056 105 3930\n",
      "0.10922907292842865 107 3940\n",
      "0.11266276240348816 108 3950\n",
      "0.13674290478229523 107 3960\n",
      "0.12215586751699448 113 3970\n",
      "0.11871804296970367 114 3980\n",
      "0.31815215945243835 111 3990\n",
      "0.35401102900505066 114 4000\n",
      "Validation:  107.7\n",
      "0.2649778723716736 105 4010\n",
      "0.2439858615398407 182 4020\n",
      "0.32053619623184204 196 4030\n",
      "0.36589428782463074 183 4040\n",
      "0.3878028690814972 175 4050\n",
      "0.34296444058418274 170 4060\n",
      "0.42122724652290344 200 4070\n",
      "0.5211295485496521 200 4080\n",
      "0.4813117980957031 200 4090\n",
      "0.4662104845046997 200 4100\n",
      "Validation:  195.0\n",
      "0.4592970609664917 200 4110\n",
      "0.4670931398868561 200 4120\n",
      "0.47121647000312805 200 4130\n",
      "0.42973124980926514 200 4140\n",
      "0.44479474425315857 200 4150\n",
      "0.43289923667907715 200 4160\n",
      "0.42588695883750916 200 4170\n",
      "0.4373510181903839 200 4180\n",
      "0.47504815459251404 200 4190\n",
      "0.4325801134109497 200 4200\n",
      "Validation:  184.2\n",
      "0.46102550625801086 200 4210\n",
      "0.48125767707824707 200 4220\n",
      "0.436725914478302 200 4230\n",
      "0.4044418931007385 200 4240\n",
      "0.3561232388019562 197 4250\n",
      "0.4110759496688843 200 4260\n",
      "0.2328227013349533 107 4270\n",
      "0.23092873394489288 111 4280\n",
      "0.2523435652256012 121 4290\n",
      "0.2628488838672638 128 4300\n",
      "Validation:  110.0\n",
      "0.27748358249664307 200 4310\n",
      "0.23572005331516266 121 4320\n",
      "0.21443495154380798 110 4330\n",
      "0.1989467740058899 112 4340\n",
      "0.21087825298309326 111 4350\n",
      "0.20831064879894257 113 4360\n",
      "0.20399035513401031 110 4370\n",
      "0.2175799012184143 109 4380\n",
      "0.2123904973268509 110 4390\n",
      "0.21611976623535156 109 4400\n",
      "Validation:  107.0\n",
      "0.204952210187912 114 4410\n",
      "0.20243243873119354 113 4420\n",
      "0.19898246228694916 112 4430\n",
      "0.1979341208934784 112 4440\n",
      "0.18982769548892975 108 4450\n",
      "0.18389955163002014 108 4460\n",
      "0.18065686523914337 106 4470\n",
      "0.17346085608005524 108 4480\n",
      "0.17573578655719757 107 4490\n",
      "0.18073943257331848 106 4500\n",
      "Validation:  103.2\n",
      "0.16098034381866455 106 4510\n",
      "0.1726248562335968 107 4520\n",
      "0.18018919229507446 110 4530\n",
      "0.16662470996379852 106 4540\n",
      "0.15477091073989868 106 4550\n",
      "0.15582942962646484 105 4560\n",
      "0.1562138944864273 106 4570\n",
      "0.15806125104427338 108 4580\n",
      "0.16260378062725067 110 4590\n",
      "0.1765712946653366 109 4600\n",
      "Validation:  104.4\n",
      "0.18010550737380981 108 4610\n",
      "0.1853903979063034 107 4620\n",
      "0.17522965371608734 108 4630\n",
      "0.16140218079090118 108 4640\n",
      "0.16730831563472748 108 4650\n",
      "0.158065527677536 107 4660\n",
      "0.14852683246135712 107 4670\n",
      "0.1483905166387558 106 4680\n",
      "0.1427762806415558 106 4690\n",
      "0.1428983062505722 106 4700\n",
      "Validation:  103.2\n",
      "0.13656973838806152 105 4710\n",
      "0.14616616070270538 106 4720\n",
      "0.14322800934314728 106 4730\n",
      "0.14477771520614624 108 4740\n",
      "0.14343610405921936 107 4750\n",
      "0.1444014608860016 107 4760\n",
      "0.13443925976753235 107 4770\n",
      "0.13815456628799438 106 4780\n",
      "0.1363724172115326 106 4790\n",
      "0.13070881366729736 105 4800\n",
      "Validation:  103.0\n",
      "0.13358283042907715 105 4810\n",
      "0.13159428536891937 105 4820\n",
      "0.1258096545934677 105 4830\n",
      "0.13648654520511627 104 4840\n",
      "0.14368875324726105 105 4850\n",
      "0.1406349241733551 105 4860\n",
      "0.13868609070777893 105 4870\n",
      "0.14298518002033234 105 4880\n",
      "0.14562220871448517 104 4890\n",
      "0.15082819759845734 105 4900\n",
      "Validation:  102.2\n",
      "0.1465291678905487 105 4910\n",
      "0.14070068299770355 105 4920\n",
      "0.1382427215576172 106 4930\n",
      "0.14595232903957367 105 4940\n",
      "0.1389029622077942 105 4950\n",
      "0.13831041753292084 106 4960\n",
      "0.1396479457616806 105 4970\n",
      "0.14624334871768951 105 4980\n",
      "0.1404198408126831 105 4990\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)#0.00006\n",
    "\n",
    "for i in range(5000):\n",
    "    model.zero_grad()\n",
    "    observation = env.reset(BATCH_SIZE)\n",
    "    state = None\n",
    "    loss = 0\n",
    "    div = 0\n",
    "    for t in range(200):\n",
    "        output, state = model(observation[:,:1].unsqueeze(0), state)\n",
    "        target = teacher(observation)/2\n",
    "        #print(observation[:,:1].unsqueeze(0).shape, output.shape, target.shape)\n",
    "        action = (output.squeeze() > 0) * 2.0\n",
    "        observation, _, done, _ = env.step(action)\n",
    "        loss = loss + (bce(torch.sigmoid(output.squeeze()), target) * (~done).float()).sum()\n",
    "        div = div + (~done).float().sum()\n",
    "        #print(t, loss)\n",
    "        if done.all():\n",
    "            break\n",
    "    loss = loss / div\n",
    "    if i%10 == 0:\n",
    "        print(loss.item(), t+1, i) #, ((outputs>0.5) != targets).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        validate(10)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "mydict = {}\n",
    "\n",
    "def train_batch(inputs, targets, mask):\n",
    "    model.zero_grad()\n",
    "    outputs, _ = model(inputs)\n",
    "    loss = (bce(torch.sigmoid(outputs), targets) * mask).sum() / mask.sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train_dataset(num_batches, num_epochs):\n",
    "    obs, target, mask = make_dataset_simple(num_batches, BATCH_SIZE, MAX_ITER, model, teacher, device, env)\n",
    "    for e in range(num_epochs):\n",
    "        idc = torch.randperm(obs.shape[1], device=device)\n",
    "        for i in range(num_batches):\n",
    "            base = i*BATCH_SIZE\n",
    "            batch_obs = obs[:, idc[base:base + BATCH_SIZE]]\n",
    "            batch_targets = target[:, idc[base:base + BATCH_SIZE]]\n",
    "            batch_mask = mask[:, idc[base:base + BATCH_SIZE]]\n",
    "            #print(batch_obs.shape, batch_targets.shape, batch_mask.shape)\n",
    "            loss = train_batch(batch_obs, batch_targets, batch_mask)\n",
    "        for p in model.parameters():\n",
    "            if torch.isnan(p).any():\n",
    "                raise Exception('Corrupted Model')\n",
    "        print(loss)\n",
    "            #if i%10 == 0:\n",
    "                #print(loss.item(), (loss/targets.view(-1).var()).item(), i)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigstep:  0\n",
      "0.664725124835968\n",
      "0.5898089408874512\n",
      "0.49153774976730347\n",
      "0.6977851390838623\n",
      "0.45482107996940613\n",
      "0.4534326195716858\n",
      "0.44856181740760803\n",
      "0.6130235195159912\n",
      "0.428638756275177\n",
      "0.4103873074054718\n",
      "Validation:  109.3\n",
      "Bigstep:  1\n",
      "0.25005558133125305\n",
      "0.20389588177204132\n",
      "0.18793132901191711\n",
      "0.1697760373353958\n",
      "0.16045846045017242\n",
      "0.14852465689182281\n",
      "0.14243480563163757\n",
      "0.13182225823402405\n",
      "0.13465696573257446\n",
      "0.14020313322544098\n",
      "Validation:  103.3\n",
      "Bigstep:  2\n",
      "0.16003140807151794\n",
      "0.1574556976556778\n",
      "0.15382830798625946\n",
      "0.13881447911262512\n",
      "0.1414133608341217\n",
      "0.14536212384700775\n",
      "0.14187590777873993\n",
      "0.128886878490448\n",
      "0.14120197296142578\n",
      "0.14318718016147614\n",
      "Validation:  103.3\n",
      "Bigstep:  3\n",
      "0.15053102374076843\n",
      "0.1493670642375946\n",
      "0.13940149545669556\n",
      "0.14449100196361542\n",
      "0.14355769753456116\n",
      "0.14049240946769714\n",
      "0.13741865754127502\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-ec9af8b70638>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Bigstep: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mtrain_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0mvalidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-c6f27557d0a7>\u001B[0m in \u001B[0;36mtrain_dataset\u001B[0;34m(num_batches, num_epochs)\u001B[0m\n\u001B[1;32m     20\u001B[0m             \u001B[0mbatch_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0midc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mbase\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mbase\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mBATCH_SIZE\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m             \u001B[0;31m#print(batch_obs.shape, batch_targets.shape, batch_mask.shape)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m             \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_obs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_targets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misnan\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0many\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-c6f27557d0a7>\u001B[0m in \u001B[0;36mtrain_batch\u001B[0;34m(inputs, targets, mask)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mtrain_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mbce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msigmoid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    530\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    531\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 532\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    533\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    534\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/SNN.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, inp, h)\u001B[0m\n\u001B[1;32m     87\u001B[0m         \u001B[0moutput\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mout1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 89\u001B[0;31m             \u001B[0moutput\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minp\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    530\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    531\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 532\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    533\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    534\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/SNN.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, inp, h)\u001B[0m\n\u001B[1;32m     48\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m                     \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m                 \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m'_linear'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m                 \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhi\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midxState\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m                 \u001B[0mnew_state\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    530\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    531\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 532\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    533\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mhook\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    534\u001B[0m             \u001B[0mhook_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 87\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     88\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1368\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbias\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1369\u001B[0m         \u001B[0;31m# fused op is marginally faster\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1370\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maddmm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1371\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1372\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print('Bigstep: ', i)\n",
    "    train_dataset(100, 10)\n",
    "    validate(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  105.0\n"
     ]
    }
   ],
   "source": [
    "validate(1, render=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obs = testenv.reset()\n",
    "state = None\n",
    "for t in range(300):\n",
    "    output, state = model(torch.tensor([[[obs[0]]]], dtype=torch.float), state)\n",
    "    action = 2 if output > 0 else 0\n",
    "    obs, _, done, _ = testenv.step(action)\n",
    "    print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "                    if torch.isnan(p).any():\n",
    "                        raise Exception('Corrupted Model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "teacher(observation)/2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#torch.save(model, '../../models/rsnn_mountaincar')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.input_linear.bias\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "{'out': tensor([[[-0.0653],\n          [ 0.0964],\n          [ 0.1616],\n          ...,\n          [ 0.0449],\n          [ 0.1112],\n          [ 0.0767]],\n \n         [[-0.0532],\n          [-0.1147],\n          [-0.1384],\n          ...,\n          [-0.0960],\n          [-0.1202],\n          [-0.1077]],\n \n         [[-0.0761],\n          [-0.3994],\n          [-0.5322],\n          ...,\n          [-0.2986],\n          [-0.4298],\n          [-0.3611]],\n \n         ...,\n \n         [[-0.9187],\n          [-0.9111],\n          [-0.9117],\n          ...,\n          [-0.9049],\n          [-0.9030],\n          [-0.9077]],\n \n         [[-0.9186],\n          [-0.9110],\n          [-0.9113],\n          ...,\n          [-0.9055],\n          [-0.9033],\n          [-0.9079]],\n \n         [[-0.9185],\n          [-0.9108],\n          [-0.9109],\n          ...,\n          [-0.9060],\n          [-0.9035],\n          [-0.9081]]], grad_fn=<AddBackward0>), 'tar': tensor([[[ 1.0000],\n          [ 0.0000],\n          [ 0.0000],\n          ...,\n          [ 0.0000],\n          [ 0.0000],\n          [ 0.0000]],\n \n         [[ 1.0000],\n          [ 0.0000],\n          [ 0.0000],\n          ...,\n          [ 1.0000],\n          [ 0.0000],\n          [ 0.0000]],\n \n         [[ 1.0000],\n          [ 0.0000],\n          [ 0.0000],\n          ...,\n          [ 1.0000],\n          [ 0.0000],\n          [ 0.0000]],\n \n         ...,\n \n         [[ 0.9741],\n          [ 0.9159],\n          [ 0.9500],\n          ...,\n          [-0.8064],\n          [ 0.8240],\n          [ 0.9782]],\n \n         [[ 0.9501],\n          [ 0.9377],\n          [-0.5010],\n          ...,\n          [ 0.7143],\n          [ 0.9673],\n          [ 0.4398]],\n \n         [[ 0.9753],\n          [ 0.9200],\n          [ 0.9490],\n          ...,\n          [-0.7758],\n          [ 0.8180],\n          [ 0.9781]]])}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mydict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([200, 64, 1])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bce(torch.sigmoid(mydict['out']), mydict['tar']).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict['tar'][110]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}