{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from Code import macroNeurons as Neurons\n",
    "from Code.lstm import lstmPolicyPredictor, FullyConnected\n",
    "from Code.envs.MountainCar import MultiMountainCar, LookupPolicy, PassiveEnv\n",
    "from Code.SNN import RSNN, FeedForwardSNN, magicRSNN, AdaptiveFF, newRSNN\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "class CooldownNeuron(nn.Module):\n",
      "\n",
      "    def __init__(self, params, size):\n",
      "        super(CooldownNeuron, self).__init__()\n",
      "        self.spike_fn = SuperSpike.apply\n",
      "        self.beta = params['BETA']\n",
      "        self.config = params\n",
      "        self.spike_fn = SuperSpike.apply\n",
      "        self.elu = torch.nn.ELU()\n",
      "        self.initial_mem = nn.Parameter(torch.zeros([size]), requires_grad=True)\n",
      "        self.sgn = torch.ones([size], requires_grad=False)\n",
      "        self.sgn[(size // 2):] *= (-(1))\n",
      "        self.size = size\n",
      "\n",
      "    def get_initial_state(self, batch_size):\n",
      "        return {'mem':self.initial_mem.expand([batch_size, self.size])}\n",
      "\n",
      "    def get_initial_output(self, batch_size):\n",
      "        return (self.sgn < 0).float().expand([batch_size, self.size])\n",
      "\n",
      "    def forward(self, x, h):\n",
      "        if (not h):\n",
      "            h = self.get_initial_state(x.shape[0])\n",
      "        new_h = {}\n",
      "        new_h['mem'] = (((self.beta * h['mem']) + self.elu((x - 2))) + 1)\n",
      "        spikes = self.spike_fn((self.sgn * (new_h['mem'] - 1)))\n",
      "        return (spikes, new_h)\n",
      "\n",
      "\n",
      "class LIFNeuron(nn.Module):\n",
      "\n",
      "    def __init__(self, params, size):\n",
      "        super(LIFNeuron, self).__init__()\n",
      "        self.config = params\n",
      "        self.alpha = params['ALPHA']\n",
      "        self.beta = params['BETA']\n",
      "        self.spike_fn = SuperSpike.apply\n",
      "        self.reset_zero = params['RESET_ZERO']\n",
      "        self.initial_mem = nn.Parameter(torch.zeros([size]), requires_grad=True)\n",
      "        self.size = size\n",
      "\n",
      "    def get_initial_state(self, batch_size):\n",
      "        h = {'mem':self.initial_mem.expand([batch_size, self.size])}\n",
      "        h['syn'] = torch.zeros([batch_size, self.size])\n",
      "        return h\n",
      "\n",
      "    def forward(self, x, h):\n",
      "        if (not h):\n",
      "            h = self.get_initial_state(x.shape[0])\n",
      "        new_h = {}\n",
      "        mem = (self.beta * h['mem'])\n",
      "        new_h['syn'] = ((self.alpha * h['syn']) + x)\n",
      "        mem = (mem + new_h['syn'])\n",
      "        spikes = self.spike_fn((mem - 1))\n",
      "        new_h['mem'] = (mem - spikes.detach())\n",
      "        return (spikes, new_h)\n",
      "\n",
      "\n",
      "class OutputNeuron(nn.Module):\n",
      "\n",
      "    def __init__(self, params, size):\n",
      "        super(OutputNeuron, self).__init__()\n",
      "        self.config = params\n",
      "        self.alpha = params['ALPHA']\n",
      "        self.beta = params['BETA']\n",
      "        self.spike_fn = SuperSpike.apply\n",
      "        self.reset_zero = params['RESET_ZERO']\n",
      "        self.initial_mem = nn.Parameter(torch.zeros([size]), requires_grad=True)\n",
      "        self.size = size\n",
      "\n",
      "    def get_initial_state(self, batch_size):\n",
      "        h = {'mem':self.initial_mem.expand([batch_size, self.size])}\n",
      "        h['syn'] = torch.zeros([batch_size, self.size])\n",
      "        return h\n",
      "\n",
      "    def forward(self, x, h):\n",
      "        if (not h):\n",
      "            h = {'mem':torch.zeros_like(x)}\n",
      "            h['mem'] = self.initial_mem.expand(x.shape)\n",
      "            h['syn'] = torch.zeros_like(x)\n",
      "        new_h = {}\n",
      "        new_h['mem'] = (self.beta * h['mem'])\n",
      "        new_h['syn'] = ((self.alpha * h['syn']) + x)\n",
      "        new_h['mem'] = (new_h['mem'] + new_h['syn'])\n",
      "        return (new_h['mem'], new_h)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "config = {\n",
    "    'ALPHA': 0.7,\n",
    "    'BETA': 0.95,\n",
    "    'RESET_ZERO': False,\n",
    "    'THRESH_ADD': 1,\n",
    "    'THRESH_DECAY': 1,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss',\n",
    "    'SIM_TIME': 10\n",
    "}\n",
    "mconfig = {'CooldownNeuron': config,\n",
    "           'LIFNeuron': config,\n",
    "           'OutputNeuron': config}\n",
    "Neurons.set_config(mconfig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "env = PassiveEnv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#model = lstmPolicyPredictor(2,8,16)\n",
    "#model = RSNN(config, 1, 32, 32, 1, Neurons.LIFNeuron, Neurons.AdaptiveNeuron, Neurons.OutputNeuron)\n",
    "#model = magicRSNN(config, 1, 32, 32, 1, Neurons.LIFNeuron, Neurons.MagicNeuron, Neurons.OutputNeuron)\n",
    "#model = FeedForwardSNN(config, [1, 128, 128, 1], Neurons.LIFNeuron, Neurons.OutputNeuron)\n",
    "#model = FullyConnected([1, 128, 128, 1])\n",
    "#model = AdaptiveFF(config, 1, 64, 32, 64, 1, Neurons.LIFNeuron, Neurons.AdaptiveNeuron, Neurons.OutputNeuron)\n",
    "#model = AdaptiveFF(config, 1, 64, 32, 64, 1, Neurons.LIFNeuron, Neurons.FlipFlopNeuron, Neurons.OutputNeuron)\n",
    "#model = RSNN(config, 1, 32, 32, 1, Neurons.LIFNeuron, Neurons.FlipFlopNeuron, Neurons.OutputNeuron)\n",
    "#model = newRSNN(config, 1, 32, 32, 32, 1, Neurons.LIFNeuron, Neurons.FlipFlopNeuron, Neurons.OutputNeuron)\n",
    "model = newRSNN(config, 1, 64, 32, 64, 128, 1, Neurons.LIFNeuron, Neurons.CooldownNeuron, Neurons.OutputNeuron)\n",
    "#model = newRSNN(config, 1, 64, 32, 64, 128, 1, Neurons.CooldownNeuron, Neurons.CooldownNeuron, Neurons.OutputNeuron)\n",
    "\n",
    "\n",
    "teacher = LookupPolicy()\n",
    "\n",
    "\n",
    "#TODO: test superspike instead of Bellec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#inputs, targets, mask = env.getBatch(BATCH_SIZE)\n",
    "#model = torch.jit.trace(model, inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "spikes = torch.ones((13, 1, config['SIM_TIME']))\n",
    "def logger(h, t, i):\n",
    "    if t%10 == 0:\n",
    "        spikes[t//10, 0, i] = h['spikes'][0][:32].sum()\n",
    "        #spikes[t//10, 1, i] = h['spikes'][0][32:].sum()\n",
    "\n",
    "        #print(t, i)\n",
    "        #print(h['spikes'][0].sum())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#bce = nn.BCELoss(reduction='none') #reduction='sum'\n",
    "mse = nn.MSELoss(reduction='none')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)#0.000011e-6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.033898670226335526 61.55609130859375 0\n",
      "0.022605909034609795 42.211151123046875 10\n",
      "44.07919239997864\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "start = time.time()\n",
    "#inputs, targets, mask = env.getBatch(BATCH_SIZE)\n",
    "#model(inputs/0.4, h=None, logger=logger)\n",
    "#print(spikes.squeeze())\n",
    "for i in range(20):\n",
    "    model.zero_grad()\n",
    "    inputs, targets, mask = env.getBatch(BATCH_SIZE)\n",
    "    if i%100 == 0:\n",
    "        # torch.autograd.set_detect_anomaly(False)\n",
    "        for p in model.parameters():\n",
    "            if torch.isnan(p).any():\n",
    "                raise Exception('Corrupted Model')\n",
    "    outputs, _ = model(inputs/0.4)\n",
    "    #print(outputs.shape, targets.shape)\n",
    "    loss = (mse(outputs.squeeze(dim=2)/50, targets) * mask).sum() / mask.sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #if i%100 == 0:\n",
    "    #    torch.autograd.set_detect_anomaly(False)\n",
    "    if i%10 == 0:\n",
    "        print(loss.item(), (loss/targets.view(-1).var()).item(), i) #, ((outputs>0.5) != targets).sum()\n",
    "    #if i%50 == 0:\n",
    "    #    model(inputs/0.4, h=None, logger=logger)\n",
    "    #    print(spikes.squeeze())\n",
    "print(time.time()-start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[ 0.0886,  0.0034,  0.0122,  ..., -0.1079, -0.0454,  0.1268],\n        [ 0.0730, -0.1046, -0.0994,  ...,  0.0973,  0.0527, -0.0051],\n        [ 0.1256, -0.0232,  0.0665,  ..., -0.0530, -0.1733, -0.0602],\n        ...,\n        [ 0.0011, -0.0089, -0.0370,  ..., -0.0695,  0.0889,  0.1279],\n        [ 0.0916,  0.1379, -0.0358,  ...,  0.0395, -0.0350, -0.0625],\n        [ 0.1300, -0.0407, -0.0327,  ...,  0.0911,  0.0870,  0.1360]],\n       requires_grad=True)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "model.adaptive_linear.weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#torch.save(model, '../models/lstm_passive')\n",
    "#0.0002"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#torch.save(model, '../models/withalpha_006')\n",
    "#0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#model = torch.load('../models/snn_passive3')\n",
    "%matplotlib\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def doplot():\n",
    "    inputs, targets, mask = env.getBatch(1)\n",
    "    outputs, _ = model(inputs/0.4)\n",
    "    plt.close()\n",
    "    plt.plot(inputs[:, 0, 0], targets)\n",
    "    plt.plot(inputs[:, 0, 0], outputs.squeeze().detach()/50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "doplot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.0204, -0.0907,  0.0328,  0.0208, -0.0162, -0.0155, -0.0051,  0.0004,\n",
      "        -0.0103,  0.0376,  0.0286,  0.0266,  0.0085,  0.0174, -0.0050,  0.1202,\n",
      "         0.0269, -0.0510, -0.0024,  0.0244, -0.0004, -0.0123,  0.0150,  0.0328,\n",
      "        -0.0040, -0.0520, -0.0198,  0.0324, -0.0129, -0.0187,  0.0372, -0.0176,\n",
      "        -0.0086, -0.0481,  0.0040,  0.0074, -0.0169,  0.0119, -0.0310,  0.0245,\n",
      "        -0.0128, -0.0212, -0.0158,  0.0223,  0.0099,  0.0035,  0.0097, -0.0083,\n",
      "         0.0372, -0.0129, -0.0219, -0.0241,  0.0306,  0.0258,  0.0064,  0.0308,\n",
      "         0.0259, -0.0114,  0.0161,  0.0028,  0.0459,  0.0226,  0.0388, -0.0146],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0074, -0.0094, -0.0251, -0.0063, -0.0061, -0.0195,  0.0115, -0.0146,\n",
      "         0.0162, -0.0154, -0.0255, -0.0009,  0.0177,  0.0074, -0.0161, -0.0006,\n",
      "        -0.0131, -0.0003, -0.0208, -0.0075, -0.0098, -0.0122, -0.0198,  0.0032,\n",
      "        -0.0114, -0.0136, -0.0323, -0.0263, -0.0131, -0.0013, -0.0063, -0.0095],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0086,  0.0038, -0.0722,  0.0514,  0.0448,  0.0004,  0.0102,  0.0109,\n",
      "         0.0827, -0.0516, -0.0541,  0.0113,  0.0011,  0.0250,  0.0646, -0.0155,\n",
      "        -0.0066, -0.0179, -0.0136,  0.1166,  0.0285,  0.0690, -0.0586,  0.0283,\n",
      "         0.0331, -0.0099,  0.1420, -0.0088, -0.0309,  0.0033,  0.0457, -0.0063,\n",
      "        -0.0321,  0.0072, -0.0284,  0.0085,  0.0059, -0.0072, -0.0111, -0.0217,\n",
      "         0.1008, -0.0124, -0.0602, -0.0193, -0.0877,  0.1068,  0.0182,  0.0154,\n",
      "         0.0114,  0.0209, -0.0245, -0.0123, -0.0729,  0.0963, -0.0548, -0.0132,\n",
      "        -0.0087, -0.0116,  0.0048, -0.0077, -0.0051, -0.0356, -0.0207, -0.0086],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0642, -0.0772,  0.1420,  ..., -0.0075,  0.1457, -0.1103],\n",
      "        [-0.1767, -0.0856,  0.0043,  ...,  0.0192, -0.0569,  0.0871],\n",
      "        [-0.0482,  0.1303, -0.1850,  ...,  0.1084,  0.1235,  0.1655],\n",
      "        ...,\n",
      "        [ 0.1077, -0.1999,  0.2315,  ..., -0.0810, -0.0779,  0.0600],\n",
      "        [ 0.1961,  0.0942,  0.0202,  ...,  0.1027,  0.0879,  0.0405],\n",
      "        [-0.0646, -0.1469,  0.1364,  ..., -0.1435,  0.0701,  0.0051]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1377, -0.0960,  0.0776, -0.1205, -0.1951, -0.1009,  0.1901,  0.1219,\n",
      "        -0.0382,  0.1757,  0.0931,  0.0397, -0.0349,  0.1460, -0.1592,  0.0893,\n",
      "         0.0148,  0.1013,  0.0587,  0.0153,  0.1441, -0.0109, -0.0892,  0.1708,\n",
      "         0.0186,  0.0644,  0.0991, -0.0244,  0.0078,  0.0842, -0.0185,  0.0008,\n",
      "        -0.0093, -0.0418,  0.1900,  0.0184,  0.0085,  0.1963, -0.0942,  0.0746,\n",
      "        -0.0081,  0.0839, -0.0420,  0.0599,  0.0691, -0.1358,  0.1825, -0.0448,\n",
      "        -0.1622,  0.1312, -0.1178,  0.1440,  0.1664,  0.0792, -0.0208,  0.0879,\n",
      "        -0.0158, -0.0127, -0.1103, -0.1134,  0.1183,  0.0651,  0.0761,  0.0058],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0886,  0.0034,  0.0122,  ..., -0.1079, -0.0454,  0.1268],\n",
      "        [ 0.0730, -0.1046, -0.0994,  ...,  0.0973,  0.0527, -0.0051],\n",
      "        [ 0.1256, -0.0232,  0.0665,  ..., -0.0530, -0.1733, -0.0602],\n",
      "        ...,\n",
      "        [ 0.0011, -0.0089, -0.0370,  ..., -0.0695,  0.0889,  0.1279],\n",
      "        [ 0.0916,  0.1379, -0.0358,  ...,  0.0395, -0.0350, -0.0625],\n",
      "        [ 0.1300, -0.0407, -0.0327,  ...,  0.0911,  0.0870,  0.1360]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0636, -0.0434,  0.0266, -0.0540,  0.0325, -0.0415,  0.0583, -0.1036,\n",
      "         0.0437,  0.0840, -0.1201,  0.0834,  0.0178,  0.0641, -0.0706,  0.0812,\n",
      "         0.0688, -0.0116,  0.0370,  0.0160,  0.0313,  0.0939, -0.1480, -0.0582,\n",
      "        -0.0359,  0.0228,  0.0372,  0.0351, -0.0540,  0.0700,  0.0260,  0.0293],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1406, -0.1391,  0.0123,  ..., -0.1512,  0.0328, -0.2094],\n",
      "        [-0.1112, -0.0456, -0.0208,  ...,  0.0840,  0.0858,  0.0160],\n",
      "        [-0.2327,  0.0584,  0.0415,  ...,  0.1911,  0.1670,  0.1402],\n",
      "        ...,\n",
      "        [-0.0286, -0.1827, -0.1879,  ...,  0.1035,  0.0478, -0.0081],\n",
      "        [-0.2063, -0.0834, -0.1318,  ...,  0.1468, -0.1114, -0.0128],\n",
      "        [ 0.0290,  0.0750,  0.1612,  ..., -0.0992, -0.0561,  0.1111]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1359,  0.1897, -0.0088, -0.0577, -0.0285,  0.1160, -0.0373, -0.1781,\n",
      "        -0.0553, -0.0510,  0.0122,  0.0062,  0.0084, -0.0877,  0.0615,  0.0232,\n",
      "         0.0061, -0.0778, -0.1006, -0.0817,  0.0687,  0.0579,  0.0584, -0.0980,\n",
      "         0.0380, -0.1808, -0.1236, -0.0578,  0.1171,  0.0093,  0.1323, -0.0918,\n",
      "        -0.0764, -0.0476, -0.0693,  0.1344, -0.0188,  0.0661, -0.0336,  0.0345,\n",
      "        -0.1329,  0.0245,  0.1143, -0.0202, -0.1521,  0.1325,  0.1718,  0.0509,\n",
      "         0.1619,  0.1218, -0.0659, -0.1095,  0.1395,  0.1473,  0.1701,  0.0637,\n",
      "        -0.1799,  0.1694,  0.0114, -0.1408, -0.0297,  0.0799, -0.1315, -0.0919],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0940, -0.1071,  0.0313, -0.0725,  0.1006, -0.1137, -0.0765, -0.0470,\n",
      "         -0.1122,  0.0299,  0.1287,  0.0769,  0.1479, -0.0436, -0.0847,  0.1484,\n",
      "          0.0089, -0.1472,  0.1441, -0.1392,  0.0161,  0.0937,  0.1106, -0.0885,\n",
      "         -0.0369, -0.0518, -0.1496, -0.0350, -0.1148,  0.0107, -0.0976,  0.0916,\n",
      "          0.1255, -0.1164,  0.0329,  0.0535, -0.0515,  0.1147,  0.1183,  0.1480,\n",
      "         -0.1588,  0.1205,  0.1174, -0.0475,  0.0953, -0.1148, -0.0425, -0.0655,\n",
      "         -0.0780, -0.1078, -0.1128,  0.1037,  0.1113,  0.0870, -0.1063,  0.0365,\n",
      "         -0.0456,  0.1523,  0.0785,  0.1133, -0.0905, -0.0433,  0.1257,  0.1299]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0154], requires_grad=True)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([-0.0204, -0.0907,  0.0328,  0.0208, -0.0162, -0.0155, -0.0051,  0.0004,\n        -0.0103,  0.0376,  0.0286,  0.0266,  0.0085,  0.0174, -0.0050,  0.1202,\n         0.0269, -0.0510, -0.0024,  0.0244, -0.0004, -0.0123,  0.0150,  0.0328,\n        -0.0040, -0.0520, -0.0198,  0.0324, -0.0129, -0.0187,  0.0372, -0.0176,\n        -0.0086, -0.0481,  0.0040,  0.0074, -0.0169,  0.0119, -0.0310,  0.0245,\n        -0.0128, -0.0212, -0.0158,  0.0223,  0.0099,  0.0035,  0.0097, -0.0083,\n         0.0372, -0.0129, -0.0219, -0.0241,  0.0306,  0.0258,  0.0064,  0.0308,\n         0.0259, -0.0114,  0.0161,  0.0028,  0.0459,  0.0226,  0.0388, -0.0146],\n       requires_grad=True)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "model.parameters().__next__()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#model(inputs/0.4)[0].squeeze()\n",
    "model.zero_grad()\n",
    "inputs, targets, mask = env.getBatch(1)\n",
    "outputs = model(inputs/0.4)\n",
    "loss = (mse(outputs.squeeze(dim=2)/30, targets) * mask).sum() / mask.sum()\n",
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 25
    }
   ],
   "source": [
    "teacher(torch.cat((torch.zeros([20, 1]), torch.linspace(-0.07, 0, 20).unsqueeze(1)), dim=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0000, -0.0700],\n        [ 0.0000, -0.0663],\n        [ 0.0000, -0.0626],\n        [ 0.0000, -0.0589],\n        [ 0.0000, -0.0553],\n        [ 0.0000, -0.0516],\n        [ 0.0000, -0.0479],\n        [ 0.0000, -0.0442],\n        [ 0.0000, -0.0405],\n        [ 0.0000, -0.0368],\n        [ 0.0000, -0.0332],\n        [ 0.0000, -0.0295],\n        [ 0.0000, -0.0258],\n        [ 0.0000, -0.0221],\n        [ 0.0000, -0.0184],\n        [ 0.0000, -0.0147],\n        [ 0.0000, -0.0111],\n        [ 0.0000, -0.0074],\n        [ 0.0000, -0.0037],\n        [ 0.0000,  0.0000]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 28
    }
   ],
   "source": [
    "torch.cat((torch.zeros([20, 1]), torch.linspace(-0.07, 0, 20).unsqueeze(1)), dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2.)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 35
    }
   ],
   "source": [
    "teacher(torch.tensor([0, -0.052]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "FullyConnected(\n  (layers): ModuleList(\n    (0): Linear(in_features=1, out_features=128, bias=True)\n    (1): Linear(in_features=128, out_features=128, bias=True)\n    (2): Linear(in_features=128, out_features=1, bias=True)\n  )\n)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  _0 = getattr(self.layers, \"2\")\n",
      "  _1 = getattr(self.layers, \"1\")\n",
      "  _2 = getattr(self.layers, \"0\")\n",
      "  out = torch.zeros([1], dtype=6, layout=0, device=torch.device(\"cpu\"), pin_memory=False)\n",
      "  input0 = torch.relu((_2).forward(input, ))\n",
      "  input1 = torch.relu((_1).forward(input0, ))\n",
      "  out0 = torch.add(out, (_0).forward(input1, ), alpha=1)\n",
      "  input2 = torch.relu((_2).forward1(input, ))\n",
      "  input3 = torch.relu((_1).forward1(input2, ))\n",
      "  out1 = torch.add(out0, (_0).forward1(input3, ), alpha=1)\n",
      "  input4 = torch.relu((_2).forward2(input, ))\n",
      "  input5 = torch.relu((_1).forward2(input4, ))\n",
      "  out2 = torch.add(out1, (_0).forward2(input5, ), alpha=1)\n",
      "  input6 = torch.relu((_2).forward3(input, ))\n",
      "  input7 = torch.relu((_1).forward3(input6, ))\n",
      "  out3 = torch.add(out2, (_0).forward3(input7, ), alpha=1)\n",
      "  input8 = torch.relu((_2).forward4(input, ))\n",
      "  input9 = torch.relu((_1).forward4(input8, ))\n",
      "  out4 = torch.add(out3, (_0).forward4(input9, ), alpha=1)\n",
      "  input10 = torch.relu((_2).forward5(input, ))\n",
      "  input11 = torch.relu((_1).forward5(input10, ))\n",
      "  out5 = torch.add(out4, (_0).forward5(input11, ), alpha=1)\n",
      "  input12 = torch.relu((_2).forward6(input, ))\n",
      "  input13 = torch.relu((_1).forward6(input12, ))\n",
      "  out6 = torch.add(out5, (_0).forward6(input13, ), alpha=1)\n",
      "  input14 = torch.relu((_2).forward7(input, ))\n",
      "  input15 = torch.relu((_1).forward7(input14, ))\n",
      "  out7 = torch.add(out6, (_0).forward7(input15, ), alpha=1)\n",
      "  input16 = torch.relu((_2).forward8(input, ))\n",
      "  input17 = torch.relu((_1).forward8(input16, ))\n",
      "  out8 = torch.add(out7, (_0).forward8(input17, ), alpha=1)\n",
      "  input18 = torch.relu((_2).forward9(input, ))\n",
      "  input19 = torch.relu((_1).forward9(input18, ))\n",
      "  _3 = torch.add(out8, (_0).forward9(input19, ), alpha=1)\n",
      "  return _3\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "print(model.code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "torch.set_printoptions(profile='default')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}