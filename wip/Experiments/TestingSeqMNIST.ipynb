{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from Code.Networks import OuterWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "USE_JIT = False\n",
    "\n",
    "device = torch.device('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "test = MNIST('../../', transform=transforms.ToTensor(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(test, batch_size=1024, drop_last=False, num_workers=0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model_name = 'big6'\n",
    "n_models = 19"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:563: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: tensor(0.9138, device='cuda:0')\n",
      "Model 1: tensor(0.9128, device='cuda:0')\n",
      "Model 2: tensor(0.9148, device='cuda:0')\n",
      "Model 3: tensor(0.9124, device='cuda:0')\n",
      "Model 4: tensor(0.9136, device='cuda:0')\n",
      "Model 5: tensor(0.9151, device='cuda:0')\n",
      "Model 6: tensor(0.9139, device='cuda:0')\n",
      "Model 7: tensor(0.9146, device='cuda:0')\n",
      "Model 8: tensor(0.9150, device='cuda:0')\n",
      "Model 9: tensor(0.9123, device='cuda:0')\n",
      "Model 10: tensor(0.9135, device='cuda:0')\n",
      "Model 11: tensor(0.9155, device='cuda:0')\n",
      "Model 12: tensor(0.9150, device='cuda:0')\n",
      "Model 13: tensor(0.9140, device='cuda:0')\n",
      "Model 14: tensor(0.9156, device='cuda:0')\n",
      "Model 15: tensor(0.9158, device='cuda:0')\n",
      "Model 16: tensor(0.9131, device='cuda:0')\n",
      "Model 17: tensor(0.9148, device='cuda:0')\n",
      "Model 18: tensor(0.9147, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for m in range(n_models):\n",
    "        mem_model = OuterWrapper(torch.load('../../models/mem_'+model_name+'_'+str(m)), device, USE_JIT)\n",
    "        post_model = OuterWrapper(torch.load('../../models/post_'+model_name+'_'+str(m)), device, USE_JIT)\n",
    "        confusion = torch.zeros([10,10])\n",
    "        i = 0\n",
    "        acc = 0\n",
    "        for inp, target in test_loader:\n",
    "            x = inp.view(inp.shape[0], -1, 1).transpose(0,1).to(device)\n",
    "            target = target.to(device)\n",
    "            mem, _ = mem_model(x)\n",
    "            outputs, _ = post_model(mem[-1].expand(56, x.shape[1], 256))\n",
    "            choice = torch.argmax(outputs.mean(dim=0), 1)\n",
    "            acc += (choice == target).float().mean()\n",
    "            i += 1\n",
    "            for k in range(len(target)):\n",
    "                confusion[choice[k], target[k]] += 1\n",
    "        print('Model '+str(m)+': '+str(acc/i))\n",
    "#print(confusion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "max = confusion.max().item()\n",
    "from PIL import Image\n",
    "img = Image.new('L',(10,10),color=128)\n",
    "for i in range(10):\n",
    "    for k in range(10):\n",
    "        img.putpixel((i, k), int(confusion[i,k]/max*255))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=500x500 at 0x7FF84EAF1B00>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAH0CAAAAADuvYBWAAAFXElEQVR4nO3dwWlVYRhFUWNCJvYgCOLQsVZhJxZjG/bhPA5VsAlBUDTWcK7k+nCvNT/kvez3j7+rL49Wz+fF/+JqXtw/wKf4e4//9QfgfKIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQfuxggPXCg78ER6Qlx4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR50ytGFu3nxal58nxc38+J6XvyYF3uQ3/PCSw8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA865bLD7bx4Py/ezIsX8+LTvLjMN3WZn4oHJXqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4kedMplhzPsVxf2yw6X6XpeeOlBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBBy477JPbefF0XnyeF+/mxdt5cTMv7ufFr3nhpQeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogedctnhybz4Ni8OfJHZh3nxel7s32O/BeGlB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiBx04iLD/TvbbA7v9b5xxQ+HrvHg2L67nhZceJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4kedOCywxkXEfZrBb/mxe7AP2t2Ny9ezgsvPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPehCLzvsv8X9FsTPebHb/1f79/g4L7z0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0oD9K3h69MbMnJgAAAABJRU5ErkJggg==\n"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.resize((500, 500))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "testi = MNIST('../../', train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "show = []\n",
    "schoice = []\n",
    "starget = []\n",
    "for img, target in testi:\n",
    "    x = transforms.ToTensor()(img).view(-1, 1, 1).to(device)\n",
    "    mem, _ = mem_model(x)\n",
    "    outputs, _ = post_model(mem[-1].expand(56, 1, 256))\n",
    "    choice = torch.argmax(outputs.mean(dim=0), 1).item()\n",
    "    if choice != target:\n",
    "        show.append(img)\n",
    "        schoice.append(choice)\n",
    "        starget.append(target)\n",
    "        if len(show) == 10:\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=500x500 at 0x7FF84EA884A8>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAH0CAAAAADuvYBWAAAFW0lEQVR4nO3dwatmcxzH8UuTsCDUtRsSKZJRs56ljVkospIFoiyHhQ0b/A2sZanwH5gUCxsWsjAySBYWREhpsrE63zJPT891z33er9fy07nub3r77U7nHhwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAe+Ka4z4A/7p+LC+O5d7l8NRWv+rarX6KE030INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPejUcR8g4fGx3DaWZ8Zy+1he2s1x3PQg0YNEDxI9SPQg0YNEDxI9SPQg0YNEDxI9SPQg0YNEDxI9SPQg35z5T7eO5XA5vDYeOTuWW8by91jm52N+GcvHY9mKmx4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR6UeXPmobHcPJaHx/LC1X/qynjknbG8NZYvxjJeyTm4NJYdcdODRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDTuKbM08vhwvjkfnPOj2WG7f65R8th9fHI5+P5aetftWRcdODRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0oFPHfYAtnFsO88/rzJcofhvLu2P5YCzvb3qmE8VNDxI9SPQg0YNEDxI9SPQg0YNEDxI9SPQg0YNEDxI9SPQg0YNED1r/50fuHsuZ5XDPeOTtDf7DP2xzmr3gpgeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBoget7Zsz94/lsbFcXg4fjke6b8Vswk0PEj1I9CDRg0QPEj1I9CDRg0QPEj1I9CDRg0QPEj1I9CDRg0QPWtubM/eN5fxYnlsOnx3JUfaXmx4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR60tr/WdNNYvhnLdcvhzHjk692cZk+56UGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EFr++bM4Vg+Gcsjy+G98cjPY3l2LF9tfKh946YHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHiR4kepDoQaIHre2bM9OdY7nj6j/08li+HMuFbU6zF9z0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPWhtnx+ZLm+wDE+M5dxYbhjLn5ucZw+46UGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EHr//zIVq6M5fuxPDCWX4/kLOvjpgeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBoget/5szO/LKWP44hlOsg5seJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4keJHqQ6EGiB4ketKffnLk0lgfH8vv/cZBVctODRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDTuI3Zw6Xw5vjkbvGcnYsF3d0nJPHTQ8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA9a/5sz83/L55fDo+OR78by7W5Osxfc9CDRg0QPEj1I9CDRg0QPEj1I9CDRg0QPEj1I9CDRg0QPEj1I9KD1/7Wm8YWZgx+Xw6fjkSfHMv9+U5ebHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBogeJHiR6kOhBoget/yWK+YGUV5fDG+ORv47mLHvCTQ8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRA8SPUj0INGDRAcAAAAAAAAAAAAAAAAAAAAAgD32D11lNzM0OYCKAAAAAElFTkSuQmCC\n"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show[7].resize((500,500))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 8, 5, 6, 6, 5, 7, 7, 5]\n",
      "[5, 5, 3, 3, 3, 2, 3, 5, 9, 3]\n"
     ]
    }
   ],
   "source": [
    "print(schoice)\n",
    "print(starget)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.named_parameters at 0x7f73a476be60>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_model.model.model.layers.shortterm_synapse.named_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.pre_mem_synapse.weight torch.Size([128, 193])\n",
      "model.layers.pre_mem_synapse.bias torch.Size([128])\n",
      "model.layers.pre_mem.initial_mem torch.Size([128])\n",
      "model.layers.shortterm_synapse.weight torch.Size([64, 128])\n",
      "model.layers.shortterm_synapse.bias torch.Size([64])\n",
      "model.layers.shortterm.initial_mem torch.Size([64])\n",
      "model.layers.output_synapse.weight torch.Size([128, 128])\n",
      "model.layers.output_synapse.bias torch.Size([128])\n",
      "model.layers.output.initial_mem torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for name, p in n_mem.named_parameters():\n",
    "    print(name, p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.pre_mem_synapse.weight torch.Size([128, 129])\n",
      "model.layers.pre_mem_synapse.bias torch.Size([128])\n",
      "model.layers.pre_mem.initial_mem torch.Size([128])\n",
      "model.layers.output_synapse.weight torch.Size([128, 128])\n",
      "model.layers.output_synapse.bias torch.Size([128])\n",
      "model.layers.output.initial_mem torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for name, p in mem_model2.named_parameters():\n",
    "    print(name, p.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "mem_model2 = torch.load('../../models/mem_nores3_76')\n",
    "n_mem = make_SequenceWrapper(DynNetwork(mem_loop), USE_JIT)\n",
    "with torch.no_grad():\n",
    "    n_mem.model.layers.output_synapse.weight = mem_model2.model.layers.output_synapse.weight\n",
    "    n_mem.model.layers.output_synapse.bias = mem_model2.model.layers.output_synapse.bias\n",
    "    n_mem.model.layers.output.initial_mem = mem_model2.model.layers.output.initial_mem\n",
    "    n_mem.model.layers.pre_mem_synapse.bias = mem_model2.model.layers.pre_mem_synapse.bias\n",
    "    n_mem.model.layers.pre_mem.initial_mem = mem_model2.model.layers.pre_mem.initial_mem\n",
    "    n_mem.model.layers.pre_mem_synapse.weight[:, :129] = mem_model2.model.layers.pre_mem_synapse.weight"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n        1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9, 0, 4, 6, 7, 4, 6, 8, 0,\n        7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,\n        2, 0, 2, 7, 1, 8, 6, 4])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.__iter__().__next__()[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}