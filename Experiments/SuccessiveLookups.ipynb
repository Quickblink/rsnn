{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from Code.envs.statemachine import SuccessiveLookups\n",
    "from Code.train import train, OptWrapper\n",
    "from Code.everything5 import build_standard_model\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "MAIN_DECAY = np.exp(-1/(20)*0.5)\n",
    "ADAP_DECAY = np.exp(-1/(20*2))\n",
    "\n",
    "spec = {\n",
    "    'control_config': {\n",
    "        'neuron_type': 'LIF',\n",
    "        'n_neurons': 100,\n",
    "        'BETA': 0.8,\n",
    "        '1-beta': 'improved',\n",
    "        'SPIKE_FN': 'bellec'\n",
    "    },\n",
    "    'mem_config': {\n",
    "        'neuron_type': 'FlipFlop',\n",
    "        'n_neurons': 20,\n",
    "        'BETA': 0.8,\n",
    "        '1-beta': 'improved',\n",
    "        'SPIKE_FN': 'bellec',\n",
    "        'ADAPSCALE': 30,\n",
    "        'ADAPDECAY': None, #TODO: set this\n",
    "        'OFFSET': None,\n",
    "        'DECAY': MAIN_DECAY\n",
    "    },\n",
    "    'exp_config': {\n",
    "        'n_sequence': 30,\n",
    "        'val_sequence': 100,\n",
    "        'round_length': 20\n",
    "    },\n",
    "    'lr': 0.001,\n",
    "    'lr_decay': 1,\n",
    "    'iterations': 5000,\n",
    "    'batch_size': 64,\n",
    "    'architecture': '1L'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "\n",
    "train_problem = SuccessiveLookups(spec['iterations'], spec['batch_size'], spec['exp_config']['n_sequence'],\n",
    "                               spec['exp_config']['round_length'], DEVICE)\n",
    "val_problem = SuccessiveLookups(1, spec['batch_size'], spec['exp_config']['val_sequence'],\n",
    "                               spec['exp_config']['round_length'], DEVICE)\n",
    "\n",
    "\n",
    "n_in, n_out, input_rate = train_problem.get_infos()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'control': [[('input', 1), ('control', 1), ('mem', 1)], LIFNeuron(), <class 'torch.nn.modules.linear.Linear'>], 'mem': [[('input', 1), ('control', 1), ('mem', 1)], NewFlipFlop(\n",
      "  (lif_on): LIFNeuron()\n",
      "  (lif_off): LIFNeuron()\n",
      "), <class 'torch.nn.modules.linear.Linear'>], 'output': [[('control', 1), ('mem', 1)], BaseNeuron(), None]}\n"
     ]
    },
    {
     "data": {
      "text/plain": "OuterWrapper(\n  (model): DynNetwork(\n    (layers): ModuleDict(\n      (loop): SequenceWrapper(\n        (model): ParallelNetwork2(\n          (layers): ModuleDict(\n            (control): LIFNeuron()\n            (control_synapse): Linear(in_features=148, out_features=100, bias=True)\n            (mem): NewFlipFlop(\n              (lif_on): LIFNeuron()\n              (lif_off): LIFNeuron()\n            )\n            (mem_synapse): Linear(in_features=148, out_features=20, bias=True)\n            (output): BaseNeuron()\n          )\n        )\n      )\n      (output_synapse): Linear(in_features=120, out_features=8, bias=True)\n      (output): BaseNeuron()\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_standard_model(spec, n_in, input_rate, n_out)\n",
    "model.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "optimizer = OptWrapper(model.parameters(), spec['lr'], spec['lr_decay'], 2500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.1284722238779068 Time per it: 4.824\n",
      "It:   19 Loss: 2.082 Acc: 12.46%\n",
      "It:   39 Loss: 2.078 Acc: 13.56%\n",
      "It:   59 Loss: 2.075 Acc: 14.79%\n",
      "It:   79 Loss: 2.052 Acc: 17.23%\n",
      "It:   99 Loss: 2.037 Acc: 17.29%\n",
      "Val Acc: 0.24021464586257935 Time per it: 2.020\n",
      "It:  119 Loss: 2.013 Acc: 19.57%\n",
      "It:  139 Loss: 1.991 Acc: 20.25%\n",
      "It:  159 Loss: 1.929 Acc: 23.79%\n",
      "It:  179 Loss: 1.985 Acc: 19.15%\n",
      "It:  199 Loss: 1.953 Acc: 20.91%\n",
      "Val Acc: 0.1974431872367859 Time per it: 2.013\n",
      "It:  219 Loss: 2.010 Acc: 19.84%\n",
      "It:  239 Loss: 1.930 Acc: 24.84%\n",
      "It:  259 Loss: 1.866 Acc: 27.68%\n",
      "It:  279 Loss: 1.872 Acc: 27.68%\n",
      "It:  299 Loss: 1.852 Acc: 28.14%\n",
      "Val Acc: 0.26799243688583374 Time per it: 2.065\n",
      "It:  319 Loss: 1.838 Acc: 27.83%\n",
      "It:  339 Loss: 1.798 Acc: 29.75%\n",
      "It:  359 Loss: 1.755 Acc: 32.61%\n",
      "It:  379 Loss: 1.746 Acc: 32.13%\n",
      "It:  399 Loss: 1.830 Acc: 29.34%\n",
      "Val Acc: 0.27320075035095215 Time per it: 2.083\n",
      "It:  419 Loss: 1.867 Acc: 28.54%\n",
      "It:  439 Loss: 1.837 Acc: 29.01%\n",
      "It:  459 Loss: 1.776 Acc: 31.90%\n",
      "It:  479 Loss: 1.744 Acc: 32.87%\n",
      "It:  499 Loss: 1.719 Acc: 33.97%\n",
      "Val Acc: 0.34359216690063477 Time per it: 2.074\n",
      "It:  519 Loss: 1.716 Acc: 33.24%\n",
      "It:  539 Loss: 1.660 Acc: 34.82%\n",
      "It:  559 Loss: 1.614 Acc: 36.71%\n",
      "It:  579 Loss: 1.623 Acc: 36.17%\n",
      "It:  599 Loss: 1.641 Acc: 36.62%\n",
      "Val Acc: 0.36000630259513855 Time per it: 2.079\n",
      "It:  619 Loss: 1.645 Acc: 37.28%\n",
      "It:  639 Loss: 1.595 Acc: 38.46%\n",
      "It:  659 Loss: 1.559 Acc: 39.68%\n",
      "It:  679 Loss: 1.577 Acc: 39.89%\n",
      "It:  699 Loss: 1.594 Acc: 39.57%\n",
      "Val Acc: 0.37831440567970276 Time per it: 1.990\n",
      "It:  719 Loss: 1.627 Acc: 38.32%\n",
      "It:  739 Loss: 1.587 Acc: 39.50%\n",
      "It:  759 Loss: 1.599 Acc: 40.19%\n",
      "It:  779 Loss: 1.602 Acc: 41.39%\n",
      "It:  799 Loss: 1.571 Acc: 42.01%\n",
      "Val Acc: 0.42945075035095215 Time per it: 1.988\n",
      "It:  819 Loss: 1.558 Acc: 42.55%\n",
      "It:  839 Loss: 1.497 Acc: 45.45%\n",
      "It:  859 Loss: 1.467 Acc: 46.41%\n",
      "It:  879 Loss: 1.445 Acc: 47.11%\n",
      "It:  899 Loss: 1.442 Acc: 46.78%\n",
      "Val Acc: 0.45849114656448364 Time per it: 2.029\n",
      "It:  919 Loss: 1.439 Acc: 47.25%\n",
      "It:  939 Loss: 1.449 Acc: 46.24%\n",
      "It:  959 Loss: 1.447 Acc: 46.18%\n",
      "It:  979 Loss: 1.443 Acc: 46.07%\n",
      "It:  999 Loss: 1.399 Acc: 47.99%\n",
      "Val Acc: 0.4717487394809723 Time per it: 2.071\n",
      "It: 1019 Loss: 1.404 Acc: 47.66%\n",
      "It: 1039 Loss: 1.364 Acc: 48.87%\n",
      "It: 1059 Loss: 1.339 Acc: 49.52%\n",
      "It: 1079 Loss: 1.324 Acc: 50.40%\n",
      "It: 1099 Loss: 1.305 Acc: 51.40%\n",
      "Val Acc: 0.5115214586257935 Time per it: 2.093\n",
      "It: 1119 Loss: 1.296 Acc: 51.47%\n",
      "It: 1139 Loss: 1.286 Acc: 51.99%\n",
      "It: 1159 Loss: 1.277 Acc: 52.97%\n",
      "It: 1179 Loss: 1.257 Acc: 53.52%\n",
      "It: 1199 Loss: 1.247 Acc: 53.91%\n",
      "Val Acc: 0.5604482293128967 Time per it: 2.086\n",
      "It: 1219 Loss: 1.225 Acc: 55.38%\n",
      "It: 1239 Loss: 1.210 Acc: 56.10%\n",
      "It: 1259 Loss: 1.174 Acc: 57.29%\n",
      "It: 1279 Loss: 1.161 Acc: 57.65%\n",
      "It: 1299 Loss: 1.139 Acc: 58.80%\n",
      "Val Acc: 0.5934343338012695 Time per it: 2.071\n",
      "It: 1319 Loss: 1.105 Acc: 60.76%\n",
      "It: 1339 Loss: 1.072 Acc: 61.73%\n",
      "It: 1359 Loss: 1.046 Acc: 62.73%\n",
      "It: 1379 Loss: 1.047 Acc: 63.03%\n",
      "It: 1399 Loss: 1.036 Acc: 63.47%\n",
      "Val Acc: 0.6262626051902771 Time per it: 2.092\n",
      "It: 1419 Loss: 1.022 Acc: 64.04%\n",
      "It: 1439 Loss: 0.997 Acc: 64.81%\n",
      "It: 1459 Loss: 0.974 Acc: 65.64%\n",
      "It: 1479 Loss: 0.965 Acc: 66.34%\n",
      "It: 1499 Loss: 0.960 Acc: 66.29%\n",
      "Val Acc: 0.6527777910232544 Time per it: 2.046\n",
      "It: 1519 Loss: 0.959 Acc: 66.41%\n",
      "It: 1539 Loss: 0.933 Acc: 67.38%\n",
      "It: 1559 Loss: 0.931 Acc: 66.99%\n",
      "It: 1579 Loss: 0.932 Acc: 67.02%\n",
      "It: 1599 Loss: 0.926 Acc: 67.19%\n",
      "Val Acc: 0.6772411465644836 Time per it: 2.078\n",
      "It: 1619 Loss: 0.916 Acc: 67.58%\n",
      "It: 1639 Loss: 0.885 Acc: 68.92%\n",
      "It: 1659 Loss: 0.850 Acc: 69.92%\n",
      "It: 1679 Loss: 0.837 Acc: 70.49%\n",
      "It: 1699 Loss: 0.825 Acc: 70.76%\n",
      "Val Acc: 0.6958649158477783 Time per it: 2.100\n",
      "It: 1719 Loss: 0.820 Acc: 71.20%\n",
      "It: 1739 Loss: 0.790 Acc: 72.58%\n",
      "It: 1759 Loss: 0.767 Acc: 73.29%\n",
      "It: 1779 Loss: 0.761 Acc: 73.76%\n",
      "It: 1799 Loss: 0.745 Acc: 74.70%\n",
      "Val Acc: 0.7405303120613098 Time per it: 2.081\n",
      "It: 1819 Loss: 0.746 Acc: 74.28%\n",
      "It: 1839 Loss: 0.729 Acc: 75.19%\n",
      "It: 1859 Loss: 0.696 Acc: 76.22%\n",
      "It: 1879 Loss: 0.684 Acc: 76.80%\n",
      "It: 1899 Loss: 0.684 Acc: 76.49%\n",
      "Val Acc: 0.7444760203361511 Time per it: 2.070\n",
      "It: 1919 Loss: 0.692 Acc: 76.24%\n",
      "It: 1939 Loss: 0.679 Acc: 76.83%\n",
      "It: 1959 Loss: 0.679 Acc: 76.83%\n",
      "It: 1979 Loss: 0.674 Acc: 76.90%\n",
      "It: 1999 Loss: 0.672 Acc: 76.91%\n",
      "Val Acc: 0.7779356241226196 Time per it: 2.152\n",
      "It: 2019 Loss: 0.621 Acc: 78.99%\n",
      "It: 2039 Loss: 0.613 Acc: 79.28%\n",
      "It: 2059 Loss: 0.610 Acc: 79.25%\n",
      "It: 2079 Loss: 0.587 Acc: 80.19%\n",
      "It: 2099 Loss: 0.578 Acc: 80.65%\n",
      "Val Acc: 0.792455792427063 Time per it: 2.014\n",
      "It: 2119 Loss: 0.557 Acc: 81.26%\n",
      "It: 2139 Loss: 0.571 Acc: 80.48%\n",
      "It: 2159 Loss: 0.564 Acc: 80.95%\n",
      "It: 2179 Loss: 0.566 Acc: 81.02%\n",
      "It: 2199 Loss: 0.553 Acc: 81.59%\n",
      "Val Acc: 0.8074495196342468 Time per it: 2.012\n",
      "It: 2219 Loss: 0.514 Acc: 82.79%\n",
      "It: 2239 Loss: 0.497 Acc: 83.47%\n",
      "It: 2259 Loss: 0.490 Acc: 83.66%\n",
      "It: 2279 Loss: 0.466 Acc: 84.78%\n",
      "It: 2299 Loss: 0.460 Acc: 84.82%\n",
      "Val Acc: 0.8579545617103577 Time per it: 2.033\n",
      "It: 2319 Loss: 0.420 Acc: 86.32%\n",
      "It: 2339 Loss: 0.411 Acc: 86.66%\n",
      "It: 2359 Loss: 0.400 Acc: 87.32%\n",
      "It: 2379 Loss: 0.393 Acc: 87.18%\n",
      "It: 2399 Loss: 0.385 Acc: 87.87%\n",
      "Val Acc: 0.8784722089767456 Time per it: 2.032\n",
      "It: 2419 Loss: 0.362 Acc: 88.42%\n",
      "It: 2439 Loss: 0.342 Acc: 89.16%\n",
      "It: 2459 Loss: 0.330 Acc: 89.58%\n",
      "It: 2479 Loss: 0.314 Acc: 90.04%\n",
      "It: 2499 Loss: 0.316 Acc: 90.07%\n",
      "Val Acc: 0.903724730014801 Time per it: 2.107\n",
      "It: 2519 Loss: 0.287 Acc: 91.19%\n"
     ]
    }
   ],
   "source": [
    "train(train_problem, val_problem, optimizer, model, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}