{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from Code.envs.SequentialMNIST import SequentialMNIST\n",
    "from Code.train import train, OptWrapper\n",
    "from Code.everything5 import build_standard_loop\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#TODO: this is same decay!!!!\n",
    "MAIN_DECAY = np.exp(-1/(700)*0.5)\n",
    "ADAP_DECAY = np.exp(-1/(700*2))\n",
    "\n",
    "MAIN_DECAY = np.exp(-1/700)\n",
    "\n",
    "spec = {\n",
    "    'control_config': {\n",
    "        'neuron_type': 'LIF',\n",
    "        'n_neurons': 120,\n",
    "        'BETA': 0.8,\n",
    "        '1-beta': 'improved',\n",
    "        'SPIKE_FN': 'bellec'\n",
    "    },\n",
    "    'mem_config': {\n",
    "        'neuron_type': 'Cooldown2',\n",
    "        'n_neurons': 50,\n",
    "        'BETA': np.exp(-1/700),\n",
    "        '1-beta': 'improved',\n",
    "        'SPIKE_FN': 'bellec',\n",
    "        'ADAPSCALE': 30,\n",
    "        'ADAPDECAY': None, #TODO: set this\n",
    "        'OFFSET': -np.log(1-np.exp(-1/700)),\n",
    "        'DECAY': MAIN_DECAY\n",
    "    },\n",
    "    'experiment': 'SequentialMNIST',\n",
    "    'lr': 0.001,\n",
    "    'lr_decay': 0.9,\n",
    "    'iterations': 5000,\n",
    "    'batch_size': 64,\n",
    "    'architecture': '1L'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "\n",
    "\n",
    "train_problem = SequentialMNIST(spec['iterations'], spec['batch_size'], DEVICE, '../')\n",
    "val_problem = SequentialMNIST(-1, spec['batch_size'], DEVICE, '../', validate=True)\n",
    "\n",
    "\n",
    "n_in, n_out, input_rate = train_problem.get_infos()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'control': [[('input', 1), ('control', 1), ('mem', 1)], LIFNeuron(), <class 'torch.nn.modules.linear.Linear'>], 'mem': [[('input', 1), ('control', 1), ('mem', 1)], CooldownNeuron2(\n",
      "  (elu): ELU(alpha=1.0)\n",
      "), <class 'torch.nn.modules.linear.Linear'>], 'output': [[('control', 1), ('mem', 1)], BaseNeuron(), None]}\n"
     ]
    },
    {
     "data": {
      "text/plain": "OuterWrapper(\n  (model): DynNetwork(\n    (layers): ModuleDict(\n      (loop): SequenceWrapper(\n        (model): ParallelNetwork2(\n          (layers): ModuleDict(\n            (control): LIFNeuron()\n            (control_synapse): Linear(in_features=301, out_features=120, bias=True)\n            (mem): CooldownNeuron2(\n              (elu): ELU(alpha=1.0)\n            )\n            (mem_synapse): Linear(in_features=301, out_features=50, bias=False)\n            (output): BaseNeuron()\n          )\n        )\n      )\n      (mean): MeanModule()\n      (output_synapse): Linear(in_features=220, out_features=10, bias=True)\n      (output): BaseNeuron()\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Code.everything5 import OuterWrapper, DynNetwork, ParallelNetwork2, SequenceWrapper, MeanModule, BaseNeuron, ParallelNetwork\n",
    "\n",
    "from Code.everything5 import LIFNeuron, SeqOnlySpike, AdaptiveNeuron, CooldownNeuron, NoResetNeuron, NoResetNeuron2, NoResetNeuron3, NewFlipFlop, PositiveLinear, CooldownNeuron2\n",
    "def build_standard_loop(spec, n_input, input_rate):\n",
    "\n",
    "    neuron_lookup = {\n",
    "        'LIF': LIFNeuron,\n",
    "        'Disc': SeqOnlySpike,\n",
    "        'Adaptive': AdaptiveNeuron,\n",
    "        'Cooldown': CooldownNeuron,\n",
    "        'NoReset': NoResetNeuron,\n",
    "        'FlipFlop': NewFlipFlop,  # FlipFlopNeuron,\n",
    "        'NoReset2': NoResetNeuron2,\n",
    "        'NoReset3': NoResetNeuron3,\n",
    "        'Cooldown2': CooldownNeuron2\n",
    "    }\n",
    "\n",
    "    control_neuron = neuron_lookup[spec['control_config']['neuron_type']](spec['control_config']['n_neurons'], spec['control_config'])\n",
    "    mem_neuron = neuron_lookup[spec['mem_config']['neuron_type']](spec['mem_config']['n_neurons'], spec['mem_config'])\n",
    "    out_neuron_size = control_neuron.out_size + mem_neuron.out_size\n",
    "    out_neuron = BaseNeuron(out_neuron_size, None)\n",
    "\n",
    "    loop_2L = {\n",
    "        'input': (n_input, input_rate),\n",
    "        'control': [['input', 'mem'], control_neuron, nn.Linear],\n",
    "        'mem': [['control'], mem_neuron, nn.Linear],\n",
    "        'output': [['control', 'mem'], out_neuron, None],\n",
    "    }\n",
    "\n",
    "    loop_1L = {\n",
    "        'input': (n_input, input_rate),\n",
    "        'control': [['input', 'control', 'mem'], control_neuron, nn.Linear],\n",
    "        'mem': [['input', 'control', 'mem'], mem_neuron, nn.Linear],\n",
    "        'output': [['control', 'mem'], out_neuron, None],\n",
    "    }\n",
    "\n",
    "    return loop_1L if spec['architecture'] == '1L' else loop_2L\n",
    "\n",
    "loop = build_standard_loop(spec, n_in, input_rate)\n",
    "loop_model = SequenceWrapper(ParallelNetwork2(loop))\n",
    "out_neuron_size = loop_model.out_size\n",
    "\n",
    "#TODO: this has to be ordered\n",
    "outer = {\n",
    "    'input': n_in,\n",
    "    'loop': [['input'], loop_model, None],\n",
    "    'mean': [['loop'], MeanModule(out_neuron_size, -56), None],\n",
    "    'output': [['mean'], BaseNeuron(n_out, None), nn.Linear]\n",
    "}\n",
    "\n",
    "model = OuterWrapper(DynNetwork(outer))\n",
    "model.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "optimizer = OptWrapper(model.parameters(), spec['lr'], spec['lr_decay'], 2500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 8.94% | Val Time: 172.6s | Time per it: 87.8s\n",
      "It:   20 | Loss: 2.317 | Acc: 10.31%\n",
      "It:   40 | Loss: 2.318 | Acc: 9.69%\n",
      "It:   60 | Loss: 2.297 | Acc: 12.03%\n",
      "It:   80 | Loss: 2.304 | Acc: 11.80%\n",
      "It:  100 | Loss: 2.261 | Acc: 14.22%\n",
      "Val Acc: 15.63% | Val Time: 170.5s | Time per it: 4.4s\n",
      "It:  120 | Loss: 2.177 | Acc: 15.47%\n",
      "It:  140 | Loss: 2.024 | Acc: 24.06%\n",
      "It:  160 | Loss: 1.907 | Acc: 31.17%\n",
      "It:  180 | Loss: 1.833 | Acc: 28.98%\n",
      "It:  200 | Loss: 1.838 | Acc: 30.63%\n",
      "Val Acc: 25.01% | Val Time: 158.3s | Time per it: 4.1s\n",
      "It:  220 | Loss: 1.880 | Acc: 26.95%\n",
      "It:  240 | Loss: 1.832 | Acc: 28.83%\n",
      "It:  260 | Loss: 1.808 | Acc: 31.33%\n",
      "It:  280 | Loss: 1.763 | Acc: 34.69%\n",
      "It:  300 | Loss: 1.734 | Acc: 34.84%\n",
      "Val Acc: 34.10% | Val Time: 158.4s | Time per it: 4.1s\n",
      "It:  320 | Loss: 1.753 | Acc: 32.66%\n",
      "It:  340 | Loss: 1.754 | Acc: 33.44%\n",
      "It:  360 | Loss: 1.879 | Acc: 27.89%\n",
      "It:  380 | Loss: 1.775 | Acc: 34.30%\n",
      "It:  400 | Loss: 1.794 | Acc: 29.77%\n",
      "Val Acc: 33.44% | Val Time: 158.3s | Time per it: 4.1s\n",
      "It:  420 | Loss: 1.760 | Acc: 33.83%\n",
      "It:  440 | Loss: 1.778 | Acc: 34.14%\n",
      "It:  460 | Loss: 1.700 | Acc: 37.34%\n",
      "It:  480 | Loss: 1.728 | Acc: 34.06%\n",
      "It:  500 | Loss: 1.742 | Acc: 33.12%\n",
      "Val Acc: 39.25% | Val Time: 158.4s | Time per it: 4.1s\n",
      "It:  520 | Loss: 1.685 | Acc: 41.09%\n",
      "It:  540 | Loss: 2.117 | Acc: 23.75%\n",
      "It:  560 | Loss: 1.923 | Acc: 30.55%\n",
      "It:  580 | Loss: 1.834 | Acc: 30.78%\n",
      "It:  600 | Loss: 1.783 | Acc: 36.33%\n",
      "Val Acc: 29.25% | Val Time: 158.5s | Time per it: 4.1s\n",
      "It:  620 | Loss: 2.158 | Acc: 22.19%\n",
      "It:  640 | Loss: 2.179 | Acc: 16.72%\n",
      "It:  660 | Loss: 2.076 | Acc: 21.80%\n",
      "It:  680 | Loss: 1.813 | Acc: 35.16%\n",
      "It:  700 | Loss: 1.761 | Acc: 36.64%\n",
      "Val Acc: 35.52% | Val Time: 158.5s | Time per it: 4.1s\n",
      "It:  720 | Loss: 1.914 | Acc: 32.66%\n",
      "It:  740 | Loss: 1.824 | Acc: 32.97%\n",
      "It:  760 | Loss: 1.882 | Acc: 30.23%\n",
      "It:  780 | Loss: 2.136 | Acc: 22.50%\n",
      "It:  800 | Loss: 1.818 | Acc: 32.89%\n",
      "Val Acc: 36.52% | Val Time: 158.8s | Time per it: 4.1s\n",
      "It:  820 | Loss: 1.798 | Acc: 35.55%\n",
      "It:  840 | Loss: 1.697 | Acc: 39.45%\n",
      "It:  860 | Loss: 1.824 | Acc: 32.42%\n",
      "It:  880 | Loss: 1.791 | Acc: 33.28%\n",
      "It:  900 | Loss: 1.758 | Acc: 32.89%\n",
      "Val Acc: 29.01% | Val Time: 158.7s | Time per it: 4.1s\n",
      "It:  920 | Loss: 1.714 | Acc: 36.64%\n",
      "It:  940 | Loss: 1.881 | Acc: 29.06%\n",
      "It:  960 | Loss: 1.914 | Acc: 29.06%\n",
      "It:  980 | Loss: 1.838 | Acc: 32.27%\n",
      "It: 1000 | Loss: 2.055 | Acc: 21.95%\n",
      "Val Acc: 36.46% | Val Time: 158.7s | Time per it: 4.1s\n",
      "It: 1020 | Loss: 1.985 | Acc: 25.78%\n",
      "It: 1040 | Loss: 2.098 | Acc: 22.81%\n",
      "It: 1060 | Loss: 1.882 | Acc: 28.52%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-7e0f344e1f2a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_problem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_problem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Code/train.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(train_problem, val_problem, optimizer, model, run_id, print_every, validate_every)\u001B[0m\n\u001B[1;32m     70\u001B[0m         \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0macc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_problem\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss_and_acc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     73\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    193\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m         \"\"\"\n\u001B[0;32m--> 195\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    197\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[1;32m     97\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[1;32m     98\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train(train_problem, val_problem, optimizer, model, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input = train_problem.make_inputs()#[:,:1]\n",
    "out, _, log = OuterWrapper(model.model.layers.loop).to(DEVICE)(input, logging=True)\n",
    "ar_length = input.shape[0]\n",
    "array_list = [input, log['control'], log['mem']] #log['loop']['output']\n",
    "array_list2 = []\n",
    "for ar in array_list:\n",
    "    array_list2.append(ar[:, 0])\n",
    "    array_list2.append(torch.ones((ar_length, 1), device=input.device) * 0.5)\n",
    "big_ar = (1-torch.cat(array_list2[:-1], dim=1).detach()).t() * 255\n",
    "img = Image.fromarray(big_ar.cpu().numpy().astype(np.uint8), 'L')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log['control'].mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}