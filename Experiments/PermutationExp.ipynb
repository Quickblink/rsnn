{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "from torch.distributions.geometric import Geometric\n",
    "from Code.envs.permutations2 import make_batch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64#128\n",
    "\n",
    "USE_JIT = False\n",
    "\n",
    "#TODO: test device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "SEQ_LEN = 30\n",
    "CHAR_DUR = 5 #0 #100\n",
    "RESET_PROB = 0.1 #0.2\n",
    "\n",
    "perm_num = 4\n",
    "n_input = perm_num**2+1+CHAR_DUR\n",
    "n_out = perm_num**2\n",
    "n_control = 100\n",
    "n_mem = 20 #100\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "spec2 = {'beta': 0.9,\n",
    "   'lr': 0.001,\n",
    "   'lr_decay': 0.8,\n",
    "   '1-beta': False,\n",
    "   'ported_weights': True,\n",
    "   'NoBias': True,\n",
    "   'iterations': 5000,\n",
    "   'batch_size': 128,\n",
    "   'mem_beta': 1,\n",
    "   'spkfn': 'ss',\n",
    "   'decay_out': False,\n",
    "   'architecture': '1L',\n",
    "   'control_neuron': 'LIF',\n",
    "   'mem_neuron': 'Cooldown'}\n",
    "\n",
    "spec = {'beta': 0.9,\n",
    "   'lr': 0.01,\n",
    "   'lr_decay': 0.8,\n",
    "   '1-beta': False,\n",
    "   'ported_weights': True,\n",
    "   'NoBias': True,\n",
    "   'iterations': 5000,\n",
    "   'batch_size': 128,\n",
    "   'mem_beta': 0.95,\n",
    "   'spkfn': 'bellec',\n",
    "   'decay_out': False,\n",
    "   'architecture': '2L',\n",
    "   'control_neuron': 'LIF',\n",
    "   'mem_neuron': 'Adaptive'}\n",
    "\n",
    "spec['iterations'] = 15000\n",
    "#spec['mem_beta'] = 0.9985\n",
    "#spec['mem_neuron'] = 'FlipFlop'\n",
    "#spec['1-beta'] = 'improved'\n",
    "spec['lr'] = 0.001\n",
    "spec['lr_decay'] = 0.9\n",
    "spec['beta'] = 0.8\n",
    "spec['mem_beta'] = 0.8\n",
    "\n",
    "ADAP_DECAY = np.exp(-1/5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('control', [[('input', 0.8), ('mem', 0.2)], LIFNeuron(), <class 'torch.nn.modules.linear.Linear'>]), ('mem', [[('control', 1)], AdaptiveNeuron(), <class 'torch.nn.modules.linear.Linear'>]), ('output', [[('control', 1), ('mem', 1)], BaseNeuron(), None])])\n"
     ]
    },
    {
     "data": {
      "text/plain": "OuterWrapper(\n  (model): DynNetwork(\n    (layers): ModuleDict(\n      (loop): SequenceWrapper(\n        (model): ParallelNetwork2(\n          (layers): ModuleDict(\n            (control): LIFNeuron()\n            (control_synapse): Linear(in_features=38, out_features=100, bias=True)\n            (mem): AdaptiveNeuron()\n            (mem_synapse): Linear(in_features=100, out_features=20, bias=True)\n            (output): BaseNeuron()\n          )\n        )\n      )\n      (output_synapse): Linear(in_features=120, out_features=16, bias=True)\n      (output): BaseNeuron()\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Code.everything3 import DynNetwork, OuterWrapper, BaseNeuron, SequenceWrapper, ParallelNetwork, \\\n",
    " SeqOnlySpike, CooldownNeuron, OutputNeuron, LIFNeuron, NoResetNeuron, AdaptiveNeuron, FlipFlopNeuron, ParallelNetwork2\n",
    "\n",
    "\n",
    "built_config = {\n",
    "    'target_rate': 0.01,\n",
    "    'BETA': spec['beta'],\n",
    "    'OFFSET': 7, # TODO: was 3 for config24\n",
    "    'SPIKE_FN': spec['spkfn'],\n",
    "    '1-beta': spec['1-beta'],\n",
    "    'ADAPDECAY': ADAP_DECAY, #0.9985,\n",
    "    'ADAPSCALE': 180\n",
    "}\n",
    "\n",
    "#TODO: changed here\n",
    "built_config['ADAPDECAY'] = 0.99\n",
    "\n",
    "mem_config = {\n",
    "    **built_config,\n",
    "    'BETA': spec['mem_beta']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "control_lookup = {\n",
    "    'LIF': LIFNeuron,\n",
    "    'Disc': SeqOnlySpike,\n",
    "    'NoReset': NoResetNeuron\n",
    "}\n",
    "\n",
    "mem_lookup = {\n",
    "    'Adaptive': AdaptiveNeuron,\n",
    "    'Cooldown': CooldownNeuron,\n",
    "    'NoReset': NoResetNeuron,\n",
    "    'FlipFlop': FlipFlopNeuron\n",
    "}\n",
    "\n",
    "control_neuron = control_lookup[spec['control_neuron']](n_control, built_config)\n",
    "mem_neuron = mem_lookup[spec['mem_neuron']](n_mem, mem_config)\n",
    "out_neuron = OutputNeuron(n_control+n_mem, built_config) if spec['decay_out'] else BaseNeuron(n_control+n_mem, built_config)\n",
    "\n",
    "\n",
    "loop_2L = OrderedDict([\n",
    "    ('input', n_input),\n",
    "    ('control', [['input', 'mem'], control_neuron, nn.Linear]),\n",
    "    ('mem', [['control'], mem_neuron, nn.Linear]),\n",
    "    ('output', [['control', 'mem'], out_neuron, None]),\n",
    "])\n",
    "\n",
    "loop_2L = OrderedDict([\n",
    "    ('input', (n_input, 0.1)),\n",
    "    ('control', [[('input', 0.8), ('mem', 0.2)], control_neuron, nn.Linear]),\n",
    "    ('mem', [['control'], mem_neuron, nn.Linear]),\n",
    "    ('output', [['control', 'mem'], out_neuron, None]),\n",
    "])\n",
    "\n",
    "\n",
    "loop_1L = OrderedDict([\n",
    "    ('input', n_input),\n",
    "    ('control', [['input', 'control', 'mem'], control_neuron, nn.Linear]),\n",
    "    ('mem', [['input', 'control', 'mem'], mem_neuron, nn.Linear]),\n",
    "    ('output', [['control', 'mem'], out_neuron, None]),\n",
    "])\n",
    "\n",
    "loop = loop_1L if spec['architecture'] == '1L' else loop_2L\n",
    "\n",
    "outer = OrderedDict([\n",
    "    ('input', n_input),\n",
    "    ('loop', [['input'], SequenceWrapper(ParallelNetwork2(loop, bias=(not spec['NoBias']))), None]),\n",
    "    ('output', [['loop'], BaseNeuron(n_out, None), nn.Linear]),\n",
    "])\n",
    "\n",
    "model = OuterWrapper(DynNetwork(outer), device)\n",
    "\n",
    "\n",
    "#loop_model = OuterWrapper(make_SequenceWrapper(ParallelNetwork(loop), USE_JIT), device, USE_JIT)\n",
    "\n",
    "#final_linear = nn.Linear(n_control+n_mem, 10).to(device)\n",
    "'''\n",
    "if spec['ported_weights']:\n",
    "    o_weights = pickle.load(open('weight_transplant_enc', 'rb'))\n",
    "\n",
    "    o1 = torch.tensor(o_weights['RecWeights/RecurrentWeight:0']).t()\n",
    "    o2 = torch.tensor(o_weights['InputWeights/InputWeight:0']).t()\n",
    "    o3 = torch.cat((o2, o1), dim=1)\n",
    "    with torch.no_grad():\n",
    "        model.pretrace.layers.loop.model.layers.control_synapse.weight.data[:,:300] = o3[:120] if spec['architecture'] == '1L' else o3[:120, :181]\n",
    "        model.pretrace.layers.loop.model.layers.mem_synapse.weight.data[:,:300] = o3[120:] if spec['architecture'] == '1L' else o3[120:, 180:]\n",
    "        model.pretrace.layers.output_synapse.weight.data = torch.tensor(o_weights['out_weight:0']).t()\n",
    "'''\n",
    "params = list(model.parameters())\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "OuterWrapper(\n  (model): DynNetwork(\n    (layers): ModuleDict(\n      (lstm): LSTMWrapper(\n        (lstm): LSTM(22, 32)\n      )\n      (output_synapse): Linear(in_features=32, out_features=16, bias=True)\n      (output): BaseNeuron()\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Code.everything3 import DynNetwork, OuterWrapper, LSTMWrapper, MeanModule, BaseNeuron\n",
    "\n",
    "lstm_size = 32\n",
    "\n",
    "outer = OrderedDict([\n",
    "    ('input', n_input),\n",
    "    ('lstm', [['input'], LSTMWrapper(n_input, lstm_size), None]),\n",
    "    ('output', [['lstm'], BaseNeuron(n_out, None), nn.Linear]),\n",
    "])\n",
    "\n",
    "model = OuterWrapper(DynNetwork(outer), device, USE_JIT)\n",
    "\n",
    "#with torch.no_grad():\n",
    "#    model.model.layers.lstm.lstm.bias_hh_l0[:256] += 3\n",
    "\n",
    "\n",
    "\n",
    "params = list(model.parameters())\n",
    "\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from Code.everything3 import DynNetwork, OuterWrapper, LSTMWrapper, MeanModule, BaseNeuron\n",
    "model = OuterWrapper(torch.load('../models/perm_lstm2'), device, USE_JIT)\n",
    "params = list(model.parameters())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "lr = spec['lr']\n",
    "optimizer = optim.Adam(params, lr=lr)\n",
    "#bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "ce = nn.CrossEntropyLoss() #reduction='none'\n",
    "\n",
    "\n",
    "ITERATIONS = spec['iterations']#36000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'grad_norm': [],\n",
    "    'loss': [],\n",
    "    'acc': [],\n",
    "    'batch_var': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "grad_norm_history = []\n",
    "def record_norm():\n",
    "    norms = []\n",
    "    for p in params:\n",
    "        norms.append(p.grad.norm().item())\n",
    "    stats['grad_norm'].append(torch.tensor(norms).norm().item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "'''\n",
    "#store_dist = (lambda : Geometric(torch.tensor([0.2], device=device)).sample().int().item()+1)\n",
    "recall_dist = (lambda : Geometric(torch.tensor([0.2], device=device)).sample().int().item()+1)\n",
    "store_dist = (lambda : 1)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    rythm = torch.zeros([CHAR_DUR], device=device)\n",
    "    rythm[0] = 1\n",
    "    rythm = rythm.expand(SEQ_LEN, CHAR_DUR).reshape(SEQ_LEN*CHAR_DUR, 1, 1).expand(SEQ_LEN*CHAR_DUR, BATCH_SIZE, 1)\n",
    "    #rythm = rythm.view(1,5,1,1).expand([SEQ_LEN, CHAR_DUR, BATCH_SIZE, 1]).view(SEQ_LEN*CHAR_DUR, BATCH_SIZE, 1)\n",
    "'''\n",
    "with torch.no_grad():\n",
    "    rythm = torch.diag(torch.ones([CHAR_DUR], device=device))\n",
    "    rythm = rythm.expand(SEQ_LEN, CHAR_DUR, CHAR_DUR).reshape(SEQ_LEN*CHAR_DUR, 1, CHAR_DUR).expand(SEQ_LEN*CHAR_DUR, BATCH_SIZE, CHAR_DUR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001328125043073669 20\n",
      "0.012395833249320276 40\n",
      "0.03843749994412064 60\n",
      "0.04096354190260172 80\n",
      "0.04661458320915699 100\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'validate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-b318db201327>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0msumacc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m%\u001B[0m\u001B[0;36m100\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0mvalidate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m%\u001B[0m\u001B[0;36m2500\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m         \u001B[0mlr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlr\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mspec\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'lr_decay'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'validate' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start = time.time()\n",
    "i = 1\n",
    "sumloss = 0\n",
    "sumacc = 0\n",
    "\n",
    "while i < ITERATIONS:\n",
    "    batchstart = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    input, target = make_batch(BATCH_SIZE, SEQ_LEN, RESET_PROB, device, perm_num)\n",
    "    #data = data.repeat_interleave(CHAR_DUR, 0)\n",
    "\n",
    "    recall = torch.ones([1], device=device).expand(SEQ_LEN, BATCH_SIZE, perm_num)\n",
    "\n",
    "    input = input.repeat_interleave(CHAR_DUR, 0)\n",
    "    input = torch.cat((input, rythm), dim=-1)\n",
    "\n",
    "    #TODO: repeat data over\n",
    "\n",
    "    output, _ = model(input)\n",
    "    output = output.view(SEQ_LEN, CHAR_DUR, BATCH_SIZE, perm_num, perm_num).mean(dim=1)\n",
    "    out2 = output.transpose(-1, -2)\n",
    "    loss1 = ce(output.view(-1, perm_num), target[0].view(-1))\n",
    "    loss2 = ce(out2.reshape(-1, perm_num), target[1].view(-1))\n",
    "    loss = ((loss1+loss2)*recall.view(-1)).sum()/recall.sum()\n",
    "    #TODO: mask with recall\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    acc1 = (output.argmax(dim=-1) == target[0]).all(dim=-1).float().mean().item()\n",
    "    acc2 = (out2.argmax(dim=-1) == target[1]).all(dim=-1).float().mean().item()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        record_norm()\n",
    "        stats['loss'].append(loss.item())\n",
    "        #acc = ((((output > 0).float() == target).float()*recall).sum()/recall.sum()).item()\n",
    "        #stats['acc'].append(acc)\n",
    "        batch_var = 3 #out_final.var(0).mean().item()\n",
    "        #stats['batch_var'].append(batch_var)\n",
    "\n",
    "        #print(loss.item(), acc1, acc2)\n",
    "\n",
    "\n",
    "    sumloss += loss.item()\n",
    "    sumacc += acc1\n",
    "    if i%20 == 0:\n",
    "        print(sumacc/20, i)\n",
    "        #print(loss.item(), sumloss/20, sumacc/20, time.time()-batchstart, batch_var) #torch.argmax(outputs[-1], 1).float().var()\n",
    "        sumloss = 0\n",
    "        sumacc = 0\n",
    "    if i%100 == 0:\n",
    "        validate()\n",
    "    if i%2500 == 0:\n",
    "        lr = lr * spec['lr_decay']\n",
    "        optimizer = optim.Adam(params, lr=lr)\n",
    "        print('Learning Rate: ', lr)\n",
    "    i += 1\n",
    "    #config['stats'] = stats\n",
    "    #config['progress'] = i\n",
    "    #with open('configs/' + run_id + '.json', 'w') as config_file:\n",
    "    #    json.dump(config, config_file, indent=2)\n",
    "    #model.save('models/'+run_id)\n",
    "\n",
    "\n",
    "print('Total time: ', time.time()-start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_batch() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-95562d56184f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m13\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstore_dist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecall_dist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: make_batch() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "test_data = make_batch(1, 13, store_dist, recall_dist, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = test_data[:, 0 ,0].nonzero()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = test_data[:a, 0, 1].nonzero()[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data[b, 0, 2] == test_data[a, 0, 3]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "seql = 100\n",
    "res_prob = 0.\n",
    "with torch.no_grad():\n",
    "    nrythm = torch.diag(torch.ones([CHAR_DUR], device=device))\n",
    "    nrythm = nrythm.expand(seql, CHAR_DUR, CHAR_DUR).reshape(seql*CHAR_DUR, 1, CHAR_DUR).expand(seql*CHAR_DUR, BATCH_SIZE, CHAR_DUR)\n",
    "\n",
    "def validate():\n",
    "    #seql = SEQ_LEN\n",
    "    with torch.no_grad():\n",
    "        input, target = make_batch(BATCH_SIZE, seql, res_prob, device, perm_num)\n",
    "        input = input.repeat_interleave(CHAR_DUR, 0)\n",
    "        input = torch.cat((input, nrythm), dim=-1)\n",
    "\n",
    "    #TODO: repeat data over\n",
    "        output, _, log = model(input, logging=True)\n",
    "        output = output.view(seql, CHAR_DUR, BATCH_SIZE, perm_num, perm_num).mean(dim=1)\n",
    "        print('Validation: ', (output.argmax(dim=-1) == target[0]).all(dim=-1).float().mean().item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  0.3695312440395355\n"
     ]
    }
   ],
   "source": [
    "validate()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "ar_length = input.shape[0]\n",
    "array_list = [input, log['loop']['control'], log['loop']['mem'], log['output']] #log['loop']['output']\n",
    "array_list2 = []\n",
    "for ar in array_list:\n",
    "    array_list2.append(ar[:, 0])\n",
    "    array_list2.append(torch.ones((ar_length, 1), device=input.device) * 0.5)\n",
    "big_ar = torch.cat(array_list2[:-1], dim=1).detach() * 255\n",
    "img = Image.fromarray(big_ar.numpy().astype(np.uint8), 'L')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(237, 25)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=237x500 at 0x7FB3C77873C8>",
      "image/png": "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\n"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.resize((237, 500))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log['loop']['control'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log['loop']['mem'].mean()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.layers.loop.model.layers.control_synapse.weight.var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.model.layers.loop.model.layers.mem_synapse.weight.var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.layers.loop.model.layers.control_synapse.weight.var() * log['loop']['mem'].mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#model.save('../models/perm_lstm2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8187307530779818"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADAP_DECAY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([25, 128, 16])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}