{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from Code.envs.statemachine import run, make_rythm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "standard = {'beta': 0.8,\n",
    "   'lr': 0.001,\n",
    "   'NoBias': False, #no effect\n",
    "   'iterations': 5000,\n",
    "   'batch_size': 64,\n",
    "   'spkfn': 'bellec',\n",
    "   'decay_out': False,\n",
    "   'control_neuron': 'LIF',\n",
    "}\n",
    "\n",
    "spec = {\n",
    "    **standard,\n",
    "   '1-beta': 'improved',\n",
    "   'decay_change': 1,\n",
    "   'architecture': '1L',\n",
    "   'mem_neuron': 'Adaptive',\n",
    "   'char_dur': 2,\n",
    "   'n_mem': 10\n",
    "}\n",
    "\n",
    "#spec['1-beta'] = False\n",
    "#spec['beta'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BATCH_SIZE = spec['batch_size']\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "SEQ_LEN = 30\n",
    "CHAR_DUR = spec['char_dur']\n",
    "\n",
    "perm_num = 8\n",
    "n_input = perm_num + CHAR_DUR\n",
    "n_out = perm_num\n",
    "n_control = 100\n",
    "n_mem = spec['n_mem']\n",
    "\n",
    "MAIN_DECAY = np.exp(-1/(CHAR_DUR*spec['decay_change']))\n",
    "INPUT_RATE = 1.5/n_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#MAIN_DECAY = 1# = 0.99\n",
    "MAIN_DECAY = np.exp(-1/(CHAR_DUR)*0.5)\n",
    "ADAP_DECAY = np.exp(-1/(CHAR_DUR*2))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('control', [[('input', 1), ('control', 1), ('mem', 1)], LIFNeuron(), <class 'torch.nn.modules.linear.Linear'>]), ('mem', [[('input', 1), ('control', 1), ('mem', 1)], AdaptiveNeuron(), <class 'torch.nn.modules.linear.Linear'>]), ('output', [[('control', 1), ('mem', 1)], BaseNeuron(), None])])\n"
     ]
    },
    {
     "data": {
      "text/plain": "OuterWrapper(\n  (model): DynNetwork(\n    (layers): ModuleDict(\n      (loop): SequenceWrapper(\n        (model): ParallelNetwork2(\n          (layers): ModuleDict(\n            (control): LIFNeuron()\n            (control_synapse): Linear(in_features=120, out_features=100, bias=True)\n            (mem): AdaptiveNeuron()\n            (mem_synapse): Linear(in_features=120, out_features=10, bias=True)\n            (output): BaseNeuron()\n          )\n        )\n      )\n      (output_synapse): Linear(in_features=110, out_features=8, bias=True)\n      (output): BaseNeuron()\n    )\n  )\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Code.everything4 import DynNetwork, OuterWrapper, BaseNeuron, SequenceWrapper, ParallelNetwork, \\\n",
    " SeqOnlySpike, CooldownNeuron, OutputNeuron, LIFNeuron, NoResetNeuron, AdaptiveNeuron, FlipFlopNeuron, ParallelNetwork2\n",
    "\n",
    "\n",
    "built_config = {\n",
    "    'BETA': spec['beta'],\n",
    "    'OFFSET': -np.log(1-MAIN_DECAY),#-np.log(1-spec['beta']),#3, # TODO: was 3 for config24\n",
    "    'SPIKE_FN': spec['spkfn'],\n",
    "    '1-beta': spec['1-beta'],\n",
    "    'ADAPDECAY': ADAP_DECAY, #0.9985,\n",
    "    'ADAPSCALE': 30#180\n",
    "}\n",
    "\n",
    "#built_config['ADAPDECAY'] = 0.99\n",
    "\n",
    "mem_config = {\n",
    "    **built_config,\n",
    "    'BETA': spec['beta'] if spec['mem_neuron'] in ['Adaptive', 'LIF'] else MAIN_DECAY\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "control_lookup = {\n",
    "    'LIF': LIFNeuron,\n",
    "    'Disc': SeqOnlySpike,\n",
    "    'NoReset': NoResetNeuron\n",
    "}\n",
    "\n",
    "mem_lookup = {\n",
    "    'Adaptive': AdaptiveNeuron,\n",
    "    'Cooldown': CooldownNeuron,\n",
    "    'NoReset': NoResetNeuron,\n",
    "    'FlipFlop': FlipFlopNeuron,\n",
    "    'LIF': LIFNeuron\n",
    "}\n",
    "\n",
    "control_neuron = control_lookup[spec['control_neuron']](n_control, built_config)\n",
    "mem_neuron = mem_lookup[spec['mem_neuron']](n_mem, mem_config)\n",
    "out_neuron_size = n_mem if spec['architecture'] == '2L' else n_mem+n_control\n",
    "out_neuron = OutputNeuron(out_neuron_size, built_config) if spec['decay_out'] else BaseNeuron(out_neuron_size, built_config)\n",
    "#out_neuron = LIFNeuron(n_control, built_config)\n",
    "#TODO: fix this for 1L\n",
    "\n",
    "#from mem only\n",
    "loop_2L = OrderedDict([\n",
    "    ('input', (n_input, INPUT_RATE)),\n",
    "    ('control', [['input', 'mem'], control_neuron, nn.Linear]),\n",
    "    ('mem', [['control'], mem_neuron, nn.Linear]),\n",
    "    ('output', [['mem'], out_neuron, None]),\n",
    "])\n",
    "\n",
    "\n",
    "loop_1L = OrderedDict([\n",
    "    ('input', (n_input, INPUT_RATE)),\n",
    "    ('control', [['input', 'control', 'mem'], control_neuron, nn.Linear]),\n",
    "    ('mem', [['input', 'control', 'mem'], mem_neuron, nn.Linear]),\n",
    "    ('output', [['control', 'mem'], out_neuron, None]),\n",
    "])\n",
    "\n",
    "loop = loop_1L if spec['architecture'] == '1L' else loop_2L\n",
    "\n",
    "outer = OrderedDict([\n",
    "    ('input', n_input),\n",
    "    ('loop', [['input'], SequenceWrapper(ParallelNetwork2(loop, bias=(not spec['NoBias']))), None]),\n",
    "    ('output', [['loop'], BaseNeuron(n_out, None), nn.Linear]),\n",
    "])\n",
    "\n",
    "model = OuterWrapper(DynNetwork(outer), device)\n",
    "\n",
    "\n",
    "params = list(model.parameters())\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "lr = spec['lr']\n",
    "optimizer = optim.Adam(params, lr=lr)\n",
    "#bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "#ce = nn.CrossEntropyLoss() #reduction='none'\n",
    "\n",
    "\n",
    "ITERATIONS = spec['iterations']#36000\n",
    "\n",
    "\n",
    "lookup = torch.tensor([[6, 1, 4, 5, 7, 2, 0, 3],\n",
    "        [7, 0, 4, 2, 3, 1, 5, 6],\n",
    "        [0, 5, 6, 2, 4, 3, 7, 1],\n",
    "        [2, 7, 6, 4, 3, 1, 5, 0],\n",
    "        [0, 6, 4, 5, 2, 1, 7, 3],\n",
    "        [5, 1, 0, 6, 4, 7, 3, 2],\n",
    "        [4, 6, 1, 2, 5, 7, 0, 3],\n",
    "        [2, 7, 4, 3, 5, 6, 0, 1]], dtype=torch.long, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "seql = 100\n",
    "\n",
    "val_rythm = make_rythm(BATCH_SIZE, 100, CHAR_DUR, device)\n",
    "def validate():\n",
    "    acc, _, _ = run(model, lookup, val_rythm, BATCH_SIZE, 100, CHAR_DUR, perm_num, device)\n",
    "    print('Validation: ', acc)\n",
    "\n",
    "stats = {\n",
    "    'grad_norm': [],\n",
    "    'loss': [],\n",
    "    'acc': [],\n",
    "    'batch_var': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "grad_norm_history = []\n",
    "def record_norm():\n",
    "    norms = []\n",
    "    for p in params:\n",
    "        norms.append(p.grad.norm().item())\n",
    "    stats['grad_norm'].append(torch.tensor(norms).norm().item())\n",
    "    #print(stats['grad_norm'][-1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14477370567619802 20\n",
      "0.18674568980932235 40\n",
      "0.22031249850988388 60\n",
      "0.2554148696362972 80\n",
      "0.27521551847457887 100\n",
      "Validation:  0.30366161465644836\n",
      "0.292349137365818 120\n",
      "0.31109913289546964 140\n",
      "0.31821120977401735 160\n",
      "0.33168102949857714 180\n",
      "0.3449084058403969 200\n",
      "Validation:  0.359375\n",
      "0.36139547675848005 220\n",
      "0.3633890077471733 240\n",
      "0.3735991358757019 260\n",
      "0.3592402994632721 280\n",
      "0.38060344755649567 300\n",
      "Validation:  0.39472854137420654\n",
      "0.37556573152542116 320\n",
      "0.387284480035305 340\n",
      "0.39824891835451126 360\n",
      "0.4156250014901161 380\n",
      "0.4261853456497192 400\n",
      "Validation:  0.4201388955116272\n",
      "0.4335398688912392 420\n",
      "0.4476023703813553 440\n",
      "0.4612607717514038 460\n",
      "0.4877155154943466 480\n",
      "0.498545253276825 500\n",
      "Validation:  0.4848484992980957\n",
      "0.5027747809886932 520\n",
      "0.5108028009533883 540\n",
      "0.5263200402259827 560\n",
      "0.5259967729449272 580\n",
      "0.5360991358757019 600\n",
      "Validation:  0.5320391654968262\n",
      "0.5404633581638336 620\n",
      "0.5498652994632721 640\n",
      "0.5569234848022461 660\n",
      "0.5667564600706101 680\n",
      "0.569181028008461 700\n",
      "Validation:  0.5579229593276978\n",
      "0.5687500029802323 720\n",
      "0.5780980587005615 740\n",
      "0.5806034475564956 760\n",
      "0.5868803799152374 780\n",
      "0.597306028008461 800\n",
      "Validation:  0.589330792427063\n",
      "0.6033674627542496 820\n",
      "0.6013200461864472 840\n",
      "0.6056573212146759 860\n",
      "0.6109913855791091 880\n",
      "0.6141972035169602 900\n",
      "Validation:  0.6123737096786499\n",
      "0.6141971945762634 920\n",
      "0.622790950536728 940\n",
      "0.6281519383192062 960\n",
      "0.6264008611440659 980\n",
      "0.6313577502965927 1000\n",
      "Validation:  0.6201072931289673\n",
      "0.6358297318220139 1020\n",
      "0.6372036576271057 1040\n",
      "0.6414601296186447 1060\n",
      "0.6383081883192062 1080\n",
      "0.6466864198446274 1100\n",
      "Validation:  0.629419207572937\n",
      "0.6523168027400971 1120\n",
      "0.6529094815254212 1140\n",
      "0.6556034415960312 1160\n",
      "0.6585129261016845 1180\n",
      "0.6640624940395355 1200\n",
      "Validation:  0.6452020406723022\n",
      "0.670985996723175 1220\n",
      "0.6709321051836014 1240\n",
      "0.6689116328954696 1260\n",
      "0.6742456883192063 1280\n",
      "0.6759159356355667 1300\n",
      "Validation:  0.6482007503509521\n",
      "0.6790678858757019 1320\n",
      "0.6769665896892547 1340\n",
      "0.680872842669487 1360\n",
      "0.6867726236581803 1380\n",
      "0.6841864168643952 1400\n",
      "Validation:  0.6668245196342468\n",
      "0.6884159445762634 1420\n",
      "0.6922683119773865 1440\n",
      "0.6879849076271057 1460\n",
      "0.6960937410593033 1480\n",
      "0.6983836203813553 1500\n",
      "Validation:  0.6832386255264282\n",
      "0.6962823241949081 1520\n",
      "0.6985991328954697 1540\n",
      "0.705495685338974 1560\n",
      "0.7006734907627106 1580\n",
      "0.7044989168643951 1600\n",
      "Validation:  0.6833964586257935\n",
      "0.6760237067937851 1620\n",
      "0.6748114258050919 1640\n",
      "0.6860722005367279 1660\n",
      "0.6798760712146759 1680\n",
      "0.674703660607338 1700\n",
      "Validation:  0.6961805820465088\n",
      "0.6806034505367279 1720\n",
      "0.6987338304519654 1740\n",
      "0.7043642193078995 1760\n",
      "0.7027747869491577 1780\n",
      "0.7016971915960312 1800\n",
      "Validation:  0.6934974789619446\n",
      "0.7048221975564957 1820\n",
      "0.7107219815254211 1840\n",
      "0.7106680989265441 1860\n",
      "0.7132812529802323 1880\n",
      "0.714089435338974 1900\n",
      "Validation:  0.696811854839325\n",
      "0.7125808149576187 1920\n",
      "0.7205549567937851 1940\n",
      "0.7187500029802323 1960\n",
      "0.7180765062570572 1980\n",
      "0.719477367401123 2000\n",
      "Validation:  0.6979166865348816\n",
      "0.7197198331356048 2020\n",
      "0.7231950402259827 2040\n",
      "0.7242726296186447 2060\n",
      "0.7251346945762634 2080\n",
      "0.7260775893926621 2100\n",
      "Validation:  0.7039141654968262\n",
      "0.7241918087005615 2120\n",
      "0.726643317937851 2140\n",
      "0.7281788736581802 2160\n",
      "0.7270743459463119 2180\n",
      "0.7268588274717331 2200\n",
      "Validation:  0.6976010203361511\n",
      "0.7253502160310745 2220\n",
      "0.7308728396892548 2240\n",
      "0.7322198212146759 2260\n",
      "0.7307112067937851 2280\n",
      "0.7323275834321976 2300\n",
      "Validation:  0.7217487096786499\n",
      "0.7320043087005615 2320\n",
      "0.7304956793785096 2340\n",
      "0.7295258700847626 2360\n",
      "0.7275323301553727 2380\n",
      "0.7322198241949082 2400\n",
      "Validation:  0.7141729593276978\n",
      "0.7306842654943466 2420\n",
      "0.7386314600706101 2440\n",
      "0.7376616388559342 2460\n",
      "0.7386314630508423 2480\n",
      "0.7368803888559341 2500\n",
      "Validation:  0.7236426472663879\n",
      "0.7349137872457504 2520\n",
      "0.7389547318220139 2540\n",
      "0.7413254290819168 2560\n",
      "0.736826503276825 2580\n",
      "0.741163793206215 2600\n",
      "Validation:  0.723169207572937\n",
      "0.7449622809886932 2620\n",
      "0.7414870679378509 2640\n",
      "0.7370420336723328 2660\n",
      "0.7380387872457504 2680\n",
      "0.7435883581638336 2700\n",
      "Validation:  0.7263257503509521\n",
      "0.7444234907627105 2720\n",
      "0.7369611978530883 2740\n",
      "0.7463631421327591 2760\n",
      "0.7425915956497192 2780\n",
      "0.7430495649576188 2800\n",
      "Validation:  0.728061854839325\n",
      "0.7424568951129913 2820\n",
      "0.7424030125141143 2840\n",
      "0.7428340524435043 2860\n",
      "0.7496767252683639 2880\n",
      "0.7425377130508423 2900\n",
      "Validation:  0.7334280014038086\n",
      "0.7426724135875702 2920\n",
      "0.7504040956497192 2940\n",
      "0.7526939600706101 2960\n",
      "0.7482489228248597 2980\n",
      "0.7495959043502808 3000\n",
      "Validation:  0.7255366444587708\n",
      "0.7492726296186447 3020\n",
      "0.7443426698446274 3040\n",
      "0.7533135771751404 3060\n",
      "0.753394392132759 3080\n",
      "0.7539870619773865 3100\n",
      "Validation:  0.7222222089767456\n",
      "0.7482489258050918 3120\n",
      "0.7504849135875702 3140\n",
      "0.751185342669487 3160\n",
      "0.7540409445762635 3180\n",
      "0.7562499910593032 3200\n",
      "Validation:  0.7408459782600403\n",
      "0.7565732777118683 3220\n",
      "0.7485721915960312 3240\n",
      "0.7481681048870087 3260\n",
      "0.7537446111440659 3280\n",
      "0.7569504231214523 3300\n",
      "Validation:  0.7471590638160706\n",
      "0.7564116358757019 3320\n",
      "0.7485991388559341 3340\n",
      "0.7574353396892548 3360\n",
      "0.7566810250282288 3380\n",
      "0.7550107717514039 3400\n",
      "Validation:  0.7398989796638489\n",
      "0.7543911635875702 3420\n",
      "0.7565732777118683 3440\n",
      "0.7554418116807937 3460\n",
      "0.75703125 3480\n",
      "0.7602640122175217 3500\n",
      "Validation:  0.7422664165496826\n",
      "0.7584051698446274 3520\n",
      "0.7643049567937851 3540\n",
      "0.7638469845056534 3560\n",
      "0.7627155244350433 3580\n",
      "0.7552262812852859 3600\n",
      "Validation:  0.732481062412262\n",
      "0.7571120619773865 3620\n",
      "0.7578663766384125 3640\n",
      "0.7603178858757019 3660\n",
      "0.7599946141242981 3680\n",
      "0.7625538766384125 3700\n",
      "Validation:  0.7398989796638489\n",
      "0.7619342654943466 3720\n",
      "0.7674838334321976 3740\n",
      "0.7624999910593033 3760\n",
      "0.7645204782485961 3780\n",
      "0.7648976355791092 3800\n",
      "Validation:  0.7378472089767456\n",
      "0.7683189630508422 3820\n",
      "0.7701508551836014 3840\n",
      "0.765625 3860\n",
      "0.7668911635875701 3880\n",
      "0.7711206883192062 3900\n",
      "Validation:  0.7507891654968262\n",
      "0.7691002130508423 3920\n",
      "0.7671066761016846 3940\n",
      "0.7696928828954697 3960\n",
      "0.7690193980932236 3980\n",
      "0.7668103456497193 4000\n",
      "Validation:  0.7468434572219849\n",
      "0.7668911635875701 4020\n",
      "0.7747575491666794 4040\n",
      "0.7693696111440659 4060\n",
      "0.7698006421327591 4080\n",
      "0.7635506480932236 4100\n",
      "Validation:  0.7490530014038086\n",
      "0.7711745709180832 4120\n",
      "0.7747306048870086 4140\n",
      "0.7748652994632721 4160\n",
      "0.7747844755649567 4180\n",
      "0.7773976176977158 4200\n",
      "Validation:  0.7577335834503174\n",
      "0.7791756451129913 4220\n",
      "0.775727367401123 4240\n",
      "0.776912721991539 4260\n",
      "0.7759428918361664 4280\n",
      "0.7809267163276672 4300\n",
      "Validation:  0.7582070827484131\n",
      "0.7814924627542496 4320\n",
      "0.7808189630508423 4340\n",
      "0.7746228516101837 4360\n",
      "0.7784213304519654 4380\n",
      "0.7801185339689255 4400\n",
      "Validation:  0.756313145160675\n",
      "0.7796605616807938 4420\n",
      "0.7860183149576188 4440\n",
      "0.7820043087005615 4460\n",
      "0.7832974106073379 4480\n",
      "0.7788793087005615 4500\n",
      "Validation:  0.7679924368858337\n",
      "0.7810344815254211 4520\n",
      "0.7859105587005615 4540\n",
      "0.7817618548870087 4560\n",
      "0.7873114168643951 4580\n",
      "0.7858836144208908 4600\n",
      "Validation:  0.7766729593276978\n",
      "0.7844827502965928 4620\n",
      "0.787580817937851 4640\n",
      "0.7843480557203293 4660\n",
      "0.7872575461864472 4680\n",
      "0.7851023644208908 4700\n",
      "Validation:  0.7607322931289673\n",
      "0.7872575461864472 4720\n",
      "0.7886853456497193 4740\n",
      "0.7961745649576187 4760\n",
      "0.7943426728248596 4780\n",
      "0.7901670306921005 4800\n",
      "Validation:  0.7847222089767456\n",
      "0.7904364198446274 4820\n",
      "0.7970635771751404 4840\n",
      "0.7932112067937851 4860\n",
      "0.7962015062570572 4880\n",
      "0.7936422407627106 4900\n",
      "Validation:  0.7833017706871033\n",
      "0.7937769293785095 4920\n",
      "0.7911907225847244 4940\n",
      "0.8008351296186447 4960\n",
      "0.7969827562570572 4980\n",
      "Total time:  813.6796772480011\n"
     ]
    }
   ],
   "source": [
    "train_rythm = make_rythm(BATCH_SIZE, SEQ_LEN, CHAR_DUR, device)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "i = 1\n",
    "sumloss = 0\n",
    "sumacc = 0\n",
    "\n",
    "while i < ITERATIONS:\n",
    "    batchstart = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    acc, loss, _ = run(model, lookup, train_rythm, BATCH_SIZE, SEQ_LEN, CHAR_DUR, perm_num, device)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        record_norm()\n",
    "        stats['loss'].append(loss.item())\n",
    "        #acc = ((((output > 0).float() == target).float()*recall).sum()/recall.sum()).item()\n",
    "        #stats['acc'].append(acc)\n",
    "        batch_var = 3 #out_final.var(0).mean().item()\n",
    "        #stats['batch_var'].append(batch_var)\n",
    "\n",
    "        #print(loss.item(), acc1, acc2)\n",
    "\n",
    "\n",
    "    sumloss += loss.item()\n",
    "    sumacc += acc\n",
    "    if i%20 == 0:\n",
    "        print(sumacc/20, i)\n",
    "        #print(loss.item(), sumloss/20, sumacc/20, time.time()-batchstart, batch_var) #torch.argmax(outputs[-1], 1).float().var()\n",
    "        sumloss = 0\n",
    "        sumacc = 0\n",
    "    if i%100 == 0:\n",
    "        validate()\n",
    "    i += 1\n",
    "    #config['stats'] = stats\n",
    "    #config['progress'] = i\n",
    "    #with open('configs/' + run_id + '.json', 'w') as config_file:\n",
    "    #    json.dump(config, config_file, indent=2)\n",
    "    #model.save('models/'+run_id)\n",
    "\n",
    "\n",
    "print('Total time: ', time.time()-start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7788007830714049"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAIN_DECAY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  0.7784090638160706\n"
     ]
    }
   ],
   "source": [
    "validate()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6, 1, 4, 5, 7, 2, 0, 3],\n        [7, 0, 4, 2, 3, 1, 5, 6],\n        [0, 5, 6, 2, 4, 3, 7, 1],\n        [2, 7, 6, 4, 3, 1, 5, 0],\n        [0, 6, 4, 5, 2, 1, 7, 3],\n        [5, 1, 0, 6, 4, 7, 3, 2],\n        [4, 6, 1, 2, 5, 7, 0, 3],\n        [2, 7, 4, 3, 5, 6, 0, 1]], device='cuda:0')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_rythm = make_rythm(BATCH_SIZE, SEQ_LEN, CHAR_DUR, device)\n",
    "\n",
    "_, _, info = run(model, lookup, train_rythm, BATCH_SIZE, SEQ_LEN, CHAR_DUR, perm_num, device, logging=True)\n",
    "\n",
    "input, log = info\n",
    "ar_length = input.shape[0]\n",
    "array_list = [input, log['loop']['control'], log['loop']['mem'], log['output']] #log['loop']['output']\n",
    "array_list2 = []\n",
    "for ar in array_list:\n",
    "    array_list2.append(ar[:, 0])\n",
    "    array_list2.append(torch.ones((ar_length, 1), device=input.device) * 0.5)\n",
    "big_ar = torch.cat(array_list2[:-1], dim=1).detach() * 255\n",
    "img = Image.fromarray(big_ar.cpu().numpy().astype(np.uint8), 'L')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(131, 60)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=131x60 at 0x7FCA380F3438>",
      "image/png": "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\n"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img\n",
    "#img.resize((239, 600))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3839, device='cuda:0', grad_fn=<MeanBackward0>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log['loop']['control'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0655, device='cuda:0', grad_fn=<MeanBackward0>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log['loop']['mem'].mean()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1437, device='cuda:0', grad_fn=<VarBackward0>)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers.loop.model.layers.control_synapse.weight.var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.model.layers.loop.model.layers.mem_synapse.weight.var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3352, device='cuda:0', grad_fn=<VarBackward0>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0094, device='cuda:0', grad_fn=<MulBackward0>)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers.loop.model.layers.control_synapse.weight.var() * log['loop']['mem'].mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#model.save('../models/state_adaptive1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[[6, 1, 4, 5, 7, 2, 0, 3],\n [7, 0, 4, 2, 3, 1, 5, 6],\n [0, 5, 6, 2, 4, 3, 7, 1],\n [2, 7, 6, 4, 3, 1, 5, 0],\n [0, 6, 4, 5, 2, 1, 7, 3],\n [5, 1, 0, 6, 4, 7, 3, 2],\n [4, 6, 1, 2, 5, 7, 0, 3],\n [2, 7, 4, 3, 5, 6, 0, 1]]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "train_rythm = make_rythm(BATCH_SIZE, SEQ_LEN, CHAR_DUR, device)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "acc, loss, _ = run(model, lookup, train_rythm, BATCH_SIZE, SEQ_LEN, CHAR_DUR, perm_num, device)\n",
    "\n",
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.loop.model.layers.control.initial_mem tensor(0.0011, device='cuda:0')\n",
      "model.layers.loop.model.layers.control_synapse.weight tensor(0.2593, device='cuda:0')\n",
      "model.layers.loop.model.layers.control_synapse.bias tensor(0.0592, device='cuda:0')\n",
      "model.layers.loop.model.layers.mem.initial_mem tensor(8.3642e-05, device='cuda:0')\n",
      "model.layers.loop.model.layers.mem_synapse.weight tensor(0.0198, device='cuda:0')\n",
      "model.layers.loop.model.layers.mem_synapse.bias tensor(0.0046, device='cuda:0')\n",
      "model.layers.output_synapse.weight tensor(0.1062, device='cuda:0')\n",
      "model.layers.output_synapse.bias tensor(0.0222, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, par in model.named_parameters():\n",
    "    print(name, par.grad.norm())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.loop.model.layers.control.initial_mem tensor(0.0011, device='cuda:0')\n",
      "model.layers.loop.model.layers.control_synapse.weight tensor(0.2593, device='cuda:0')\n",
      "model.layers.loop.model.layers.control_synapse.bias tensor(0.0592, device='cuda:0')\n",
      "model.layers.loop.model.layers.mem.initial_mem tensor(8.3642e-05, device='cuda:0')\n",
      "model.layers.loop.model.layers.mem_synapse.weight tensor(0.0198, device='cuda:0')\n",
      "model.layers.loop.model.layers.mem_synapse.bias tensor(0.0046, device='cuda:0')\n",
      "model.layers.output_synapse.weight tensor(0.1062, device='cuda:0')\n",
      "model.layers.output_synapse.bias tensor(0.0222, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, par in model.named_parameters():\n",
    "    print(name, par.grad.norm())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lookuplist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-25-8d218367e0c0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m     spamwriter = csv.writer(csvfile, delimiter=' ',\n\u001B[1;32m      4\u001B[0m                             quotechar='|', quoting=csv.QUOTE_MINIMAL)\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0mspamwriter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwriterows\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlookuplist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'lookuplist' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(f'../export/lookuplist.csv', 'w') as csvfile: #, newline=''\n",
    "    spamwriter = csv.writer(csvfile, delimiter=' ',\n",
    "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerows(lookuplist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lookuplist = torch.cat((torch.tensor(range(8)).view(8,1), lookup.cpu()), dim=1).tolist()\n",
    "lookuplist.insert(0, [15]+list(range(8)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lookuplist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ADAP_DECAY"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}