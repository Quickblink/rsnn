{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "from torch.distributions.geometric import Geometric\n",
    "from Code.envs.storerecall import make_batch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "USE_JIT = False\n",
    "\n",
    "#TODO: test device\n",
    "device = torch.device('cpu')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "spec2 = {'beta': 0.9,\n",
    "   'lr': 0.001,\n",
    "   'lr_decay': 0.8,\n",
    "   '1-beta': False,\n",
    "   'ported_weights': True,\n",
    "   'NoBias': True,\n",
    "   'iterations': 5000,\n",
    "   'batch_size': 128,\n",
    "   'mem_beta': 1,\n",
    "   'spkfn': 'ss',\n",
    "   'decay_out': False,\n",
    "   'architecture': '1L',\n",
    "   'control_neuron': 'LIF',\n",
    "   'mem_neuron': 'Cooldown'}\n",
    "\n",
    "spec = {'beta': 0.9,\n",
    "   'lr': 0.01,\n",
    "   'lr_decay': 0.8,\n",
    "   '1-beta': False,\n",
    "   'ported_weights': True,\n",
    "   'NoBias': True,\n",
    "   'iterations': 5000,\n",
    "   'batch_size': 128,\n",
    "   'mem_beta': 0.95,\n",
    "   'spkfn': 'bellec',\n",
    "   'decay_out': False,\n",
    "   'architecture': '2L',\n",
    "   'control_neuron': 'LIF',\n",
    "   'mem_neuron': 'Adaptive'}\n",
    "\n",
    "spec['iterations'] = 1000\n",
    "#spec['mem_beta'] = 0.9985\n",
    "#spec['mem_neuron'] = 'FlipFlop'\n",
    "spec['1-beta'] = 'improved'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('control', [[('input', 0.8), ('mem', 0.2)], LIFNeuron(), <class 'torch.nn.modules.linear.Linear'>]), ('mem', [[('control', 1)], AdaptiveNeuron(), <class 'torch.nn.modules.linear.Linear'>]), ('output', [[('control', 1), ('mem', 1)], BaseNeuron(), None])])\n"
     ]
    },
    {
     "data": {
      "text/plain": "OuterWrapper(\n  (model): DynNetwork(\n    (layers): ModuleDict(\n      (loop): SequenceWrapper(\n        (model): ParallelNetwork2(\n          (layers): ModuleDict(\n            (control): LIFNeuron()\n            (control_synapse): Linear(in_features=13, out_features=10, bias=False)\n            (mem): AdaptiveNeuron()\n            (mem_synapse): Linear(in_features=10, out_features=10, bias=False)\n            (output): BaseNeuron()\n          )\n        )\n      )\n      (output_synapse): Linear(in_features=20, out_features=1, bias=True)\n      (output): BaseNeuron()\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Code.everything3 import DynNetwork, OuterWrapper, BaseNeuron, SequenceWrapper, ParallelNetwork, \\\n",
    " SeqOnlySpike, CooldownNeuron, OutputNeuron, LIFNeuron, NoResetNeuron, AdaptiveNeuron, FlipFlopNeuron, ParallelNetwork2\n",
    "\n",
    "\n",
    "built_config = {\n",
    "    'target_rate': 0.01,\n",
    "    'BETA': spec['beta'],\n",
    "    'OFFSET': 7, # TODO: was 3 for config24\n",
    "    'SPIKE_FN': spec['spkfn'],\n",
    "    '1-beta': spec['1-beta'],\n",
    "    'ADAPDECAY': 0.9985,\n",
    "    'ADAPSCALE': 180\n",
    "}\n",
    "\n",
    "#TODO: changed here\n",
    "built_config['ADAPDECAY'] = 0.99\n",
    "\n",
    "mem_config = {\n",
    "    **built_config,\n",
    "    'BETA': spec['mem_beta']\n",
    "}\n",
    "\n",
    "n_input = 3\n",
    "n_control = 10\n",
    "n_mem = 10\n",
    "\n",
    "control_lookup = {\n",
    "    'LIF': LIFNeuron,\n",
    "    'Disc': SeqOnlySpike,\n",
    "    'NoReset': NoResetNeuron\n",
    "}\n",
    "\n",
    "mem_lookup = {\n",
    "    'Adaptive': AdaptiveNeuron,\n",
    "    'Cooldown': CooldownNeuron,\n",
    "    'NoReset': NoResetNeuron,\n",
    "    'FlipFlop': FlipFlopNeuron\n",
    "}\n",
    "\n",
    "control_neuron = control_lookup[spec['control_neuron']](n_control, built_config)\n",
    "mem_neuron = mem_lookup[spec['mem_neuron']](n_mem, mem_config)\n",
    "out_neuron = OutputNeuron(n_control+n_mem, built_config) if spec['decay_out'] else BaseNeuron(n_control+n_mem, built_config)\n",
    "\n",
    "\n",
    "loop_2L = OrderedDict([\n",
    "    ('input', n_input),\n",
    "    ('control', [['input', 'mem'], control_neuron, nn.Linear]),\n",
    "    ('mem', [['control'], mem_neuron, nn.Linear]),\n",
    "    ('output', [['control', 'mem'], out_neuron, None]),\n",
    "])\n",
    "\n",
    "loop_2L = OrderedDict([\n",
    "    ('input', (n_input, 0.1)),\n",
    "    ('control', [[('input', 0.8), ('mem', 0.2)], control_neuron, nn.Linear]),\n",
    "    ('mem', [['control'], mem_neuron, nn.Linear]),\n",
    "    ('output', [['control', 'mem'], out_neuron, None]),\n",
    "])\n",
    "\n",
    "\n",
    "loop_1L = OrderedDict([\n",
    "    ('input', n_input),\n",
    "    ('control', [['input', 'control', 'mem'], control_neuron, nn.Linear]),\n",
    "    ('mem', [['input', 'control', 'mem'], mem_neuron, nn.Linear]),\n",
    "    ('output', [['control', 'mem'], out_neuron, None]),\n",
    "])\n",
    "\n",
    "loop = loop_1L if spec['architecture'] == '1L' else loop_2L\n",
    "\n",
    "outer = OrderedDict([\n",
    "    ('input', n_input),\n",
    "    ('loop', [['input'], SequenceWrapper(ParallelNetwork2(loop, bias=(not spec['NoBias']))), None]),\n",
    "    ('output', [['loop'], BaseNeuron(1, None), nn.Linear]),\n",
    "])\n",
    "\n",
    "model = OuterWrapper(DynNetwork(outer), device)\n",
    "\n",
    "\n",
    "#loop_model = OuterWrapper(make_SequenceWrapper(ParallelNetwork(loop), USE_JIT), device, USE_JIT)\n",
    "\n",
    "#final_linear = nn.Linear(n_control+n_mem, 10).to(device)\n",
    "'''\n",
    "if spec['ported_weights']:\n",
    "    o_weights = pickle.load(open('weight_transplant_enc', 'rb'))\n",
    "\n",
    "    o1 = torch.tensor(o_weights['RecWeights/RecurrentWeight:0']).t()\n",
    "    o2 = torch.tensor(o_weights['InputWeights/InputWeight:0']).t()\n",
    "    o3 = torch.cat((o2, o1), dim=1)\n",
    "    with torch.no_grad():\n",
    "        model.pretrace.layers.loop.model.layers.control_synapse.weight.data[:,:300] = o3[:120] if spec['architecture'] == '1L' else o3[:120, :181]\n",
    "        model.pretrace.layers.loop.model.layers.mem_synapse.weight.data[:,:300] = o3[120:] if spec['architecture'] == '1L' else o3[120:, 180:]\n",
    "        model.pretrace.layers.output_synapse.weight.data = torch.tensor(o_weights['out_weight:0']).t()\n",
    "'''\n",
    "params = list(model.parameters())\n",
    "\n",
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "lr = spec['lr']\n",
    "optimizer = optim.Adam(params, lr=lr)\n",
    "bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "ITERATIONS = spec['iterations']#36000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'grad_norm': [],\n",
    "    'loss': [],\n",
    "    'acc': [],\n",
    "    'batch_var': [],\n",
    "    'val': []\n",
    "}\n",
    "\n",
    "grad_norm_history = []\n",
    "def record_norm():\n",
    "    norms = []\n",
    "    for p in params:\n",
    "        norms.append(p.grad.norm().item())\n",
    "    stats['grad_norm'].append(torch.tensor(norms).norm().item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "store_dist = (lambda : Geometric(torch.tensor([0.2], device=device)).sample().int().item()+1)\n",
    "recall_dist = (lambda : Geometric(torch.tensor([0.2], device=device)).sample().int().item()+1)\n",
    "SEQ_LEN = 13\n",
    "CHAR_DUR = 100 #100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6980491280555725 0.4615384638309479\n",
      "0.6912876963615417 0.53125\n",
      "0.6945928335189819 0.4937500059604645\n",
      "0.6926613450050354 0.5176470875740051\n",
      "0.692464292049408 0.5180723071098328\n",
      "0.6941355466842651 0.4909090995788574\n",
      "0.6953136324882507 0.4651162922382355\n",
      "0.692665159702301 0.516853928565979\n",
      "0.6918294429779053 0.5388888716697693\n",
      "0.6933203935623169 0.5029585957527161\n",
      "0.6914700269699097 0.5548780560493469\n",
      "0.6935720443725586 0.488095223903656\n",
      "0.693030059337616 0.5062500238418579\n",
      "0.6929141283035278 0.5061728358268738\n",
      "0.6930458545684814 0.5060241222381592\n",
      "0.6941492557525635 0.4712643623352051\n",
      "0.6939691305160522 0.46590909361839294\n",
      "0.6930348873138428 0.5059523582458496\n",
      "0.6924463510513306 0.5408805012702942\n",
      "0.6933730840682983 0.4868420958518982\n",
      "0.6933730840682983 0.693366214632988 0.5034626662731171 5.985118389129639 3\n",
      "0.693767786026001 0.4628571569919586\n",
      "0.6936329007148743 0.5\n",
      "0.6931872367858887 0.5\n",
      "0.6932290196418762 0.45783132314682007\n",
      "0.6931511759757996 0.5065789222717285\n",
      "0.69318687915802 0.44378697872161865\n",
      "0.6932525634765625 0.4969325065612793\n",
      "0.6932387948036194 0.5060975551605225\n",
      "0.6930425763130188 0.5087719559669495\n",
      "0.6928862929344177 0.6153846383094788\n",
      "0.693598747253418 0.44171780347824097\n",
      "0.6933240294456482 0.48148149251937866\n",
      "0.6925453543663025 0.5341615080833435\n",
      "0.6924646496772766 0.5411764979362488\n",
      "0.6932486891746521 0.4787878692150116\n",
      "0.691911518573761 0.5574712753295898\n",
      "0.6935179829597473 0.5\n",
      "0.6918889880180359 0.5344827771186829\n",
      "0.6931745409965515 0.5\n",
      "0.6935235261917114 0.5\n",
      "0.6935235261917114 0.6930886626243591 0.5033760130405426 6.0289623737335205 3\n",
      "0.6926184892654419 0.5093167424201965\n",
      "0.6892982125282288 0.5964912176132202\n",
      "0.692969024181366 0.5153374075889587\n",
      "0.6934959888458252 0.5028901696205139\n",
      "0.6924730539321899 0.5151515007019043\n",
      "0.6919689178466797 0.522988498210907\n",
      "0.6946960091590881 0.4795321524143219\n",
      "0.6915668249130249 0.5180723071098328\n",
      "0.6936285495758057 0.4879518151283264\n",
      "0.6895229816436768 0.562841534614563\n",
      "0.6926672458648682 0.5146198868751526\n",
      "0.6980395317077637 0.4371257424354553\n",
      "0.6902406811714172 0.5481927990913391\n",
      "0.6949896216392517 0.47852760553359985\n",
      "0.6963742971420288 0.46107783913612366\n",
      "0.6962028741836548 0.4610389471054077\n",
      "0.69416743516922 0.49418604373931885\n",
      "0.6893308758735657 0.5644171833992004\n",
      "0.6913010478019714 0.5367231369018555\n",
      "0.6922027468681335 0.5088757276535034\n",
      "0.6922027468681335 0.69288772046566 0.510767912864685 6.053886651992798 3\n",
      "0.6932515501976013 0.49696969985961914\n",
      "0.6931108236312866 0.5120481848716736\n",
      "0.6950437426567078 0.45962733030319214\n",
      "0.6921684741973877 0.5141242742538452\n",
      "0.6905313730239868 0.5639534592628479\n",
      "0.6908681988716125 0.5502958297729492\n",
      "0.6946253776550293 0.4393063485622406\n",
      "0.6913118958473206 0.5449438095092773\n",
      "0.6927083730697632 0.5\n",
      "0.6927115321159363 0.49367088079452515\n",
      "0.691720187664032 0.5263158082962036\n",
      "0.6912051439285278 0.5625\n",
      "0.6930581331253052 0.4761904776096344\n",
      "0.6931954026222229 0.47159090638160706\n",
      "0.6921105980873108 0.5086705088615417\n",
      "0.6928254961967468 0.4937500059604645\n",
      "0.6914682388305664 0.5279502868652344\n",
      "0.6906388998031616 0.5555555820465088\n",
      "0.6931226253509521 0.4736842215061188\n",
      "0.6927037835121155 0.5030303001403809\n",
      "0.6927037835121155 0.6924189925193787 0.5087088957428932 5.481426477432251 3\n",
      "0.6921936273574829 0.522988498210907\n",
      "0.6902354955673218 0.5714285969734192\n",
      "0.6913968920707703 0.5089820623397827\n",
      "0.6908082365989685 0.5411764979362488\n",
      "0.6945825815200806 0.43396225571632385\n",
      "0.6916390061378479 0.521212100982666\n",
      "0.692327618598938 0.49438202381134033\n",
      "0.6926370859146118 0.5060241222381592\n",
      "0.6911957859992981 0.5325443744659424\n",
      "0.6966289281845093 0.396341472864151\n",
      "0.6920236945152283 0.5059523582458496\n",
      "0.6916700601577759 0.5090909004211426\n",
      "0.6921052932739258 0.4941176474094391\n",
      "0.6914766430854797 0.5146198868751526\n",
      "0.6928017139434814 0.44252872467041016\n",
      "0.6929402351379395 0.46783626079559326\n",
      "0.6927993297576904 0.5090909004211426\n",
      "0.6910412311553955 0.6627907156944275\n",
      "0.691503643989563 0.5764706134796143\n",
      "0.6913022994995117 0.5621301531791687\n",
      "0.6913022994995117 0.692165470123291 0.5136835083365441 5.979782342910767 3\n",
      "0.6915143728256226 0.52601158618927\n",
      "0.6910654306411743 0.5028901696205139\n",
      "0.6898573040962219 0.5681818127632141\n",
      "0.6911506652832031 0.4883720874786377\n",
      "0.6920679807662964 0.5059523582458496\n",
      "0.6943912506103516 0.4457831382751465\n",
      "0.6920406818389893 0.49444442987442017\n",
      "0.6942656636238098 0.4491018056869507\n",
      "0.6912973523139954 0.4761904776096344\n",
      "0.6948135495185852 0.41420117020606995\n",
      "0.6908633708953857 0.522988498210907\n",
      "0.6908364295959473 0.5235294103622437\n",
      "0.6895835399627686 0.5928143858909607\n",
      "0.6889902949333191 0.6812499761581421\n",
      "0.6896568536758423 0.6387096643447876\n",
      "0.6892297863960266 0.6190476417541504\n",
      "0.6894239187240601 0.6405228972434998\n",
      "0.6883767247200012 0.5642458200454712\n",
      "0.6900023818016052 0.543749988079071\n",
      "0.6887037754058838 0.5889570713043213\n",
      "0.6887037754058838 0.6909065663814544 0.5393472194671631 5.6406333446502686 3\n",
      "0.6904827952384949 0.6143791079521179\n",
      "0.6905473470687866 0.5272727012634277\n",
      "0.6869258880615234 0.6424242258071899\n",
      "0.688470184803009 0.6211180090904236\n",
      "0.6873306632041931 0.6628571152687073\n",
      "0.6891260147094727 0.5786163806915283\n",
      "0.6872611045837402 0.625\n",
      "0.6863725185394287 0.5964912176132202\n",
      "0.6870039701461792 0.6121212244033813\n",
      "0.6866692304611206 0.6057142615318298\n",
      "0.6942049264907837 0.526627242565155\n",
      "0.6941026449203491 0.522988498210907\n",
      "0.6820767521858215 0.5773809552192688\n",
      "0.6824976205825806 0.6529411673545837\n",
      "0.6860894560813904 0.6235294342041016\n",
      "0.6870539784431458 0.6309523582458496\n",
      "0.6858721375465393 0.5620915293693542\n",
      "0.6877805590629578 0.4968944191932678\n",
      "0.6832452416419983 0.6000000238418579\n",
      "0.6844511032104492 0.5087719559669495\n",
      "0.6844511032104492 0.6873782068490982 0.5894085913896561 5.793396472930908 3\n",
      "0.6818615198135376 0.5433526039123535\n",
      "0.6855113506317139 0.5155279636383057\n",
      "0.6796417832374573 0.56886225938797\n",
      "0.6864848732948303 0.4795321524143219\n",
      "0.6841712594032288 0.5235294103622437\n",
      "0.6817299127578735 0.6107784509658813\n",
      "0.6814018487930298 0.625\n",
      "0.6702446937561035 0.7212121486663818\n",
      "0.680783212184906 0.6024096608161926\n",
      "0.6749715805053711 0.645348846912384\n",
      "0.6755467653274536 0.6529411673545837\n",
      "0.679423451423645 0.6198830604553223\n",
      "0.6798595786094666 0.678787887096405\n",
      "0.682270348072052 0.5853658318519592\n",
      "0.6737529635429382 0.7017543911933899\n",
      "0.6823152899742126 0.5857987999916077\n",
      "0.6810528039932251 0.6187845468521118\n",
      "0.676372230052948 0.6402438879013062\n",
      "0.6752658486366272 0.6158192157745361\n",
      "0.6699105501174927 0.7127071619033813\n",
      "0.6699105501174927 0.6791285932064056 0.6123819723725319 5.927525520324707 3\n",
      "0.6764528751373291 0.6395348906517029\n",
      "0.6728125810623169 0.6823529601097107\n",
      "0.6720967292785645 0.6325300931930542\n",
      "0.6756102442741394 0.6000000238418579\n",
      "0.6775716543197632 0.6097561120986938\n",
      "0.6777824759483337 0.6312500238418579\n",
      "0.6711553335189819 0.6158536672592163\n",
      "0.6712700128555298 0.6459627151489258\n",
      "0.6648501753807068 0.6745561957359314\n",
      "0.6669619083404541 0.6395348906517029\n",
      "0.6712197661399841 0.6385542154312134\n",
      "0.6723567247390747 0.6206896305084229\n",
      "0.6610008478164673 0.658823549747467\n",
      "0.6595936417579651 0.6568047404289246\n",
      "0.6566441059112549 0.7052023410797119\n",
      "0.6729369163513184 0.5987654328346252\n",
      "0.6491822004318237 0.7116564512252808\n",
      "0.6599991321563721 0.6395348906517029\n",
      "0.6538931727409363 0.6627218723297119\n",
      "0.6584786772727966 0.6845238208770752\n",
      "0.6584786772727966 0.6670934587717057 0.6474304258823395 5.432356834411621 3\n",
      "0.6583608388900757 0.6257668733596802\n",
      "0.6518151760101318 0.6745561957359314\n",
      "0.6570216417312622 0.680232584476471\n",
      "0.6747124791145325 0.6369426846504211\n",
      "0.6507378816604614 0.6768292784690857\n",
      "0.6646891832351685 0.6607142686843872\n",
      "0.6533207297325134 0.7055214643478394\n",
      "0.667046308517456 0.6000000238418579\n",
      "0.6596109867095947 0.6647058725357056\n",
      "0.6495623588562012 0.742514967918396\n",
      "0.6506016254425049 0.699386477470398\n",
      "0.6430601477622986 0.7573964595794678\n",
      "0.6646191477775574 0.6196318864822388\n",
      "0.6478610038757324 0.6909090876579285\n",
      "0.6398597359657288 0.75\n",
      "0.6403111815452576 0.7543859481811523\n",
      "0.6440766453742981 0.7215189933776855\n",
      "0.6427541971206665 0.6894409656524658\n",
      "0.6465103030204773 0.6407185792922974\n",
      "0.6419787406921387 0.668571412563324\n",
      "0.6419787406921387 0.6524255156517029 0.6829872012138367 5.458093643188477 3\n",
      "0.6253541707992554 0.7117646932601929\n",
      "0.6405175924301147 0.7133758068084717\n",
      "0.6487188935279846 0.604651153087616\n",
      "0.6284551620483398 0.6785714030265808\n",
      "0.6272267699241638 0.7048192620277405\n",
      "0.6256482005119324 0.7041420340538025\n",
      "0.6624082326889038 0.5757575631141663\n",
      "0.6085440516471863 0.6954023241996765\n",
      "0.6359777450561523 0.6424580812454224\n",
      "0.6433475613594055 0.6499999761581421\n",
      "0.634635329246521 0.6380367875099182\n",
      "0.6265666484832764 0.6583850979804993\n",
      "0.633861780166626 0.699386477470398\n",
      "0.6214202642440796 0.7055214643478394\n",
      "0.6277486085891724 0.6568047404289246\n",
      "0.6377276182174683 0.648809552192688\n",
      "0.6540800333023071 0.5952380895614624\n",
      "0.6154951453208923 0.6568047404289246\n",
      "0.63992840051651 0.6149068474769592\n",
      "0.6262004375457764 0.6547619104385376\n",
      "0.6262004375457764 0.6331931322813034 0.6604799002408981 5.879492521286011 3\n",
      "0.643962025642395 0.6149425506591797\n",
      "0.6287059783935547 0.6606060862541199\n",
      "0.6244557499885559 0.6534090638160706\n",
      "0.6108627915382385 0.6436781883239746\n",
      "0.6085216403007507 0.7093023061752319\n",
      "0.6278905272483826 0.6645569801330566\n",
      "0.5850171446800232 0.7692307829856873\n",
      "0.5986473560333252 0.7333333492279053\n",
      "0.6049076914787292 0.7371794581413269\n",
      "0.6297973394393921 0.6545454263687134\n",
      "0.5968158841133118 0.7212121486663818\n",
      "0.6218045353889465 0.6227545142173767\n",
      "0.6045699119567871 0.6829268336296082\n",
      "0.6270070672035217 0.6257668733596802\n",
      "0.5783894062042236 0.6964285969734192\n",
      "0.607309877872467 0.704402506351471\n",
      "0.615563690662384 0.7005987763404846\n",
      "0.6291100382804871 0.6628571152687073\n",
      "0.610270082950592 0.6706587076187134\n",
      "0.5804001092910767 0.7048192620277405\n",
      "0.5804001092910767 0.6117004424333572 0.6816604763269425 6.064690589904785 3\n",
      "0.5978037714958191 0.6909090876579285\n",
      "0.5766901969909668 0.7108433842658997\n",
      "0.599798321723938 0.6937500238418579\n",
      "0.5910069346427917 0.6994535326957703\n",
      "0.5868225693702698 0.7247191071510315\n",
      "0.5973749160766602 0.6481481194496155\n",
      "0.5929955840110779 0.6666666865348816\n",
      "0.6086931824684143 0.6190476417541504\n",
      "0.5877891182899475 0.6625000238418579\n",
      "0.565945029258728 0.719298243522644\n",
      "0.5821348428726196 0.6969696879386902\n",
      "0.5924070477485657 0.6666666865348816\n",
      "0.5709588527679443 0.645348846912384\n",
      "0.5765711069107056 0.6842105388641357\n",
      "0.5631701350212097 0.6941176652908325\n",
      "0.5390735268592834 0.7900552749633789\n",
      "0.5605039596557617 0.6951219439506531\n",
      "0.5968924760818481 0.6325300931930542\n",
      "0.5670121312141418 0.6987951993942261\n",
      "0.5909383296966553 0.652694582939148\n",
      "0.5909383296966553 0.5822291016578675 0.684592318534851 5.403172731399536 3\n",
      "0.568821132183075 0.6766467094421387\n",
      "0.597487211227417 0.6568047404289246\n",
      "0.544728696346283 0.7514792680740356\n",
      "0.5888380408287048 0.6566265225410461\n",
      "0.59684157371521 0.613095223903656\n",
      "0.5753998160362244 0.662420392036438\n",
      "0.5869660973548889 0.6397515535354614\n",
      "0.5753881931304932 0.6707317233085632\n",
      "0.5791012048721313 0.6499999761581421\n",
      "0.5719822645187378 0.682634711265564\n",
      "0.5630069971084595 0.6971428394317627\n",
      "0.5239238142967224 0.7722222208976746\n",
      "0.5613436698913574 0.7142857313156128\n",
      "0.5663612484931946 0.6863905191421509\n",
      "0.5620997548103333 0.7058823704719543\n",
      "0.5678574442863464 0.6705202460289001\n",
      "0.5905578136444092 0.650306761264801\n",
      "0.5622807145118713 0.7011494040489197\n",
      "0.5178155303001404 0.7643678188323975\n",
      "0.4923684000968933 0.8106508851051331\n",
      "0.4923684000968933 0.5646584808826447 0.6916554808616638 5.38537073135376 3\n",
      "0.5630518794059753 0.7090908885002136\n",
      "0.5570014119148254 0.6982248425483704\n",
      "0.5312317609786987 0.7398843765258789\n",
      "0.5520654320716858 0.695652186870575\n",
      "0.5058274865150452 0.7657142877578735\n",
      "0.5808742046356201 0.6725146174430847\n",
      "0.5334693789482117 0.7247191071510315\n",
      "0.5501901507377625 0.7250000238418579\n",
      "0.5351831316947937 0.6770186424255371\n",
      "0.4986093044281006 0.7758620977401733\n",
      "0.5568192601203918 0.7018633484840393\n",
      "0.5243839025497437 0.7118644118309021\n",
      "0.6045188307762146 0.6227545142173767\n",
      "0.5497294068336487 0.7017543911933899\n",
      "0.5537079572677612 0.6910112500190735\n",
      "0.5584441423416138 0.6625000238418579\n",
      "0.5201939940452576 0.7109826803207397\n",
      "0.5657938122749329 0.6687116622924805\n",
      "0.5554648637771606 0.6823529601097107\n",
      "0.49542680382728577 0.7305389046669006\n",
      "0.49542680382728577 0.5445993557572365 0.7034007608890533 5.45185923576355 3\n",
      "0.5684189200401306 0.6746987700462341\n",
      "0.5483377575874329 0.719298243522644\n",
      "0.48895132541656494 0.75\n",
      "0.5104299187660217 0.7333333492279053\n",
      "0.5616580247879028 0.6746987700462341\n",
      "0.45681387186050415 0.7515528202056885\n",
      "0.4615064859390259 0.7954545617103577\n",
      "0.5172985792160034 0.7749999761581421\n",
      "0.5659725069999695 0.6792452931404114\n",
      "0.4959472119808197 0.7361963391304016\n",
      "0.5712836384773254 0.6976743936538696\n",
      "0.5088579654693604 0.7528735399246216\n",
      "0.4899943470954895 0.7604790329933167\n",
      "0.5289377570152283 0.7356321811676025\n",
      "0.48697471618652344 0.7777777910232544\n",
      "0.5336845517158508 0.7090908885002136\n",
      "0.49611571431159973 0.7575757503509521\n",
      "0.4931551516056061 0.7485380172729492\n",
      "0.4842517375946045 0.7610062956809998\n",
      "0.5021615624427795 0.7298850417137146\n",
      "0.5021615624427795 0.5135375872254372 0.7360005527734756 5.2682178020477295 3\n",
      "0.47126251459121704 0.7514792680740356\n",
      "0.43511906266212463 0.7966101765632629\n",
      "0.5451377630233765 0.7151514887809753\n",
      "0.48339587450027466 0.7701863646507263\n",
      "0.39875537157058716 0.8433734774589539\n",
      "0.4244605004787445 0.8035714030265808\n",
      "0.42433062195777893 0.8192771077156067\n",
      "0.4591238796710968 0.7678571343421936\n",
      "0.4032689332962036 0.7965116500854492\n",
      "0.46166396141052246 0.7804877758026123\n",
      "0.48036348819732666 0.7797619104385376\n",
      "0.44638508558273315 0.7844311594963074\n",
      "0.38957467675209045 0.8139534592628479\n",
      "0.45045551657676697 0.7777777910232544\n",
      "0.43246230483055115 0.793749988079071\n",
      "0.43208572268486023 0.7941176295280457\n",
      "0.4231531322002411 0.8139534592628479\n",
      "0.46171998977661133 0.793749988079071\n",
      "0.4797682464122772 0.7810651063919067\n",
      "0.46022701263427734 0.802395224571228\n",
      "0.46022701263427734 0.4481356829404831 0.7889730781316757 5.279528379440308 3\n",
      "0.4692581295967102 0.7701863646507263\n",
      "0.5345926880836487 0.7349397540092468\n",
      "0.4356703758239746 0.792682945728302\n",
      "0.6360551714897156 0.6946107745170593\n",
      "0.47938454151153564 0.75\n",
      "0.4825393259525299 0.7941176295280457\n",
      "0.5015385746955872 0.7485380172729492\n",
      "0.4059017300605774 0.8209876418113708\n",
      "0.436259925365448 0.7914110422134399\n",
      "0.41610366106033325 0.7976878881454468\n",
      "0.4780700206756592 0.7529411911964417\n",
      "0.46971410512924194 0.7951807379722595\n",
      "0.4129990339279175 0.8106508851051331\n",
      "0.46102669835090637 0.7878788113594055\n",
      "0.3989546298980713 0.7928994297981262\n",
      "0.3840756118297577 0.841176450252533\n",
      "0.46243828535079956 0.7758620977401733\n",
      "0.3316934406757355 0.8483145833015442\n",
      "0.4427449405193329 0.7771084308624268\n",
      "0.448800653219223 0.7836257219314575\n",
      "0.448800653219223 0.45439107716083527 0.7830400198698044 5.2562172412872314 3\n",
      "0.48821771144866943 0.7440476417541504\n",
      "0.4158787131309509 0.8404908180236816\n",
      "0.4479299485683441 0.759036123752594\n",
      "0.4952245354652405 0.7745664715766907\n",
      "0.4305015206336975 0.8152866363525391\n",
      "0.41781342029571533 0.7904191613197327\n",
      "0.5132651925086975 0.7542856931686401\n",
      "0.4056704044342041 0.8083832263946533\n",
      "0.5193846225738525 0.7329192757606506\n",
      "0.4103187620639801 0.824999988079071\n",
      "0.5001023411750793 0.7528735399246216\n",
      "0.4132426381111145 0.8034682273864746\n",
      "0.48996639251708984 0.7594936490058899\n",
      "0.4154054522514343 0.8271604776382446\n",
      "0.4823175370693207 0.7439024448394775\n",
      "0.41219526529312134 0.8245614171028137\n",
      "0.46106284856796265 0.7906976938247681\n",
      "0.482331246137619 0.7727272510528564\n",
      "0.4785066843032837 0.7803468108177185\n",
      "0.4731084108352661 0.759036123752594\n",
      "0.4731084108352661 0.4576221823692322 0.7829351335763931 5.266237497329712 3\n",
      "0.3274630308151245 0.8647058606147766\n",
      "0.46406981348991394 0.773809552192688\n",
      "0.47982436418533325 0.7544910311698914\n",
      "0.41309574246406555 0.8057143092155457\n",
      "0.43402254581451416 0.8035714030265808\n",
      "0.49645042419433594 0.7636363506317139\n",
      "0.4253641664981842 0.7966101765632629\n",
      "0.3681253492832184 0.856249988079071\n",
      "0.42254638671875 0.7941176295280457\n",
      "0.4164356291294098 0.8098159432411194\n",
      "0.39823397994041443 0.8208092451095581\n",
      "0.4897545278072357 0.7267080545425415\n",
      "0.48382237553596497 0.7682926654815674\n",
      "0.5698509216308594 0.7106918096542358\n",
      "0.4569396376609802 0.8024691343307495\n",
      "0.37089017033576965 0.8176100850105286\n",
      "0.37833043932914734 0.8390804529190063\n",
      "0.4253147542476654 0.7976190447807312\n",
      "0.4747965931892395 0.7784810066223145\n",
      "0.4360942840576172 0.8083832263946533\n",
      "0.4360942840576172 0.4365712568163872 0.794643348455429 5.26776647567749 3\n",
      "0.5001125931739807 0.763005793094635\n",
      "0.4033910930156708 0.8294117450714111\n",
      "0.394459068775177 0.8518518805503845\n",
      "0.414630264043808 0.8062499761581421\n",
      "0.4317197799682617 0.8208092451095581\n",
      "0.37557679414749146 0.800000011920929\n",
      "0.42169201374053955 0.7953216433525085\n",
      "0.42151176929473877 0.7894737124443054\n",
      "0.4460016191005707 0.7721518874168396\n",
      "0.42165887355804443 0.7941176295280457\n",
      "0.44435080885887146 0.8086419701576233\n",
      "0.517654538154602 0.7333333492279053\n",
      "0.4307580292224884 0.7935484051704407\n",
      "0.41921016573905945 0.8121212124824524\n",
      "0.533000648021698 0.7239263653755188\n",
      "0.45906007289886475 0.7808988690376282\n",
      "0.4383430778980255 0.7836257219314575\n",
      "0.45316484570503235 0.8086419701576233\n",
      "0.43975830078125 0.7818182110786438\n",
      "0.47595953941345215 0.7469879388809204\n",
      "0.47595953941345215 0.44210069477558134 0.7897968769073487 5.265061140060425 3\n",
      "0.5446704030036926 0.7212121486663818\n",
      "0.4730551540851593 0.7818182110786438\n",
      "0.5012909173965454 0.7528735399246216\n",
      "0.4357790946960449 0.8284023404121399\n",
      "0.4269007742404938 0.8106508851051331\n",
      "0.5002653002738953 0.7639751434326172\n",
      "0.44695988297462463 0.7911392450332642\n",
      "0.46562841534614563 0.7710843086242676\n",
      "0.47721394896507263 0.7719298005104065\n",
      "0.44737809896469116 0.8062499761581421\n",
      "0.4082750380039215 0.8245614171028137\n",
      "0.43209031224250793 0.7965116500854492\n",
      "0.4229898750782013 0.7861271500587463\n",
      "0.3908117413520813 0.8117647171020508\n",
      "0.47700005769729614 0.7515151500701904\n",
      "0.4256346821784973 0.800000011920929\n",
      "0.411705881357193 0.7941176295280457\n",
      "0.43997398018836975 0.805031418800354\n",
      "0.41918617486953735 0.7848837375640869\n",
      "0.4728966951370239 0.8074533939361572\n",
      "0.4728966951370239 0.45098532140254977 0.7880650937557221 5.28192663192749 3\n",
      "0.3943774998188019 0.7939394116401672\n",
      "0.4420628845691681 0.7904191613197327\n",
      "0.4488324820995331 0.7823529243469238\n",
      "0.410205602645874 0.8421052694320679\n",
      "0.42721423506736755 0.8058823347091675\n",
      "0.5149461030960083 0.7278106212615967\n",
      "0.4343576431274414 0.8047337532043457\n",
      "0.4691900908946991 0.7865853905677795\n",
      "0.5146310329437256 0.7515151500701904\n",
      "0.4750957489013672 0.7660818696022034\n",
      "0.5075493454933167 0.7582417726516724\n",
      "0.47684746980667114 0.7687861323356628\n",
      "0.46126240491867065 0.7771084308624268\n",
      "0.42949408292770386 0.7740113139152527\n",
      "0.4089313745498657 0.8176470398902893\n",
      "0.39968281984329224 0.8214285969734192\n",
      "0.485322505235672 0.7349397540092468\n",
      "0.5058608055114746 0.748603343963623\n",
      "0.4185226559638977 0.7828571200370789\n",
      "0.4008926749229431 0.8181818127632141\n",
      "0.4008926749229431 0.4512639731168747 0.7826615601778031 5.161569118499756 3\n",
      "0.3533056974411011 0.8470588326454163\n",
      "0.4168962240219116 0.8109756112098694\n",
      "0.41352227330207825 0.8079096078872681\n",
      "0.42219221591949463 0.8132529854774475\n",
      "0.42040306329727173 0.8187500238418579\n",
      "0.46252015233039856 0.7882353067398071\n",
      "0.43309491872787476 0.8024691343307495\n",
      "0.4477703869342804 0.8047337532043457\n",
      "0.5230790376663208 0.739393949508667\n",
      "0.3871157169342041 0.851190447807312\n",
      "0.4329327344894409 0.7885714173316956\n",
      "0.417706161737442 0.8011049628257751\n",
      "0.3836063742637634 0.8314606547355652\n",
      "0.40516993403434753 0.8305084705352783\n",
      "0.4848393201828003 0.7660818696022034\n",
      "0.41405731439590454 0.8044692873954773\n",
      "0.41814374923706055 0.819767415523529\n",
      "0.39815422892570496 0.8117647171020508\n",
      "0.4451052248477936 0.7865168452262878\n",
      "0.43810153007507324 0.7976878881454468\n",
      "0.43810153007507324 0.42588581293821337 0.8060951590538025 5.154164791107178 3\n",
      "0.4132550358772278 0.7953216433525085\n",
      "0.4085073173046112 0.8387096524238586\n",
      "0.39711683988571167 0.7988505959510803\n",
      "0.38488420844078064 0.7914110422134399\n",
      "0.3875497877597809 0.8303030133247375\n",
      "0.37654051184654236 0.8333333134651184\n",
      "0.41811272501945496 0.800000011920929\n",
      "0.4921185076236725 0.7484662532806396\n",
      "0.4427206516265869 0.7836257219314575\n",
      "0.39344853162765503 0.8148148059844971\n",
      "0.4813489317893982 0.7514792680740356\n",
      "0.36187320947647095 0.8588957190513611\n",
      "0.4339561462402344 0.8048780560493469\n",
      "0.33904218673706055 0.8362573385238647\n",
      "0.4128241240978241 0.8128654956817627\n",
      "0.4638199508190155 0.803680956363678\n",
      "0.4688849449157715 0.8136646151542664\n",
      "0.4817526340484619 0.7544910311698914\n",
      "0.47056663036346436 0.7612903118133545\n",
      "0.4515930712223053 0.7751479148864746\n",
      "0.4515930712223053 0.42399579733610154 0.8003743380308151 5.171081066131592 3\n",
      "0.43831774592399597 0.7743902206420898\n",
      "0.46738824248313904 0.7831325531005859\n",
      "0.4216145873069763 0.8383233547210693\n",
      "0.43859317898750305 0.7954545617103577\n",
      "0.4347771108150482 0.8139534592628479\n",
      "0.4341796934604645 0.8117647171020508\n",
      "0.45090100169181824 0.7454545497894287\n",
      "0.4458239674568176 0.8012422323226929\n",
      "0.4548777937889099 0.7530864477157593\n",
      "0.4447389841079712 0.8282208442687988\n",
      "0.45470115542411804 0.7988165616989136\n",
      "0.3813151717185974 0.8443113565444946\n",
      "0.41574862599372864 0.8150289058685303\n",
      "0.41845592856407166 0.854651153087616\n",
      "0.4244626760482788 0.8271604776382446\n",
      "0.44493362307548523 0.7962962985038757\n",
      "0.4465247690677643 0.773809552192688\n",
      "0.4191359579563141 0.7916666865348816\n",
      "0.40972238779067993 0.826815664768219\n",
      "0.471648633480072 0.7664670944213867\n",
      "0.471648633480072 0.4358930617570877 0.8020023345947266 5.151981353759766 3\n",
      "0.46394145488739014 0.803680956363678\n",
      "0.42035117745399475 0.7836257219314575\n",
      "0.38181596994400024 0.8418079018592834\n",
      "0.42793020606040955 0.7852760553359985\n",
      "0.3910004794597626 0.802395224571228\n",
      "0.3532072603702545 0.8678160905838013\n",
      "0.4867365062236786 0.7816091775894165\n",
      "0.47297796607017517 0.7654321193695068\n",
      "0.4095330238342285 0.8132529854774475\n",
      "0.44059544801712036 0.8048780560493469\n",
      "0.4514697790145874 0.773809552192688\n",
      "0.41219383478164673 0.8208092451095581\n",
      "0.3794417679309845 0.8070175647735596\n",
      "0.44235795736312866 0.7911392450332642\n",
      "0.38845744729042053 0.8165680766105652\n",
      "0.4381560981273651 0.7931034564971924\n",
      "0.43978092074394226 0.819767415523529\n",
      "0.40876469016075134 0.8086419701576233\n",
      "0.461716890335083 0.805031418800354\n",
      "0.4623342454433441 0.8132529854774475\n",
      "0.4623342454433441 0.4266381561756134 0.8049457609653473 5.170207262039185 3\n",
      "0.4928211271762848 0.8011363744735718\n",
      "0.492780476808548 0.7405063509941101\n",
      "0.413659006357193 0.826347291469574\n",
      "0.34373989701271057 0.8563218116760254\n",
      "0.3640798032283783 0.8148148059844971\n",
      "0.423355370759964 0.7857142686843872\n",
      "0.3660376965999603 0.8588957190513611\n",
      "0.4320405125617981 0.8271604776382446\n",
      "0.37978896498680115 0.8520709872245789\n",
      "0.47578176856040955 0.8060606122016907\n",
      "0.4961062967777252 0.7804877758026123\n",
      "0.3874981999397278 0.8370786309242249\n",
      "0.43267571926116943 0.8128654956817627\n",
      "0.3835501968860626 0.819767415523529\n",
      "0.3612596094608307 0.8352272510528564\n",
      "0.4843445420265198 0.7437499761581421\n",
      "0.39174404740333557 0.845714271068573\n",
      "0.4280751049518585 0.8242424130439758\n",
      "0.4241361618041992 0.8275862336158752\n",
      "0.5028035044670105 0.759036123752594\n",
      "0.5028035044670105 0.42381390035152433 0.8127392143011093 5.233158826828003 3\n",
      "0.4936894476413727 0.790123462677002\n",
      "0.42357712984085083 0.8097826242446899\n",
      "0.4659535586833954 0.8139534592628479\n",
      "0.4358445703983307 0.7916666865348816\n",
      "0.5340556502342224 0.7052023410797119\n",
      "0.3407761752605438 0.8418079018592834\n",
      "0.43954065442085266 0.7852760553359985\n",
      "0.42059701681137085 0.8117647171020508\n",
      "0.44511038064956665 0.8012048006057739\n",
      "0.405724436044693 0.7869822382926941\n",
      "0.43970075249671936 0.7647058963775635\n",
      "0.48231634497642517 0.7891566157341003\n",
      "0.5128435492515564 0.7195122241973877\n",
      "0.4277350604534149 0.8048780560493469\n",
      "0.4993121325969696 0.7177914381027222\n",
      "0.5045619606971741 0.7052023410797119\n",
      "0.46098965406417847 0.7471910119056702\n",
      "0.5772188305854797 0.695652186870575\n",
      "0.5341339111328125 0.7048192620277405\n",
      "0.44251587986946106 0.7882353067398071\n",
      "0.44251587986946106 0.4643098548054695 0.768745431303978 5.1764044761657715 3\n",
      "0.45925450325012207 0.7647058963775635\n",
      "0.44097745418548584 0.7777777910232544\n",
      "0.47911325097084045 0.7514792680740356\n",
      "0.42966073751449585 0.7658227682113647\n",
      "0.4806186854839325 0.7784430980682373\n",
      "0.44682732224464417 0.7784430980682373\n",
      "0.41479194164276123 0.7747252583503723\n",
      "0.4990730583667755 0.7169811129570007\n",
      "0.42018455266952515 0.7906976938247681\n",
      "0.40422824025154114 0.8181818127632141\n",
      "0.43231046199798584 0.7719298005104065\n",
      "0.41014835238456726 0.7777777910232544\n",
      "0.4452958106994629 0.7454545497894287\n",
      "0.44311532378196716 0.7515151500701904\n",
      "0.43684712052345276 0.7798742055892944\n",
      "0.43149566650390625 0.7840909361839294\n",
      "0.4624652564525604 0.7668711543083191\n",
      "0.4504748582839966 0.792682945728302\n",
      "0.4503325819969177 0.7848101258277893\n",
      "0.41054996848106384 0.7757575511932373\n",
      "0.41054996848106384 0.4423882573843002 0.77240110039711 5.165843963623047 3\n",
      "0.4304620325565338 0.7987805008888245\n",
      "0.43726152181625366 0.7664670944213867\n",
      "0.42683154344558716 0.7882353067398071\n",
      "0.4749642312526703 0.7564102411270142\n",
      "0.4248434007167816 0.7730061411857605\n",
      "0.422285258769989 0.7965116500854492\n",
      "0.45325228571891785 0.7777777910232544\n",
      "0.43697434663772583 0.8113207817077637\n",
      "0.42166000604629517 0.8012422323226929\n",
      "0.41993817687034607 0.7751479148864746\n",
      "0.46914321184158325 0.7758620977401733\n",
      "0.47509053349494934 0.7560975551605225\n",
      "0.5261884927749634 0.7124999761581421\n",
      "0.3817409873008728 0.8150289058685303\n",
      "0.4595276415348053 0.7575757503509521\n",
      "0.45335137844085693 0.7797619104385376\n",
      "0.45595651865005493 0.7586206793785095\n",
      "0.3971374034881592 0.8023256063461304\n",
      "0.4656824469566345 0.7678571343421936\n",
      "0.4074365794658661 0.7954545617103577\n",
      "0.4074365794658661 0.4419863998889923 0.7782991915941239 5.19118070602417 3\n",
      "0.42183250188827515 0.7873563170433044\n",
      "0.46570783853530884 0.7682926654815674\n",
      "0.39225906133651733 0.832335352897644\n",
      "0.4350746273994446 0.7911392450332642\n",
      "0.44104838371276855 0.7692307829856873\n",
      "0.43209347128868103 0.7951807379722595\n",
      "0.36691218614578247 0.8323699235916138\n",
      "0.37511950731277466 0.8313953280448914\n",
      "0.3886815309524536 0.8282208442687988\n",
      "0.42765387892723083 0.7852349281311035\n",
      "0.45446860790252686 0.7714285850524902\n",
      "0.3905285596847534 0.8181818127632141\n",
      "0.4526298940181732 0.7341040372848511\n",
      "0.4627705514431 0.782608687877655\n",
      "0.45640820264816284 0.7928994297981262\n",
      "0.33481550216674805 0.8728323578834534\n",
      "0.4040088951587677 0.8060606122016907\n",
      "0.36526647210121155 0.8554216623306274\n",
      "0.39282724261283875 0.8465909361839294\n",
      "0.38808396458625793 0.8255813717842102\n",
      "0.38808396458625793 0.41240954399108887 0.8063232809305191 5.172895908355713 3\n",
      "0.44354957342147827 0.7758620977401733\n",
      "0.4449046850204468 0.7906976938247681\n",
      "0.4659205377101898 0.7710843086242676\n",
      "0.443133682012558 0.7906976938247681\n",
      "0.4206104576587677 0.8132529854774475\n",
      "0.39818504452705383 0.8203592896461487\n",
      "0.3954707980155945 0.7966101765632629\n",
      "0.4041767418384552 0.7873563170433044\n",
      "0.3862473666667938 0.8231707215309143\n",
      "0.427598774433136 0.793749988079071\n",
      "0.43695881962776184 0.7730061411857605\n",
      "0.39436712861061096 0.7933333516120911\n",
      "0.37791240215301514 0.8208092451095581\n",
      "0.42667698860168457 0.7790697813034058\n",
      "0.3480614125728607 0.8715083599090576\n",
      "0.5127947926521301 0.7532467246055603\n",
      "0.3599948585033417 0.8539325594902039\n",
      "0.2926087975502014 0.9112426042556763\n",
      "0.4712846279144287 0.7714285850524902\n",
      "0.4034254550933838 0.8062499761581421\n",
      "0.4034254550933838 0.4126941472291946 0.8048334300518036 5.2481138706207275 3\n",
      "0.4166235327720642 0.8098159432411194\n",
      "0.42138341069221497 0.7810651063919067\n",
      "0.3847621977329254 0.8125\n",
      "0.37002938985824585 0.8343558311462402\n",
      "0.3441261351108551 0.8830409646034241\n",
      "0.38200342655181885 0.8117647171020508\n",
      "0.3675401508808136 0.8604651093482971\n",
      "0.32259759306907654 0.8614457845687866\n",
      "0.32790350914001465 0.8502994179725647\n",
      "0.39700549840927124 0.847953200340271\n",
      "0.39845481514930725 0.8273809552192688\n",
      "0.4046928286552429 0.8474576473236084\n",
      "0.40593940019607544 0.7904191613197327\n",
      "0.3434905409812927 0.841176450252533\n",
      "0.3895145356655121 0.832335352897644\n",
      "0.4382247030735016 0.8045976758003235\n",
      "0.4273510277271271 0.8271604776382446\n",
      "0.3425968587398529 0.8606060743331909\n",
      "0.4652155637741089 0.8012048006057739\n",
      "0.3967660069465637 0.8313252925872803\n",
      "0.3967660069465637 0.38731105625629425 0.8308184981346131 5.184720277786255 3\n",
      "0.33801987767219543 0.8705882430076599\n",
      "0.31282269954681396 0.8514285683631897\n",
      "0.3681706488132477 0.7882353067398071\n",
      "0.3980771601200104 0.8379888534545898\n",
      "0.4387374520301819 0.770588219165802\n",
      "0.41101646423339844 0.8292682766914368\n",
      "0.35782817006111145 0.8414633870124817\n",
      "0.4055729806423187 0.8381502628326416\n",
      "0.36080166697502136 0.8484848737716675\n",
      "0.37839239835739136 0.8580247163772583\n",
      "0.3757423758506775 0.8374999761581421\n",
      "0.40677908062934875 0.8132529854774475\n",
      "0.4035876989364624 0.8253012299537659\n",
      "0.4128492474555969 0.7810651063919067\n",
      "0.41632702946662903 0.7976190447807312\n",
      "0.37170135974884033 0.8484848737716675\n",
      "0.45338204503059387 0.8106508851051331\n",
      "0.413709431886673 0.8012820482254028\n",
      "0.37929660081863403 0.8224852085113525\n",
      "0.4215162694454193 0.7878788113594055\n",
      "0.4215162694454193 0.3912165328860283 0.8229870438575745 5.155369997024536 3\n",
      "0.387739896774292 0.8322981595993042\n",
      "0.31327012181282043 0.8786126971244812\n",
      "0.30308797955513 0.8666666746139526\n",
      "0.3490053713321686 0.8484848737716675\n",
      "0.3854384124279022 0.8089887499809265\n",
      "0.4059099555015564 0.7857142686843872\n",
      "0.3934548795223236 0.8452380895614624\n",
      "0.36082586646080017 0.8483145833015442\n",
      "0.3808313012123108 0.8628571629524231\n",
      "0.4057120680809021 0.790123462677002\n",
      "0.41677382588386536 0.8245614171028137\n",
      "0.41519859433174133 0.7865853905677795\n",
      "0.4041866958141327 0.8098159432411194\n",
      "0.42055147886276245 0.7916666865348816\n",
      "0.3822769820690155 0.8433734774589539\n",
      "0.40774041414260864 0.8095238208770752\n",
      "0.4211641848087311 0.793749988079071\n",
      "0.4480331838130951 0.800000011920929\n",
      "0.3914017379283905 0.8192771077156067\n",
      "0.3955487012863159 0.8047337532043457\n",
      "0.3955487012863159 0.38940758258104324 0.8225293159484863 5.168184518814087 3\n",
      "0.4102582037448883 0.7784090638160706\n",
      "0.42119160294532776 0.762499988079071\n",
      "0.4192708134651184 0.8098159432411194\n",
      "0.33541253209114075 0.868852436542511\n",
      "0.3891593813896179 0.7988505959510803\n",
      "0.45392128825187683 0.7295597195625305\n",
      "0.3771687150001526 0.8187134265899658\n",
      "0.38514629006385803 0.8388888835906982\n",
      "0.397128164768219 0.8224852085113525\n",
      "0.40311622619628906 0.8159509301185608\n",
      "0.3365498185157776 0.8571428656578064\n",
      "0.356033593416214 0.8238636255264282\n",
      "0.414653480052948 0.7784430980682373\n",
      "0.4923132658004761 0.7298850417137146\n",
      "0.4298633933067322 0.841176450252533\n",
      "0.2790148854255676 0.8888888955116272\n",
      "0.3755852282047272 0.8012820482254028\n",
      "0.42371782660484314 0.8235294222831726\n",
      "0.39989596605300903 0.8164557218551636\n",
      "0.35296815633773804 0.8132529854774475\n",
      "0.35296815633773804 0.3926184415817261 0.8108973175287246 5.159651756286621 3\n",
      "0.4111299216747284 0.8048780560493469\n",
      "0.3491433262825012 0.8466257452964783\n",
      "0.33849290013313293 0.849711000919342\n",
      "0.4017159044742584 0.8381502628326416\n",
      "0.36592772603034973 0.8402366638183594\n",
      "0.374532550573349 0.8245614171028137\n",
      "0.4386008381843567 0.7816091775894165\n",
      "0.30953964591026306 0.8802395462989807\n",
      "0.3830914795398712 0.8057143092155457\n",
      "0.3693614900112152 0.8208092451095581\n",
      "0.3918142020702362 0.8292682766914368\n",
      "0.32565852999687195 0.8579545617103577\n",
      "0.33100324869155884 0.8383233547210693\n",
      "0.35895106196403503 0.8132529854774475\n",
      "0.3374384045600891 0.8606060743331909\n",
      "0.3759613037109375 0.8092485666275024\n",
      "0.3446080982685089 0.8275862336158752\n",
      "0.3413246273994446 0.8461538553237915\n",
      "0.32393786311149597 0.845714271068573\n",
      "0.3300510346889496 0.8682634830474854\n",
      "0.3300510346889496 0.36011420786380766 0.8344453543424606 5.212132692337036 3\n",
      "0.3720014989376068 0.8121212124824524\n",
      "0.40210893750190735 0.8101266026496887\n",
      "0.3808681070804596 0.8154761791229248\n",
      "0.342447966337204 0.8484848737716675\n",
      "0.4050430953502655 0.8214285969734192\n",
      "0.2917144298553467 0.8650306463241577\n",
      "0.3711203634738922 0.8313953280448914\n",
      "0.4058888852596283 0.8224852085113525\n",
      "0.4523566663265228 0.7485714554786682\n",
      "0.38005530834198 0.8598726391792297\n",
      "0.42534035444259644 0.772455096244812\n",
      "0.29521769285202026 0.8563535809516907\n",
      "0.4229823648929596 0.800000011920929\n",
      "0.3249538242816925 0.8622754216194153\n",
      "0.34372439980506897 0.8529411554336548\n",
      "0.3307872712612152 0.8603351712226868\n",
      "0.44121962785720825 0.8125\n",
      "0.32205283641815186 0.8443113565444946\n",
      "0.4515545964241028 0.7674418687820435\n",
      "0.398298054933548 0.8253012299537659\n",
      "0.398298054933548 0.37798681408166884 0.8244453817605972 5.162871599197388 3\n",
      "0.4273715615272522 0.7950310707092285\n",
      "0.4056726396083832 0.8235294222831726\n",
      "0.4144389033317566 0.8291139006614685\n",
      "0.33587977290153503 0.8520709872245789\n",
      "0.33212757110595703 0.8805031180381775\n",
      "0.33347317576408386 0.8786126971244812\n",
      "0.44784170389175415 0.8113207817077637\n",
      "0.40353119373321533 0.7757575511932373\n",
      "0.276206910610199 0.8908045887947083\n",
      "0.3925154507160187 0.8220859169960022\n",
      "0.3770357072353363 0.8253012299537659\n",
      "0.41248631477355957 0.8098159432411194\n",
      "0.37342309951782227 0.8034682273864746\n",
      "0.3383549153804779 0.8735632300376892\n",
      "0.38472217321395874 0.8181818127632141\n",
      "0.3839586675167084 0.8303030133247375\n",
      "0.4359451234340668 0.819767415523529\n",
      "0.46490517258644104 0.7547169923782349\n",
      "0.40674591064453125 0.8333333134651184\n",
      "0.32561516761779785 0.8641975522041321\n",
      "0.32561516761779785 0.38361255675554273 0.8295739382505417 5.174769639968872 3\n",
      "0.383635938167572 0.8106508851051331\n",
      "0.3495713770389557 0.8484848737716675\n",
      "0.36073964834213257 0.832335352897644\n",
      "0.29503923654556274 0.8520709872245789\n",
      "0.3229195773601532 0.8666666746139526\n",
      "0.41210097074508667 0.7770700454711914\n",
      "0.30234724283218384 0.8452380895614624\n",
      "0.34331557154655457 0.8373494148254395\n",
      "0.35723477602005005 0.8538011908531189\n",
      "0.4110844135284424 0.8418079018592834\n",
      "0.34381961822509766 0.8805031180381775\n",
      "0.316317081451416 0.8622754216194153\n",
      "0.3743792772293091 0.8294117450714111\n",
      "0.3728654086589813 0.8209876418113708\n",
      "0.3666054606437683 0.854651153087616\n",
      "0.3457045555114746 0.845714271068573\n",
      "0.35636425018310547 0.8395061492919922\n",
      "0.31434348225593567 0.8641975522041321\n",
      "0.3341134488582611 0.8387096524238586\n",
      "0.3945383131504059 0.790123462677002\n",
      "0.3945383131504059 0.35285198241472243 0.839577779173851 5.177996873855591 3\n",
      "0.3503482937812805 0.8466257452964783\n",
      "0.47540199756622314 0.7836257219314575\n",
      "0.38936248421669006 0.8520709872245789\n",
      "0.34361177682876587 0.851190447807312\n",
      "0.36256641149520874 0.822857141494751\n",
      "0.3237016797065735 0.8812500238418579\n",
      "0.302621066570282 0.88165682554245\n",
      "0.3625262379646301 0.8500000238418579\n",
      "0.32482150197029114 0.8735632300376892\n",
      "0.32884737849235535 0.8522727489471436\n",
      "0.3835776746273041 0.8447204828262329\n",
      "0.30022016167640686 0.8882352709770203\n",
      "0.33723968267440796 0.8611111044883728\n",
      "0.33691856265068054 0.8208092451095581\n",
      "0.30978548526763916 0.8502994179725647\n",
      "0.31706246733665466 0.8612716794013977\n",
      "0.3907778263092041 0.8273809552192688\n",
      "0.318604439496994 0.8514285683631897\n",
      "0.3754260241985321 0.8399999737739563\n",
      "0.27879318594932556 0.8850574493408203\n",
      "0.27879318594932556 0.3456107169389725 0.8512713521718979 5.194757461547852 3\n",
      "0.4215594232082367 0.8116883039474487\n",
      "0.3994732201099396 0.8383233547210693\n",
      "0.3471735715866089 0.8538011908531189\n",
      "0.44158560037612915 0.7975460290908813\n",
      "0.3471968472003937 0.8292682766914368\n",
      "0.37359678745269775 0.8481012582778931\n",
      "0.37229812145233154 0.8176470398902893\n",
      "0.3587375283241272 0.8606060743331909\n",
      "0.3472091853618622 0.8682634830474854\n",
      "0.3852527439594269 0.8588235378265381\n",
      "0.3841594159603119 0.8224852085113525\n",
      "0.29346954822540283 0.8641975522041321\n",
      "0.3315314054489136 0.8505747318267822\n",
      "0.397718220949173 0.8064516186714172\n",
      "0.325295627117157 0.8447204828262329\n",
      "0.38101106882095337 0.8433734774589539\n",
      "0.2995336055755615 0.8571428656578064\n",
      "0.36507174372673035 0.8106508851051331\n",
      "0.34900936484336853 0.8571428656578064\n",
      "0.3769092559814453 0.8322981595993042\n",
      "0.3769092559814453 0.36488961428403854 0.8386553198099136 5.181812524795532 3\n",
      "0.3263309895992279 0.8545454740524292\n",
      "0.3237496614456177 0.8342857360839844\n",
      "0.3396896421909332 0.8505747318267822\n",
      "0.37120747566223145 0.8181818127632141\n",
      "0.36614158749580383 0.8362573385238647\n",
      "0.3335324823856354 0.8932584524154663\n",
      "0.38763678073883057 0.826347291469574\n",
      "0.35586804151535034 0.851190447807312\n",
      "0.42619413137435913 0.8282208442687988\n",
      "0.29575520753860474 0.8597561120986938\n",
      "0.35846856236457825 0.8529411554336548\n",
      "0.44261476397514343 0.8136646151542664\n",
      "0.3911827802658081 0.8395061492919922\n",
      "0.3769783675670624 0.8132529854774475\n",
      "0.35219743847846985 0.8654970526695251\n",
      "0.2927439510822296 0.8650306463241577\n",
      "0.29439443349838257 0.8780487775802612\n",
      "0.3136157691478729 0.8764705657958984\n",
      "0.3209516406059265 0.8705882430076599\n",
      "0.3568861782550812 0.851190447807312\n",
      "0.3568861782550812 0.35130699425935746 0.8489404439926147 5.28253173828125 3\n",
      "0.3144107758998871 0.8888888955116272\n",
      "0.33597105741500854 0.8469945192337036\n",
      "0.33577293157577515 0.8580645322799683\n",
      "0.3563844859600067 0.8500000238418579\n",
      "0.3179749548435211 0.8616352081298828\n",
      "0.4144695997238159 0.8224852085113525\n",
      "0.4128738045692444 0.8285714387893677\n",
      "0.3458389937877655 0.8715083599090576\n",
      "0.4211588203907013 0.798701286315918\n",
      "0.36085188388824463 0.8353658318519592\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-ef077a700f7a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0;31m#TODO: mask with recall\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mbce\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mrecall\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mrecall\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m#correct shape?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m     \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m     \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[1;32m    193\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[0;34m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    194\u001B[0m         \"\"\"\n\u001B[0;32m--> 195\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    196\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    197\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[1;32m     97\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[1;32m     98\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "i = 1\n",
    "sumloss = 0\n",
    "sumacc = 0\n",
    "\n",
    "while i < ITERATIONS:\n",
    "    batchstart = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    data = make_batch(BATCH_SIZE, SEQ_LEN, store_dist, recall_dist, device)\n",
    "    #data = data.repeat_interleave(CHAR_DUR, 0)\n",
    "    input = data[:, :, :3]\n",
    "    target = data[:, :, 3]\n",
    "    recall = data[:, :, 0]\n",
    "\n",
    "    input = input.repeat_interleave(CHAR_DUR, 0)\n",
    "    #TODO: repeat data over\n",
    "\n",
    "    output, _ = model(input)\n",
    "    output = output.squeeze()\n",
    "    output = output.view(SEQ_LEN, CHAR_DUR, BATCH_SIZE).mean(dim=1)\n",
    "    assert output.shape == target.shape, f'shapes on loss {output.shape}, {target.shape}'\n",
    "    #TODO: mask with recall\n",
    "    loss = (bce(output, target)*recall).sum()/recall.sum() #correct shape?\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        record_norm()\n",
    "        stats['loss'].append(loss.item())\n",
    "        acc = ((((output > 0).float() == target).float()*recall).sum()/recall.sum()).item()\n",
    "        #stats['acc'].append(acc)\n",
    "        batch_var = 3 #out_final.var(0).mean().item()\n",
    "        #stats['batch_var'].append(batch_var)\n",
    "\n",
    "        print(loss.item(), acc)\n",
    "\n",
    "\n",
    "    sumloss += loss.item()\n",
    "    sumacc += acc\n",
    "    if i%20 == 0:\n",
    "        print(loss.item(), sumloss/20, sumacc/20, time.time()-batchstart, batch_var) #torch.argmax(outputs[-1], 1).float().var()\n",
    "        sumloss = 0\n",
    "        sumacc = 0\n",
    "    if i%2500 == 0:\n",
    "        lr = lr * spec['lr_decay']\n",
    "        optimizer = optim.Adam(params, lr=lr)\n",
    "        print('Learning Rate: ', lr)\n",
    "    i += 1\n",
    "    #config['stats'] = stats\n",
    "    #config['progress'] = i\n",
    "    #with open('configs/' + run_id + '.json', 'w') as config_file:\n",
    "    #    json.dump(config, config_file, indent=2)\n",
    "    #model.save('models/'+run_id)\n",
    "\n",
    "\n",
    "print('Total time: ', time.time()-start)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = make_batch(1, 13, store_dist, recall_dist, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = test_data[:, 0 ,0].nonzero()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b = test_data[:a, 0, 1].nonzero()[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data[b, 0, 2] == test_data[a, 0, 3]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data = make_batch(BATCH_SIZE, SEQ_LEN, store_dist, recall_dist, device)\n",
    "data = data.repeat_interleave(CHAR_DUR, 0)\n",
    "input = data[:, :, :3]\n",
    "target = data[:, :, 3]\n",
    "recall = data[:, :, 0]\n",
    "#TODO: repeat data over\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, _, log = model(input, logging=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "ab = (log['loop']['control'][:, 0] * 255).t().numpy().astype(np.uint8)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ar_length = input.shape[0]\n",
    "array_list = [input, log['loop']['control'], log['loop']['mem'], log['output']] #log['loop']['output']\n",
    "array_list2 = []\n",
    "for ar in array_list:\n",
    "    array_list2.append(ar[:, 0])\n",
    "    array_list2.append(torch.ones((ar_length, 1), device=input.device) * 0.5)\n",
    "big_ar = torch.cat(array_list2[:-1], dim=1).detach() * 255\n",
    "img = Image.fromarray(big_ar.numpy().astype(np.uint8), 'L')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(27, 1300)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=270x1300 at 0x7FE79E34BD30>",
      "image/png": "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\n"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.resize((27*10, 1300))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0163)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log['loop']['control'].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0001)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log['loop']['mem'].mean()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0252, grad_fn=<VarBackward0>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers.loop.model.layers.control_synapse.weight.var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.model.layers.loop.model.layers.mem_synapse.weight.var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1159, grad_fn=<VarBackward0>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.layers.loop.model.layers.control_synapse.weight.var() * log['loop']['mem'].mean()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}