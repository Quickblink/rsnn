{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import macropy.activate\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from Code.iff_macro import set_config\n",
    "from Code.lstm import lstmPolicyPredictor, FullyConnected\n",
    "from Code.envs.MountainCar import MultiMountainCar, LookupPolicy, PassiveEnv\n",
    "from Code.SNN import RSNN, FeedForwardSNN, magicRSNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'Code.macroNeurons' from '../Code/macroNeurons.py'>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "config = {\n",
    "    'ALPHA': 0,\n",
    "    'BETA': 1,\n",
    "    'RESET_ZERO': False,\n",
    "    'THRESH_ADD': 1,\n",
    "    'THRESH_DECAY': 1,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'bellec',\n",
    "    'SIM_TIME': 10\n",
    "}\n",
    "set_config(config)\n",
    "import Code.macroNeurons as Neurons\n",
    "importlib.reload(Neurons)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "env = PassiveEnv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#model = lstmPolicyPredictor(2,8,16)\n",
    "#model = RSNN(config, 1, 32, 16, 1, Neurons.LIFNeuron, Neurons.AdaptiveNeuron, Neurons.OutputNeuron)\n",
    "model = magicRSNN(config, 1, 32, 16, 1, Neurons.LIFNeuron, Neurons.MagicNeuron, Neurons.OutputNeuron)\n",
    "#model = FeedForwardSNN(config, [1, 128, 128, 1], Neurons.LIFNeuron, Neurons.OutputNeuron)\n",
    "#model = FullyConnected([1, 128, 128, 1])\n",
    "\n",
    "teacher = LookupPolicy()\n",
    "\n",
    "\n",
    "#TODO: test superspike instead of Bellec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#bce = nn.BCELoss(reduction='none') #reduction='sum'\n",
    "mse = nn.MSELoss(reduction='none')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)#0.00001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.002211832907050848 4.347535610198975 0\n",
      "0.0019170005107298493 3.624539613723755 10\n",
      "0.0016767119523137808 3.2489659786224365 20\n",
      "0.001473296550102532 2.7053163051605225 30\n",
      "0.0012687068665400147 2.4473164081573486 40\n",
      "0.0011260226601734757 2.215318202972412 50\n",
      "0.0009826339082792401 1.8202329874038696 60\n",
      "0.0008614218095317483 1.7241489887237549 70\n",
      "0.0007619134848937392 1.4664584398269653 80\n",
      "0.0006828340701758862 1.2884080410003662 90\n",
      "0.0006260736845433712 1.1623941659927368 100\n",
      "0.0005728006362915039 1.1182050704956055 110\n",
      "0.0005339178605936468 1.035591959953308 120\n",
      "0.0005053593777120113 1.0022834539413452 130\n",
      "0.00048571176012046635 0.9366914629936218 140\n",
      "0.0004604938440024853 0.9241296052932739 150\n",
      "0.00046307340380735695 0.8620093464851379 160\n",
      "0.00044172655907459557 0.8777489066123962 170\n",
      "0.00043628879939205945 0.8639355301856995 180\n",
      "0.0004310367803554982 0.8423964977264404 190\n",
      "0.0004301064764149487 0.8468295335769653 200\n",
      "0.00042926985770463943 0.8063421845436096 210\n",
      "0.00042852689512073994 0.8063063621520996 220\n",
      "0.0006193906301632524 1.090531587600708 230\n",
      "0.000614495889749378 1.1762595176696777 240\n",
      "0.000592011259868741 1.163644552230835 250\n",
      "0.000604954781010747 1.141430377960205 260\n",
      "0.0005741199711337686 1.1102484464645386 270\n",
      "0.0005684694624505937 1.0716869831085205 280\n",
      "0.0005921036354266107 1.115882158279419 290\n",
      "0.000592592463362962 1.0713191032409668 300\n",
      "0.0005578272975981236 1.0712374448776245 310\n",
      "0.0005566311883740127 1.043578863143921 320\n",
      "0.0005573170492425561 1.0605309009552002 330\n",
      "0.0005634396802634001 1.0256391763687134 340\n",
      "0.0005543498555198312 1.0184078216552734 350\n",
      "0.0005638700095005333 1.0690085887908936 360\n",
      "0.0005686546210199594 1.074417233467102 370\n",
      "0.0005448724259622395 1.0714367628097534 380\n",
      "0.0005562454462051392 1.0198888778686523 390\n",
      "0.0005453032208606601 1.0578484535217285 400\n",
      "0.0005276129813864827 1.0156636238098145 410\n",
      "0.000529063050635159 1.0005933046340942 420\n",
      "0.0005278020398691297 1.0437109470367432 430\n",
      "0.000535883940756321 1.0311992168426514 440\n",
      "0.0005210093222558498 0.9635869860649109 450\n",
      "0.0005062568816356361 0.9628749489784241 460\n",
      "0.0005196947022341192 1.042011022567749 470\n",
      "0.0005286886589601636 1.031717300415039 480\n",
      "0.0005109060439281166 1.0124224424362183 490\n",
      "0.0005221164901740849 1.0300943851470947 500\n",
      "0.0005207245121710002 0.9743344187736511 510\n",
      "0.0005160620785318315 0.919370710849762 520\n",
      "0.0005298136966302991 1.0036911964416504 530\n",
      "0.0005184903275221586 1.0140804052352905 540\n",
      "0.0005092676728963852 1.0057334899902344 550\n",
      "0.0005219443119131029 1.004073977470398 560\n",
      "0.0005200111772865057 0.9668889045715332 570\n",
      "0.0005322402575984597 0.9500358700752258 580\n",
      "0.0005187088972888887 0.942027747631073 590\n",
      "0.0005121778231114149 0.9747599363327026 600\n",
      "0.0005183321773074567 0.9861035346984863 610\n",
      "0.0005294651491567492 1.0069024562835693 620\n",
      "0.0005118074477650225 0.9787477254867554 630\n",
      "0.0005160857690498233 0.9950675964355469 640\n",
      "0.0005243064952082932 0.9429105520248413 650\n",
      "0.0005077359965071082 0.975502610206604 660\n",
      "0.0004996744100935757 0.9555413722991943 670\n",
      "0.0005121126305311918 0.9811941981315613 680\n",
      "0.0005093409563414752 0.9773346185684204 690\n",
      "0.00048206865903921425 0.9280436635017395 700\n",
      "0.0005055805086158216 0.9904156923294067 710\n",
      "0.0005257088923826814 0.9952223300933838 720\n",
      "0.0004983703256584704 0.9788084626197815 730\n",
      "0.000507428718265146 1.002587080001831 740\n",
      "0.0005169003270566463 0.9764382243156433 750\n",
      "0.000502744282130152 0.9864524602890015 760\n",
      "0.0004969769506715238 0.9967682957649231 770\n",
      "0.000492383202072233 0.9723204374313354 780\n",
      "0.0004974047187715769 0.9840055108070374 790\n",
      "0.0005196752608753741 0.929715633392334 800\n",
      "0.0005085435695946217 0.9741581678390503 810\n",
      "0.0005120712448842824 0.996746301651001 820\n",
      "0.0005165328038856387 0.9797404408454895 830\n",
      "0.0005001861718483269 0.9143732786178589 840\n",
      "0.0005023109843023121 0.99909508228302 850\n",
      "0.0005123676965013146 0.9858202934265137 860\n",
      "0.0005054774228483438 1.0040435791015625 870\n",
      "0.0004782823089044541 0.9642952680587769 880\n",
      "0.0005026361905038357 0.9646211862564087 890\n",
      "0.0005238775629550219 0.9618391990661621 900\n",
      "0.000503449875395745 0.9885654449462891 910\n",
      "0.0005026853177696466 1.0018291473388672 920\n",
      "0.0005022426485083997 0.9589298367500305 930\n",
      "0.0004865991941187531 0.9263426065444946 940\n",
      "0.0005202713655307889 0.9972880482673645 950\n",
      "0.0005150583456270397 0.9926638007164001 960\n",
      "0.0005024058627896011 0.9094460606575012 970\n",
      "0.0005165956681594253 0.9606899619102478 980\n",
      "0.0004930261638946831 0.9562601447105408 990\n",
      "0.0005078364629298449 0.9313244819641113 1000\n",
      "0.0005078911781311035 0.9156438112258911 1010\n",
      "0.0004999414086341858 0.9297451376914978 1020\n",
      "0.0005192249082028866 0.9375672340393066 1030\n",
      "0.0005053193308413029 0.995146632194519 1040\n",
      "0.0005223433836363256 0.9251596927642822 1050\n",
      "0.000517921696882695 0.9520622491836548 1060\n",
      "0.0005267377127893269 0.9719541668891907 1070\n",
      "0.0005026910803280771 0.963826060295105 1080\n",
      "0.0004947505076415837 0.9548213481903076 1090\n",
      "0.0005057090893387794 0.9933934211730957 1100\n",
      "0.0005032439948990941 0.965823233127594 1110\n",
      "0.0005146090989001095 0.9888811707496643 1120\n",
      "0.0005112210637889802 0.9989612102508545 1130\n",
      "0.000500024703796953 0.9704582095146179 1140\n",
      "0.0005127173499204218 0.9252009987831116 1150\n",
      "0.0004810280806850642 0.956196129322052 1160\n",
      "0.0005000050878152251 0.9694095253944397 1170\n",
      "0.000503010640386492 0.996821403503418 1180\n",
      "0.0004969924921169877 0.9682776927947998 1190\n",
      "0.0005032639019191265 0.9742900729179382 1200\n",
      "0.0005089526530355215 0.9946202039718628 1210\n",
      "0.0004889878327958286 0.9599406719207764 1220\n",
      "0.0005004060221835971 0.957022488117218 1230\n",
      "0.0005114455707371235 0.9849276542663574 1240\n",
      "0.0005065138102509081 1.0002633333206177 1250\n",
      "0.0005049998871982098 0.9392898082733154 1260\n",
      "0.0005132090882398188 0.958378255367279 1270\n",
      "0.000514317536726594 0.9603341817855835 1280\n",
      "0.0005027966108173132 0.9936338663101196 1290\n",
      "0.0005113964434713125 0.9748338460922241 1300\n",
      "0.0004942817031405866 0.9219639897346497 1310\n",
      "0.0005230593960732222 1.0008666515350342 1320\n",
      "0.0004992212052457035 0.9739369750022888 1330\n",
      "0.0005098110996186733 0.9704596996307373 1340\n",
      "0.0004949804861098528 0.9311630129814148 1350\n",
      "0.0005304449587129056 0.9992045164108276 1360\n",
      "0.0005012070760130882 0.9334241151809692 1370\n",
      "0.0005153336678631604 1.004607081413269 1380\n",
      "0.0005002158577553928 0.9928353428840637 1390\n",
      "0.0005210412200540304 0.9994601607322693 1400\n",
      "0.0004925553221255541 1.0003597736358643 1410\n",
      "0.0004978569922968745 0.9791266918182373 1420\n",
      "0.0005050886538811028 0.9611363410949707 1430\n",
      "0.0005062146228738129 0.995577871799469 1440\n",
      "0.0005116891115903854 0.9381371140480042 1450\n",
      "0.000516488857101649 1.000605583190918 1460\n",
      "0.0005122390575706959 0.9479103088378906 1470\n",
      "0.0004949651192873716 0.9986640810966492 1480\n",
      "0.0005098121473565698 0.9805135726928711 1490\n",
      "0.0005077196983620524 0.9545583724975586 1500\n",
      "0.0005166238988749683 0.9641050696372986 1510\n",
      "0.0005079201073385775 0.992108166217804 1520\n",
      "0.0005089533515274525 0.948811948299408 1530\n",
      "0.000495437765493989 0.9844476580619812 1540\n",
      "0.0005055656074546278 0.999158501625061 1550\n",
      "0.0004921299987472594 0.9982242584228516 1560\n",
      "0.0005186196649447083 0.9951620101928711 1570\n",
      "0.0005021945107728243 0.9639310836791992 1580\n",
      "0.0004952388699166477 0.9717521667480469 1590\n",
      "0.0005082952557131648 0.9793274998664856 1600\n",
      "0.0004966846317984164 0.9420839548110962 1610\n",
      "0.0004866181989200413 0.964235782623291 1620\n",
      "0.0005315989255905151 0.9950082898139954 1630\n",
      "0.0005030420725233853 0.9743224382400513 1640\n",
      "0.0005030948086641729 0.959530234336853 1650\n",
      "0.0005004592821933329 0.9985864162445068 1660\n",
      "0.0005163589958101511 0.9538000226020813 1670\n",
      "0.000497365603223443 0.9608706831932068 1680\n",
      "0.0004981542588211596 0.9716213941574097 1690\n",
      "0.0005025616264902055 0.9371074438095093 1700\n",
      "0.0004965724656358361 0.9170212149620056 1710\n",
      "0.0005080664996057749 0.9978029727935791 1720\n",
      "0.0005086595774628222 0.9390143156051636 1730\n",
      "0.0005111516802571714 0.97255939245224 1740\n",
      "0.0005039271200075746 1.0038782358169556 1750\n",
      "0.0005115691456012428 1.0041130781173706 1760\n",
      "0.000492702005431056 0.979753315448761 1770\n",
      "0.0004978061188012362 0.9830570220947266 1780\n",
      "0.0004978704964742064 0.9434362053871155 1790\n",
      "0.0004966956912539899 0.9689947962760925 1800\n",
      "0.000510884216055274 0.9476537108421326 1810\n",
      "0.0005157662089914083 0.9396228790283203 1820\n",
      "0.0005000753444619477 0.9924206733703613 1830\n",
      "0.0005156760453246534 0.9851189851760864 1840\n",
      "0.0005192590178921819 0.9921514987945557 1850\n",
      "0.00050453090807423 0.9858884811401367 1860\n",
      "0.0004954506875947118 0.919814944267273 1870\n",
      "0.0005109513294883072 0.9871866106987 1880\n",
      "0.0005224467604421079 0.9970830082893372 1890\n",
      "0.0005004084669053555 0.982970654964447 1900\n",
      "0.0004985432024113834 0.9485728144645691 1910\n",
      "0.0004924724926240742 0.9026415944099426 1920\n",
      "0.0005227715009823442 0.9590808749198914 1930\n",
      "0.0005130039644427598 0.9985196590423584 1940\n",
      "0.0005072892527095973 0.9303252100944519 1950\n",
      "0.0004949481808580458 0.9423501491546631 1960\n",
      "0.000507565273437649 0.9942554831504822 1970\n",
      "0.0005173160461708903 0.9426522850990295 1980\n",
      "0.0005015132483094931 0.934884786605835 1990\n",
      "0.0004940570215694606 0.9648997187614441 2000\n",
      "0.0004983917460776865 0.928132176399231 2010\n",
      "0.0005266605294309556 0.9936923980712891 2020\n",
      "0.0005299753975123167 0.9154137372970581 2030\n",
      "0.0005081217386759818 0.9734889268875122 2040\n",
      "0.0005085538141429424 0.9906704425811768 2050\n",
      "0.0005112054641358554 0.9285908937454224 2060\n",
      "0.0005102706491015851 0.9740463495254517 2070\n",
      "0.0005067258607596159 0.9187526702880859 2080\n",
      "0.0005103946896269917 0.932770311832428 2090\n",
      "0.0005068074096925557 0.9388287663459778 2100\n",
      "0.0004928373964503407 1.0051257610321045 2110\n",
      "0.0004943013773299754 0.9243709444999695 2120\n",
      "0.000516969827003777 0.9542626142501831 2130\n",
      "0.000490526610519737 0.9452251195907593 2140\n",
      "0.0005044769495725632 0.9604429602622986 2150\n",
      "0.0005115500534884632 0.9556374549865723 2160\n",
      "0.0004928252892568707 0.9650283455848694 2170\n",
      "0.0005222759791649878 0.9949854016304016 2180\n",
      "0.0005021576653234661 0.986267626285553 2190\n",
      "0.0005213582189753652 0.9849504828453064 2200\n",
      "0.0004929662100039423 0.9788651466369629 2210\n",
      "0.0005167907220311463 0.9738646745681763 2220\n",
      "0.0005071865161880851 0.9367977976799011 2230\n",
      "0.0005102125578559935 0.9975726008415222 2240\n",
      "0.0004891521530225873 0.926516056060791 2250\n",
      "0.0004972632741555572 0.9347416758537292 2260\n",
      "0.000510892947204411 0.9766340851783752 2270\n",
      "0.0005181538872420788 0.9736839532852173 2280\n",
      "0.0005047072772867978 0.9688022136688232 2290\n",
      "0.0005223046173341572 0.9657464623451233 2300\n",
      "0.0004909712006337941 0.9720109105110168 2310\n",
      "0.0004963582614436746 0.9462776780128479 2320\n",
      "0.0004970483132638037 0.9691179394721985 2330\n",
      "0.0005092196515761316 0.9815298914909363 2340\n",
      "0.0005091093480587006 0.9741043448448181 2350\n",
      "0.00048570858780294657 0.9724637269973755 2360\n",
      "0.0005130632780492306 0.9892981052398682 2370\n",
      "0.0004997340147383511 0.9134003520011902 2380\n",
      "0.0004940400249324739 0.9768791198730469 2390\n",
      "0.0005052685155533254 0.9741109609603882 2400\n",
      "0.0005127826589159667 0.9373030662536621 2410\n",
      "0.0004904334200546145 0.9565698504447937 2420\n",
      "0.0005177289713174105 0.9398507475852966 2430\n",
      "0.0004999950178898871 1.0030406713485718 2440\n",
      "0.0005088192410767078 0.9554546475410461 2450\n",
      "0.0005017989897169173 0.9591866731643677 2460\n",
      "0.0005006670253351331 0.9613537788391113 2470\n",
      "0.0005076948436908424 1.0038776397705078 2480\n",
      "0.0004989916342310607 0.946311891078949 2490\n",
      "0.0005025901482440531 0.9750945568084717 2500\n",
      "0.0005063345306552947 0.9837552309036255 2510\n",
      "0.0004979625809937716 0.9269763231277466 2520\n",
      "0.0005089991027489305 0.9823367595672607 2530\n",
      "0.0005000823293812573 0.9219292402267456 2540\n",
      "0.0005130258505232632 0.9951888918876648 2550\n",
      "0.0005154676618985832 0.953827440738678 2560\n",
      "0.0005109925987198949 0.939993679523468 2570\n",
      "0.0005097342655062675 0.9858478307723999 2580\n",
      "0.00048592142411507666 0.9479061961174011 2590\n",
      "0.0004949586000293493 0.9425953030586243 2600\n",
      "0.0005157868727110326 1.0051413774490356 2610\n",
      "0.0005168890347704291 0.9920200109481812 2620\n",
      "0.0005165644106455147 0.9636293649673462 2630\n",
      "0.0004993935581296682 0.9852628111839294 2640\n",
      "0.0005066379671916366 0.9835212230682373 2650\n",
      "0.0005021253600716591 0.9242721199989319 2660\n",
      "0.0004999154480174184 0.9934861660003662 2670\n",
      "0.0005075785447843373 0.996225118637085 2680\n",
      "0.0005024581914767623 0.951026201248169 2690\n",
      "0.0005093021900393069 0.9784433245658875 2700\n",
      "0.0005250785034149885 0.9999206066131592 2710\n",
      "0.0005052807973697782 1.0025298595428467 2720\n",
      "0.0005167457275092602 0.9631916880607605 2730\n",
      "0.0004859787877649069 0.9489590525627136 2740\n",
      "0.000481779919937253 0.9595237374305725 2750\n",
      "0.0005018694209866226 0.9849674105644226 2760\n",
      "0.00051873829215765 0.9758328795433044 2770\n",
      "0.0005106106400489807 1.0007318258285522 2780\n",
      "0.0004869224794674665 0.9823375940322876 2790\n",
      "0.0005272699054330587 0.9968640804290771 2800\n",
      "0.0005200256127864122 0.8838948607444763 2810\n",
      "0.0005126249743625522 0.9265159964561462 2820\n",
      "0.0005125267198309302 0.9627617001533508 2830\n",
      "0.0005215719575062394 0.9712780117988586 2840\n",
      "0.0004942011437378824 0.94786137342453 2850\n",
      "0.0005188469658605754 0.9738965034484863 2860\n",
      "0.0004924607928842306 0.9874968528747559 2870\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2f9bbf6f5452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(outputs.shape, targets.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    model.zero_grad()\n",
    "    inputs, targets, mask = env.getBatch(BATCH_SIZE)\n",
    "    outputs, _ = model(inputs/0.4)\n",
    "    #print(outputs.shape, targets.shape)\n",
    "    loss = (mse(outputs.squeeze(dim=2)/20, targets) * mask).sum() / mask.sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%10 == 0:\n",
    "        print(loss.item(), (loss/targets.view(-1).var()).item(), i) #, ((outputs>0.5) != targets).sum()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#torch.save(model, '../models/lstm_passive')\n",
    "#0.0002"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#torch.save(model, '../models/rsnn_passive_new1')\n",
    "#0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#model = torch.load('../models/snn_passive3')\n",
    "%matplotlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs[:, 0, 0].var().sqrt()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model(inputs/0.4)[0].squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def doplot():\n",
    "    inputs, targets, mask = env.getBatch(1)\n",
    "    outputs, _ = model(inputs/0.4)\n",
    "    plt.close()\n",
    "    plt.plot(inputs[:, 0, 0], targets)\n",
    "    plt.plot(inputs[:, 0, 0], outputs.squeeze().detach()/20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "doplot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}