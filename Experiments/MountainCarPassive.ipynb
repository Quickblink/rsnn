{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from Code import Neurons\n",
    "#from Code.ANN import lstmPolicyPredictor, FullyConnected\n",
    "from Code.envs.MountainCar import LookupPolicy, PassiveEnv\n",
    "#from Code.SNN import DynNetwork, SequenceWrapper\n",
    "import time\n",
    "from collections import OrderedDict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 64#512\n",
    "SIM_TIME = 1\n",
    "USE_JIT = True\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "env = PassiveEnv(device)\n",
    "\n",
    "#torch.backends.cudnn.enabled = False\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from Code.Networks import Selector, DynNetwork, OuterWrapper, LSTMWrapper, ReLuWrapper, DummyNeuron, make_SequenceWrapper\n",
    "from Code.NewNeurons import SeqOnlySpike, CooldownNeuron, LIFNeuron, AdaptiveNeuron\n",
    "\n",
    "base_config = {\n",
    "    'ALPHA': 0,\n",
    "    'BETA': 0,\n",
    "    'OFFSET': 2,\n",
    "    'ADAPDECAY': 1,\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "heavyside = {\n",
    "    **base_config,\n",
    "    'BETA': 1,\n",
    "}\n",
    "\n",
    "mem_loop = OrderedDict([\n",
    "    ('input', 1),\n",
    "    ('pre_mem', [['input', 'output'], SeqOnlySpike(128, base_config), nn.Linear]),\n",
    "    ('output', [['pre_mem'], CooldownNeuron(128, heavyside), nn.Linear]),\n",
    "])\n",
    "\n",
    "architecture = OrderedDict([\n",
    "    ('input', 1),\n",
    "    ('mem_loop', [['input'], make_SequenceWrapper(DynNetwork(mem_loop), USE_JIT), None]),\n",
    "    ('post_mem', [['input', 'mem_loop'], SeqOnlySpike(128, base_config), nn.Linear]),\n",
    "    ('output', [['post_mem'], DummyNeuron(1), nn.Linear]),\n",
    "])\n",
    "\n",
    "architecturelstm = OrderedDict([ #TODO: update this\n",
    "    ('input', 3),\n",
    "    ('obs', [['input'], Selector(0, 2), None]),\n",
    "    ('probe', [['input'], Selector(2, 1), None]),\n",
    "    ('lstm', [['obs'], LSTMWrapper(2, 128), None]),\n",
    "    ('post_mem', [['probe', 'lstm'], ReLuWrapper(128), nn.Linear]),\n",
    "    ('output', [['post_mem'], DummyNeuron(2), nn.Linear]),\n",
    "])\n",
    "\n",
    "forward_ann = OrderedDict([\n",
    "    ('input', 1),\n",
    "    ('first_layer', [['input'], ReLuWrapper(128), nn.Linear]),\n",
    "    ('second_layer', [['first_layer'], ReLuWrapper(128), nn.Linear]),\n",
    "    ('output', [['second_layer'], DummyNeuron(1), nn.Linear]),\n",
    "])\n",
    "\n",
    "lif = {\n",
    "    **base_config,\n",
    "    'BETA': 0.9,\n",
    "}\n",
    "\n",
    "forward_snn = OrderedDict([\n",
    "    ('input', 1),\n",
    "    ('first_layer', [['input'], make_SequenceWrapper(LIFNeuron(128, lif), USE_JIT), nn.Linear]),\n",
    "    ('second_layer', [['first_layer'], make_SequenceWrapper(LIFNeuron(128, lif), USE_JIT), nn.Linear]),\n",
    "    ('output', [['second_layer'], DummyNeuron(1), nn.Linear]),\n",
    "])\n",
    "\n",
    "forward_adap = OrderedDict([\n",
    "    ('input', 1),\n",
    "    ('first_layer', [['input'], make_SequenceWrapper(LIFNeuron(128, lif), USE_JIT), nn.Linear]),\n",
    "    ('second_layer', [['first_layer'], make_SequenceWrapper(LIFNeuron(64, lif), USE_JIT), nn.Linear]),\n",
    "    ('adap_layer', [['first_layer'], make_SequenceWrapper(CooldownNeuron(64, heavyside), USE_JIT), nn.Linear]),\n",
    "    ('output', [['second_layer', 'adap_layer'], DummyNeuron(1), nn.Linear]),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#144, 150, 137, 150\n",
    "\n",
    "#model = OuterWrapper(DynNetwork(architecture), device, USE_JIT)\n",
    "\n",
    "#model = OuterWrapper(DynNetwork(forward_ann), device, USE_JIT)\n",
    "\n",
    "#model = OuterWrapper(DynNetwork(forward_snn), device, USE_JIT)\n",
    "\n",
    "model = OuterWrapper(DynNetwork(forward_adap), device, USE_JIT)\n",
    "\n",
    "\n",
    "#model = (OuterWrapper(DynNetwork(architecturelstm), device, True))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "teacher = LookupPolicy(device)\n",
    "mse = nn.MSELoss(reduction='none')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)#0.000011e-6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005204004119150341 0.9564611911773682 0\n",
      "8.280282054329291e-05 0.16329488158226013 100\n",
      "3.618705886765383e-05 0.06938478350639343 200\n",
      "2.3129434339352883e-05 0.04346173256635666 300\n",
      "1.1950374755542725e-05 0.023363661020994186 400\n",
      "7.960805305629037e-06 0.01547070499509573 500\n",
      "6.595272225240478e-06 0.012753039598464966 600\n",
      "6.067212325433502e-06 0.011569429188966751 700\n",
      "6.0732822930731345e-06 0.011328786611557007 800\n",
      "4.707947482529562e-06 0.009485835209488869 900\n",
      "4.337231075624004e-06 0.0085685383528471 1000\n",
      "4.008578798675444e-06 0.00763543089851737 1100\n",
      "4.448111212695949e-06 0.008684057742357254 1200\n",
      "3.789743459492456e-06 0.0072494992054998875 1300\n",
      "3.867359282594407e-06 0.007080410607159138 1400\n",
      "3.593664587242529e-06 0.006606528535485268 1500\n",
      "3.871431545121595e-06 0.007667739875614643 1600\n",
      "3.3723799788276665e-06 0.006564905866980553 1700\n",
      "3.017428525708965e-06 0.0058224801905453205 1800\n",
      "3.2681532502465416e-06 0.00641852430999279 1900\n",
      "3.003119672939647e-06 0.005801779683679342 2000\n",
      "3.0269791295722825e-06 0.00590719236060977 2100\n",
      "3.002812945851474e-06 0.005958328489214182 2200\n",
      "2.991704604937695e-06 0.0053987810388207436 2300\n",
      "2.9433103918563575e-06 0.00575100677087903 2400\n",
      "3.154315891151782e-06 0.006074084434658289 2500\n",
      "3.191723635609378e-06 0.006182018201798201 2600\n",
      "3.1215884064295096e-06 0.006111437454819679 2700\n",
      "3.4611637147463625e-06 0.006428707856684923 2800\n",
      "3.323002829347388e-06 0.0063927508890628815 2900\n",
      "Total time:  1690.799910068512\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(3000):\n",
    "    model.zero_grad()\n",
    "    inputs, targets, mask = env.getBatch(BATCH_SIZE)\n",
    "    if i%100 == 0:\n",
    "        for p in model.parameters():\n",
    "            if torch.isnan(p).any():\n",
    "                raise Exception('Corrupted Model')\n",
    "    outputs, _ = model(inputs/0.52)\n",
    "    loss = (mse(outputs.squeeze(dim=2)*0.0234, targets) * mask).sum() / mask.sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        print(loss.item(), (loss/targets.view(-1).var()).item(), i)\n",
    "\n",
    "print('Total time: ', time.time()-start)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#model.save('../models/forward_cooldown_passive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7f54f47dbeb8>]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#model = torch.load('../models/snn_passive3')\n",
    "%matplotlib\n",
    "\n",
    "\n",
    "inputs, targets, mask = env.getBatch(1)\n",
    "outputs, _ = model(inputs/0.52)\n",
    "plt.close()\n",
    "plt.plot(inputs[:, 0, 0], targets)\n",
    "plt.plot(inputs[:, 0, 0], outputs.squeeze().detach()*0.0234)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\narchitecture1 = OrderedDict([\\n    ('input', [1]),\\n    ('pre_mem', [64, ['input', 'mem'], Neurons.LIFNeuron, config]),\\n    ('mem', [32, ['pre_mem'], Neurons.CooldownNeuron, config]), #CooldownNeuron\\n    ('post_mem', [64, ['input', 'mem'], Neurons.LIFNeuron, config]),\\n    ('output', [1, ['post_mem'], Neurons.OutputNeuron, outconfig]), #OutputNeuron\\n])\\n\\narchitecture = OrderedDict([\\n    ('input', [1]),\\n    ('pre_mem', [64, ['input', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\\n    ('mem', [32, ['pre_mem'], Neurons.CooldownNeuron, config, nn.Linear]), #CooldownNeuron\\n    ('short_mem', [32, ['pre_mem'], Neurons.CooldownNeuron, secondconfig, nn.Linear]),\\n    ('post_mem', [64, ['input', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\\n    ('output', [1, ['post_mem'], Neurons.OutputNeuron, outconfig, nn.Linear]), #OutputNeuron\\n])\\n\\n\\nBATCH_SIZE = 64\\nSIM_TIME = 1\\n\\n\\ndevice = torch.device('cpu')\\n\\nenv = PassiveEnv(device)\\n\\n#model = lstmPolicyPredictor(1,32,64)\\n\\n#model = FullyConnected([1, 128, 128, 1])\\n\\nmodel_raw = DynNetwork(architecture, SIM_TIME)\\nmodel = SequenceWrapper(model_raw, BATCH_SIZE, device, False)\\n\""
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: output reset mechanism\n",
    "\n",
    "config = {\n",
    "    'ALPHA': 0.7,\n",
    "    'BETA': 0.9, #0.95\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "secondconfig = {\n",
    "    'ALPHA': 0.7,\n",
    "    'BETA': 0.5, #0.95\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "outconfig = {\n",
    "    'ALPHA': 0,\n",
    "    'BETA': 0,\n",
    "    'RESET_ZERO': False,\n",
    "    'DECODING': 'potential',\n",
    "    'SPIKE_FN': 'ss'\n",
    "}\n",
    "\n",
    "'''\n",
    "architecture1 = OrderedDict([\n",
    "    ('input', [1]),\n",
    "    ('pre_mem', [64, ['input', 'mem'], Neurons.LIFNeuron, config]),\n",
    "    ('mem', [32, ['pre_mem'], Neurons.CooldownNeuron, config]), #CooldownNeuron\n",
    "    ('post_mem', [64, ['input', 'mem'], Neurons.LIFNeuron, config]),\n",
    "    ('output', [1, ['post_mem'], Neurons.OutputNeuron, outconfig]), #OutputNeuron\n",
    "])\n",
    "\n",
    "architecture = OrderedDict([\n",
    "    ('input', [1]),\n",
    "    ('pre_mem', [64, ['input', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('mem', [32, ['pre_mem'], Neurons.CooldownNeuron, config, nn.Linear]), #CooldownNeuron\n",
    "    ('short_mem', [32, ['pre_mem'], Neurons.CooldownNeuron, secondconfig, nn.Linear]),\n",
    "    ('post_mem', [64, ['input', 'mem', 'short_mem'], Neurons.LIFNeuron, config, nn.Linear]),\n",
    "    ('output', [1, ['post_mem'], Neurons.OutputNeuron, outconfig, nn.Linear]), #OutputNeuron\n",
    "])\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SIM_TIME = 1\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "env = PassiveEnv(device)\n",
    "\n",
    "#model = lstmPolicyPredictor(1,32,64)\n",
    "\n",
    "#model = FullyConnected([1, 128, 128, 1])\n",
    "\n",
    "model_raw = DynNetwork(architecture, SIM_TIME)\n",
    "model = SequenceWrapper(model_raw, BATCH_SIZE, device, False)\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}