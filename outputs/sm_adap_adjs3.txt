Sending build context to Docker daemon  859.6MB
Step 1/14 : FROM nvcr.io/nvidia/pytorch:20.01-py3
 ---> 5c0c8c90f238
Step 2/14 : RUN apt-get update
 ---> Using cache
 ---> 49b91d3b028f
Step 3/14 : RUN apt-get install -y mesa-utils
 ---> Using cache
 ---> f9cbee75ce95
Step 4/14 : RUN apt-get install -y sudo
 ---> Using cache
 ---> 8de31bcea5ca
Step 5/14 : RUN apt-get install -y python-opengl
 ---> Using cache
 ---> 2c2323a47648
Step 6/14 : ENV NVIDIA_VISIBLE_DEVICES     ${NVIDIA_VISIBLE_DEVICES:-all}
 ---> Using cache
 ---> 2acb4ef7032b
Step 7/14 : ENV NVIDIA_DRIVER_CAPABILITIES     ${NVIDIA_DRIVER_CAPABILITIES:+$NVIDIA_DRIVER_CAPABILITIES,}graphics
 ---> Using cache
 ---> e92792bb3c58
Step 8/14 : RUN mkdir -p /home/developer
 ---> Using cache
 ---> 7598223c06db
Step 9/14 : ENV HOME /home/developer
 ---> Using cache
 ---> b1cbf68e1462
Step 10/14 : WORKDIR /home/developer
 ---> Using cache
 ---> 140ef4df9fa5
Step 11/14 : COPY packages.txt /home/developer
 ---> Using cache
 ---> 11f6970c9c6a
Step 12/14 : RUN pip install -r packages.txt
 ---> Using cache
 ---> 247b4ac188d6
Step 13/14 : RUN export uid=1000 gid=1001 &&     mkdir -p /etc/sudoers.d &&     echo "developer:x:${uid}:${gid}:Developer,,,:/home/developer:/bin/bash" >> /etc/passwd &&     echo "developer:x:${gid}:" >> /etc/group &&     echo "developer ALL=(ALL) NOPASSWD: ALL" > /etc/sudoers.d/developer &&     chmod 0440 /etc/sudoers.d/developer &&     chown ${uid}:${gid} -R /home/developer
 ---> Using cache
 ---> 42cef29ee1aa
Step 14/14 : USER developer
 ---> Using cache
 ---> 9c927a8d6226
Successfully built 9c927a8d6226
Successfully tagged imrsnn:latest

=============
== PyTorch ==
=============

NVIDIA Release 20.01 (build 9332039)
PyTorch Version 1.4.0a0+a5b4d78

Container image Copyright (c) 2019, NVIDIA CORPORATION.  All rights reserved.

Copyright (c) 2014-2019 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.
NVIDIA modifications are covered by the license terms that apply to the underlying project or file.

NOTE: MOFED driver for multi-node communication was not detected.
      Multi-node communication performance may be reduced.

OrderedDict([('control', [[('input', 1), ('control', 1), ('mem', 1)], LIFNeuron(), <class 'torch.nn.modules.linear.Linear'>]), ('mem', [[('input', 1), ('control', 1), ('mem', 1)], CooldownNeuron(
  (elu): ELU(alpha=1.0)
), <class 'torch.nn.modules.linear.Linear'>]), ('output', [[('control', 1), ('mem', 1)], BaseNeuron(), None])])
0.13834859877824784 20
0.14597252234816552 40
0.14191810525953769 60
0.15560345090925692 80
0.17110721841454507 100
Traceback (most recent call last):
  File "Code/run_statemachine.py", line 232, in <module>
    validate()
  File "Code/run_statemachine.py", line 192, in validate
    acc, _, _ = run(model, lookup, val_rythm, BATCH_SIZE, 100, CHAR_DUR, perm_num, device)
  File "./Code/envs/statemachine.py", line 84, in run
    dir_out = model(input, logging=logging)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "./Code/everything4.py", line 336, in forward
    return self.model(inp, h)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "./Code/everything4.py", line 247, in forward
    tmp = self.layers[layer](x, state[idxState])
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "./Code/everything4.py", line 316, in forward
    output[t], h = self.model(inp[t], h)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "./Code/everything4.py", line 127, in forward
    x = torch.cat(inputs, dim=-1)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.78 GiB total capacity; 1.16 GiB already allocated; 11.19 MiB free; 1.17 GiB reserved in total by PyTorch)
